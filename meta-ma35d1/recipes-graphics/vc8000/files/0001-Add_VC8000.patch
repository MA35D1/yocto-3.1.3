From 858e0b0e048a109c0c463fc63fa58d209c743fed Mon Sep 17 00:00:00 2001
From: schung1218 <shanchun1218@gmail.com>
Date: Thu, 1 Apr 2021 05:44:07 +0000
Subject: [PATCH] Add_VC8000

---
 Makefile            |  168 ++--
 args.c              |  231 +++---
 args.h              |   66 +-
 common.h            |  361 +++++----
 dcfb.h              |  106 +++
 fb.c                |  479 +++++++++++
 fileops.c           |   60 ++
 fileops.h           |   34 +
 main.c              | 1891 +++++++++++--------------------------------
 msm-v4l2-controls.h |  461 +++++++++++
 parser.c            |  626 ++++++++++++++
 parser.h            |   96 +++
 queue.c             |   89 ++
 queue.h             |   49 ++
 video.c             | 1832 +++++++++++------------------------------
 video.h             |  159 ++--
 16 files changed, 3450 insertions(+), 3258 deletions(-)
 create mode 100755 dcfb.h
 create mode 100755 fb.c
 create mode 100644 fileops.c
 create mode 100644 fileops.h
 create mode 100644 msm-v4l2-controls.h
 create mode 100644 parser.c
 create mode 100644 parser.h
 create mode 100644 queue.c
 create mode 100644 queue.h

diff --git a/Makefile b/Makefile
index 87e552b..2cc9a7d 100644
--- a/Makefile
+++ b/Makefile
@@ -1,112 +1,56 @@
-# V4L2 Codec decoding example application
-# Kamil Debski <k.debski@samsung.com>
-#
-# Copyright 2012 Samsung Electronics Co., Ltd.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-
-# Toolchain path
-CROSS ?= aarch64-linux-gnu-
-
-CC = $(CROSS)gcc
-AR = $(CROSS)ar rc
-PKG_CONFIG ?= pkg-config
-
-WAYLAND_SCANNER ?= wayland-scanner
-WAYLAND_PROTOCOLS_DATADIR := $(shell $(PKG_CONFIG) --variable=pkgdatadir wayland-protocols)
-
-GENERATED_SOURCES = \
-  protocol/scaler-protocol.c \
-  protocol/scaler-client-protocol.h \
-  protocol/viewporter-protocol.c \
-  protocol/viewporter-client-protocol.h \
-  protocol/presentation-time-protocol.c \
-  protocol/presentation-time-client-protocol.h \
-  protocol/xdg-shell-unstable-v6-protocol.c \
-  protocol/xdg-shell-unstable-v6-client-protocol.h \
-  protocol/linux-dmabuf-protocol.c \
-  protocol/linux-dmabuf-client-protocol.h \
-  protocol/linux-dmabuf-unstable-v1-protocol.c \
-  protocol/linux-dmabuf-unstable-v1-client-protocol.h
-
-SOURCES = main.c args.c video.c display.c $(filter %.c,$(GENERATED_SOURCES))
-OBJECTS := $(SOURCES:.c=.o)
-EXEC = v4l2_decode
-
-cflags = -std=gnu11 -Wall -pthread $(shell $(PKG_CONFIG) --cflags wayland-client libffi libavformat libavcodec libavutil) $(CFLAGS)
-ldflags = -pthread $(LDFLAGS)
-cppflags = -Iprotocol -D_DEFAULT_SOURCE $(CPPFLAGS)
-ldlibs = -lm -Wl,-Bstatic $(shell $(PKG_CONFIG) --libs --static wayland-client libffi libavformat libavcodec libavutil) -Wl,-Bdynamic
-
-all: $(EXEC)
-
-%.o: %.c
-	$(CC) -c $(cflags) -o $@ -MD -MP -MF $(@D)/.$(@F).d $(cppflags) $<
-
-$(EXEC): $(GENERATED_SOURCES) $(OBJECTS)
-	$(CC) $(ldflags) -o $(EXEC) $(OBJECTS) $(ldlibs)
-
-clean:
-	$(RM) *.o protocol/*.o $(EXEC) $(GENERATED_SOURCES)
-
-install:
-
-.PHONY: clean all install
-
--include $(patsubst %,.%.d,$(OBJECTS))
-
-.SECONDEXPANSION:
-
-define protostability
-$(if $(findstring unstable,$1),unstable,stable)
-endef
-
-define protoname
-$(shell echo $1 | sed 's/\([a-z\-]\+\)-[a-z]\+-v[0-9]\+/\1/')
-endef
-
-protocol/%-protocol.c : $(WAYLAND_PROTOCOLS_DATADIR)/$$(call protostability,$$*)/$$(call protoname,$$*)/$$*.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) code < $< > $@
-
-protocol/%-server-protocol.h : $(WAYLAND_PROTOCOLS_DATADIR)/$$(call protostability,$$*)/$$(call protoname,$$*)/$$*.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) server-header < $< > $@
-
-protocol/%-client-protocol.h : $(WAYLAND_PROTOCOLS_DATADIR)/$$(call protostability,$$*)/$$(call protoname,$$*)/$$*.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) client-header < $< > $@
-
-protocol/%-protocol.c : protocol/%.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) code < $< > $@
-
-protocol/%-server-protocol.h : protocol/%.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) server-header < $< > $@
-
-protocol/%-client-protocol.h : protocol/%.xml
-	mkdir -p $(@D) && $(WAYLAND_SCANNER) client-header < $< > $@
-
-GIT_VERSION = $(shell git describe --dirty --tags --always)
-GIT_COMMIT_DATE = $(shell git log -1 --format=%cd)
-
-.PHONY: .git-version
-.git-version:
-	v='$(GIT_VERSION)'; echo "$$v" | cmp -s - $@ || echo "$$v" > $@
-
-.PHONY: .git-commitdate
-.git-commitdate:
-	v='$(GIT_COMMIT_DATE)'; echo "$$v" | cmp -s - $@ || echo "$$v" > $@
-
-version.h: .git-version .git-commitdate
-	v=`cat .git-version`; echo "#define VERSION \"$$v\"" > $@
-	v=`cat .git-commitdate`; echo "#define DATE \"$$v\"" >> $@
-
-args.o: version.h
+# V4L2 Codec decoding example application
+# Kamil Debski <k.debski@samsung.com>
+#
+# Copyright 2012 Samsung Electronics Co., Ltd.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# Toolchain path
+#TCPATH = aarch64-poky-linux-
+KERNELHEADERS = /usr/include
+
+#CC = ${TCPATH}gcc
+#AR = "${TCPATH}ar rc"
+#AR2 = ${TCPATH}ranlib make -j4
+#STRIP := ${TCPATH}strip
+
+INCLUDES = -I$(KERNELHEADERS)
+
+#INCLUDES = -I$(KERNELHEADERS)/include
+
+#-I$(TARGETROOT)/usr/include/linux
+
+SOURCES = main.c fileops.c args.c parser.c video.c queue.c
+OBJECTS := $(SOURCES:.c=.o)
+EXEC = vc8000-h264
+CFLAGS = -Wall -g -lm
+#-Os
+
+all: $(EXEC)
+	$(STRIP) $(EXEC)
+	cp $(EXEC) ../../../rootfs
+	ls -l
+
+.c.o:
+	$(CC) -c $(CFLAGS) $(INCLUDES) $<
+
+$(EXEC): $(OBJECTS)
+	$(CC) $(CFLAGS) -static -o $(EXEC) $(OBJECTS) -pthread
+
+clean:
+	rm -f *.o $(EXEC)
+
+install:
+
+.PHONY: clean all
diff --git a/args.c b/args.c
index b4c92e1..e4c1894 100644
--- a/args.c
+++ b/args.c
@@ -1,106 +1,125 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- * Argument parser
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- * Copyright (c) 2015 Linaro Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <unistd.h>
-#include <stdlib.h>
-
-#include "common.h"
-#include "version.h"
-
-int debug_level;
-
-void print_usage(char *name)
-{
-	fprintf(stderr, "v4l2_decode version " VERSION " date " DATE "\n\n");
-	fprintf(stderr, "usage: %s [OPTS] <URL>\n", name);
-	fprintf(stderr, "Where OPTS is a combination of:\n"
-	        "  -m <device>     video device (default /dev/video32)\n"
-	        "  -c              set \"continue data transfer\" flag\n"
-	        "  -d              output frames in decode order\n"
-	        "  -f              start fullscreen\n"
-	        "  -i              skip frames\n"
-	        "  -p              start paused\n"
-	        "  -s              secure mode\n"
-	        "  -v              increase debug verbosity\n"
-	        "  -q              remove all debug output\n"
-		"\n");
-}
-
-int parse_args(struct instance *i, int argc, char **argv)
-{
-	int c;
-
-	memset(i, 0, sizeof (*i));
-
-	i->video.name = "/dev/video32";
-
-	debug_level = 2;
-
-	while ((c = getopt(argc, argv, "cdfhim:o:pqsv")) != -1) {
-		switch (c) {
-		case 'c':
-			i->continue_data_transfer = 1;
-			break;
-		case 'm':
-			i->video.name = optarg;
-			break;
-		case 'd':
-			i->decode_order = 1;
-			break;
-		case 'f':
-			i->fullscreen = 1;
-			break;
-		case 'p':
-			i->paused = 1;
-			break;
-		case 'q':
-			debug_level = 0;
-			break;
-		case 'i':
-			i->skip_frames = 1;
-			break;
-		case 's':
-			i->secure = 1;
-			break;
-		case 'v':
-			debug_level++;
-			break;
-		default:
-			err("bad argument\n");
-		case 'h':
-			return -1;
-		}
-	}
-
-	if (optind >= argc) {
-		err("missing url to play\n");
-		return -1;
-	}
-
-	i->url = argv[optind];
-
-	return 0;
-}
-
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Argument parser
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ * Copyright (c) 2015 Linaro Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <unistd.h>
+#include <stdlib.h>
+#include <linux/videodev2.h>
+
+#include "common.h"
+#include "parser.h"
+
+
+void print_usage(char *name)
+{
+	printf("Usage:\n");
+	printf("\t%s\n", name);
+	printf("\t-d <device>  - Frame buffer device (e.g. /dev/fb0)\n");
+	printf("\t-i <file> - Input file name\n");
+	printf("\t-m <device> - video decoder device (e.g. /dev/video0)\n");
+	printf("\t-w video width\n");
+	printf("\t-h video height\n");
+	printf("\t-f output format\n");
+	printf("\t-s save frames on disk\n");
+	printf("\n");
+}
+
+void init_to_defaults(struct instance *i)
+{
+	memset(i, 0, sizeof(*i));
+}
+
+int parse_args(struct instance *i, int argc, char **argv)
+{
+	int c;
+
+	init_to_defaults(i);
+	
+	i->parser.codec = V4L2_PIX_FMT_H264;
+	i->out_format = NULL;
+
+	while ((c = getopt(argc, argv, "w:h:d:i:m:f:s:")) != -1) {
+		switch (c) {
+		case 'c':
+			i->parser.codec = V4L2_PIX_FMT_H264;
+			break;
+		case 'j':
+			//i->parser.codec = V4L2_PIX_FMT_JPEG;
+			break;
+		case 'd':
+			i->fb.name = optarg;
+			break;
+		case 'i':
+			i->in.name = optarg;
+			break;
+		case 'm':
+			i->video.name = optarg;
+			break;
+		case 'w':
+			i->width = atoi(optarg);
+			break;
+		case 'h':
+			i->height = atoi(optarg);
+			break;
+		case 'f':
+			i->out_format = optarg;
+			break;
+		case 's':
+			i->save_frames = 1;
+			i->save_path = optarg;
+			break;
+		default:
+			err("Bad argument");
+			return -1;
+		}
+	}
+
+	if (!i->in.name || !i->video.name) {
+		err("The following arguments are required: -i -m -c");
+		return -1;
+	}
+
+	if (!i->parser.codec) {
+		err("Unknown or not set codec (-c)");
+		return -1;
+	}
+
+	switch (i->parser.codec) {
+	case V4L2_PIX_FMT_XVID:
+	case V4L2_PIX_FMT_H263:
+	case V4L2_PIX_FMT_MPEG4:
+		i->parser.func = parse_mpeg4_stream;
+		break;
+	case V4L2_PIX_FMT_H264:
+		i->parser.func = parse_h264_stream;
+		break;
+	case V4L2_PIX_FMT_MPEG1:
+	case V4L2_PIX_FMT_MPEG2:
+		i->parser.func = parse_mpeg2_stream;
+		break;
+	}
+
+	return 0;
+}
+
diff --git a/args.h b/args.h
index 93468e5..214fa08 100644
--- a/args.h
+++ b/args.h
@@ -1,33 +1,33 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- * Argument parser header file
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-#ifndef INCLUDE_ARGS_H
-#define INCLUDE_ARGS_H
-
-#include "common.h"
-
-/* Pritn usage information of the application */
-void print_usage(char *name);
-/* Parse the arguments that have been given to the application */
-int parse_args(struct instance *i, int argc, char **argv);
-
-#endif /* INCLUDE_FILEOPS_H */
-
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Argument parser header file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+#ifndef INCLUDE_ARGS_H
+#define INCLUDE_ARGS_H
+
+#include "common.h"
+
+/* Pritn usage information of the application */
+void print_usage(char *name);
+/* Parse the arguments that have been given to the application */
+int parse_args(struct instance *i, int argc, char **argv);
+
+#endif /* INCLUDE_FILEOPS_H */
+
diff --git a/common.h b/common.h
index 222a271..bd660a6 100644
--- a/common.h
+++ b/common.h
@@ -1,167 +1,194 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- * Common stuff header file
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- * Copyright (c) 2015 Linaro Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-#ifndef INCLUDE_COMMON_H
-#define INCLUDE_COMMON_H
-
-#include <stdio.h>
-#include <stdint.h>
-#include <pthread.h>
-#include <termios.h>
-
-#include <libavformat/avformat.h>
-#include <libavcodec/avcodec.h>
-
-#include "display.h"
-#include "list.h"
-
-extern int debug_level;
-
-#define ARRAY_LENGTH(x) (sizeof (x) / sizeof (*(x)))
-
-#define print(l, msg, ...)						\
-	do {								\
-		if (debug_level >= l)					\
-			fprintf(stderr, msg, ##__VA_ARGS__);		\
-	} while (0)
-
-#define err(msg, ...) \
-	print(1, "error: " msg "\n", ##__VA_ARGS__)
-
-#define info(msg, ...) \
-	print(2, msg "\n", ##__VA_ARGS__)
-
-#define dbg(msg, ...) \
-	print(3, DBG_TAG ": " msg "\n", ##__VA_ARGS__)
-
-#define MIN(a, b) ((a) < (b) ? (a) : (b))
-
-#define memzero(x)	memset(&(x), 0, sizeof (x));
-
-/* Maximum number of output buffers */
-#define MAX_OUT_BUF		16
-
-/* Maximum number of capture buffers (32 is the limit imposed by MFC */
-#define MAX_CAP_BUF		32
-
-/* Number of output planes */
-#define OUT_PLANES		1
-
-/* Number of capture planes */
-#define CAP_PLANES		2
-
-/* Maximum number of planes used in the application */
-#define MAX_PLANES		CAP_PLANES
-
-/* video decoder related parameters */
-struct video {
-	char *name;
-	int fd;
-
-	/* Output queue related */
-	int out_buf_cnt;
-	int out_buf_size;
-	int out_buf_off[MAX_OUT_BUF];
-	char *out_buf_addr[MAX_OUT_BUF];
-	int out_buf_flag[MAX_OUT_BUF];
-	int out_ion_fd;
-	int out_ion_size;
-	void *out_ion_addr;
-
-	/* Capture queue related */
-	int cap_w;
-	int cap_h;
-	int cap_buf_cnt;
-	uint32_t cap_buf_format;
-	int cap_planes_count;
-	int cap_plane_off[CAP_PLANES];
-	int cap_plane_stride[CAP_PLANES];
-	int cap_buf_flag[MAX_CAP_BUF];
-	int cap_buf_size;
-	int cap_buf_fd[MAX_CAP_BUF];
-	void *cap_buf_addr[MAX_CAP_BUF];
-
-	/* timestamp list for all pending frames */
-	struct list_head pending_ts_list;
-	uint64_t cap_last_pts;
-	uint64_t pts_dts_delta;
-
-	/* Extradata stuff */
-	int extradata_index;
-	int extradata_size;
-	int extradata_ion_fd;
-	void *extradata_ion_addr;
-	int extradata_off[MAX_CAP_BUF];
-	void *extradata_addr[MAX_CAP_BUF];
-
-	/* Metrics */
-	unsigned long total_captured;
-};
-
-struct instance {
-	int width;
-	int height;
-	int fullscreen;
-	uint32_t fourcc;
-	int fps_n, fps_d;
-	int depth;
-	int interlaced;
-	int decode_order;
-	int skip_frames;
-	int insert_sc;
-	int need_header;
-	int secure;
-	int continue_data_transfer;
-	char *url;
-
-	/* video decoder related parameters */
-	struct video	video;
-
-	pthread_mutex_t lock;
-	pthread_cond_t cond;
-
-	/* Control */
-	int sigfd;
-	int paused;
-	int prerolled;
-	int finish;  /* Flag set when decoding has been completed and all
-			threads finish */
-
-	int reconfigure_pending;
-	int group;
-
-	struct display *display;
-	struct window *window;
-	struct list_head fb_list;
-
-	int stdin_valid;
-	struct termios stdin_termios;
-
-	AVFormatContext *avctx;
-	AVStream *stream;
-	AVBSFContext *bsf;
-	int bsf_data_pending;
-};
-
-#endif /* INCLUDE_COMMON_H */
-
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Common stuff header file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ * Copyright (c) 2015 Linaro Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#ifndef INCLUDE_COMMON_H
+#define INCLUDE_COMMON_H
+
+#include <stdio.h>
+#include <semaphore.h>
+
+#include "parser.h"
+#include "queue.h"
+
+/* When ADD_DETAILS is defined every debug and error message contains
+ * information about the file, function and line of code where it has
+ * been called */
+#define ADD_DETAILS
+
+/* When DEBUG is defined debug messages are printed on the screen.
+ * Otherwise only error messages are displayed. */
+#define DEBUG
+
+#ifdef ADD_DETAILS
+#define err(msg, ...) \
+	fprintf(stderr, "Error (%s:%s:%d): " msg "\n", __FILE__, \
+		__func__, __LINE__, ##__VA_ARGS__)
+#else
+#define err(msg, ...) \
+	fprintf(stderr, "Error: " msg "\n", __FILE__, ##__VA_ARGS__)
+#endif /* ADD_DETAILS */
+
+#define info(msg, ...) \
+	fprintf(stderr, "Info : " msg "\n", ##__VA_ARGS__)
+
+#ifdef DEBUG
+#ifdef ADD_DETAILS
+#define dbg(msg, ...) \
+	fprintf(stdout, "(%s:%s:%d): " msg "\n", __FILE__, \
+		__func__, __LINE__, ##__VA_ARGS__)
+#else
+#define dbg(msg, ...) \
+	fprintf(stdout, msg "\n", ##__VA_ARGS__)
+#endif /* ADD_DETAILS */
+#else /* DEBUG */
+#define dbg(...) {}
+#endif /* DEBUG */
+
+#define memzero(x)	memset(&(x), 0, sizeof (x));
+
+#define MAX_H264_WIDTH          1920
+#define MAX_H264_HEIGHT         1088
+
+/* Maximum number of output buffers */
+#define MAX_OUT_BUF		16
+
+/* Maximum number of capture buffers (32 is the limit imposed by MFC */
+#define MAX_CAP_BUF		32
+
+/* Number of output planes */
+#define OUT_PLANES		1
+
+/* Number of capture planes */
+#define CAP_PLANES		1
+
+/* Maximum number of planes used in the application */
+#define MAX_PLANES		CAP_PLANES
+
+/* Maximum number of frame buffers - used for double buffering and
+ * vsyns synchronisation */
+#define FB_MAX_BUFS		2
+
+/* The buffer is free to use by video decoder */
+#define BUF_FREE		0
+
+/* Input file related parameters */
+struct input {
+	char *name;
+	int fd;
+	char *p;
+	int size;
+	int offs;
+};
+
+/* Frame buffer related parameters */
+struct fb {
+	char *name;
+	int fd;
+	char *p[FB_MAX_BUFS];
+	int cur_buf;
+	int buffers;
+	int width;
+	int height;
+	int virt_width;
+	int virt_height;
+	int bpp;
+	int stride;
+	int size;
+	int full_size;
+	int double_buf;
+};
+
+/* video decoder related parameters */
+struct video {
+	char *name;
+	int fd;
+
+	/* Output queue related */
+	int out_buf_cnt;
+	int out_buf_size;
+	int out_buf_off[MAX_OUT_BUF];
+	char *out_buf_addr[MAX_OUT_BUF];
+	int out_buf_flag[MAX_OUT_BUF];
+
+	/* Capture queue related */
+	int cap_w;
+	int cap_h;
+	int cap_crop_w;
+	int cap_crop_h;
+	int cap_crop_left;
+	int cap_crop_top;
+	int cap_buf_cnt;
+	int cap_buf_cnt_min;
+	int cap_buf_size[CAP_PLANES];
+	int cap_buf_off[MAX_CAP_BUF][CAP_PLANES];
+	char *cap_buf_addr[MAX_CAP_BUF][CAP_PLANES];
+	int cap_buf_flag[MAX_CAP_BUF];
+	int cap_buf_queued;
+
+	unsigned long total_captured;
+};
+
+/* Parser related parameters */
+struct parser {
+	struct mfc_parser_context ctx;
+	unsigned long codec;
+	/* Callback function to the real parsing function.
+	 * Dependent on the codec used. */
+	int (*func)(struct mfc_parser_context *ctx,
+		    char* in, int in_size, char* out, int out_size,
+		    int *consumed, int *frame_size, char get_head);
+	/* Set when the parser has finished and end of file has
+	 * been reached */
+	int finished;
+};
+
+struct instance {
+	int width;
+	int height;
+	char  *out_format;
+	int save_frames;
+	char *save_path;
+
+	/* Input file related parameters */
+	struct input	in;
+
+	/* Frame buffer related parameters */
+	struct fb	fb;
+
+	/* video decoder related parameters */
+	struct video	video;
+
+	/* Parser related parameters */
+	struct parser	parser;
+
+	pthread_mutex_t lock;
+	struct queue queue;
+
+	/* Control */
+	int error;   /* The error flag */
+	int finish;  /* Flag set when decoding has been completed and all
+			threads finish */
+};
+
+#endif /* INCLUDE_COMMON_H */
+
diff --git a/dcfb.h b/dcfb.h
new file mode 100755
index 0000000..aa7c42b
--- /dev/null
+++ b/dcfb.h
@@ -0,0 +1,106 @@
+#ifndef _UAPI_LINUX_ULTRAFB_H
+#include <stdbool.h>
+
+#define _UAPI_LINUX_ULTRAFB_H
+
+#define ULTRAFBIO_CURSOR 0x46A0
+#define ULTRAFBIO_BLENDING_MODE 0x46A4
+#define ULTRAFBIO_GLOBAL_MODE_VALUE 0x46A5
+#define ULTRAFBIO_BUFFER_SIZE 0x46A7
+#define ULTRAFBIO_OVERLAY_RECT 0x46A8
+#define ULTRAFBIO_SCALE_FILTER_TAP 0x46A9
+#define ULTRAFBIO_SYNC_TABLE 0x46AA
+#define ULTRAFBIO_GAMMA 0x46BD
+#define ULTRAFBIO_DITHER 0x46BE
+#define ULTRAFBIO_ROTATION 0x46BF
+#define ULTRAFBIO_TILEMODE 0x46C1
+#define ULTRAFBIO_COLORKEY 0x46C2
+
+#define CURSOR_SIZE 32
+#define GAMMA_INDEX_MAX 256
+
+typedef struct _dc_frame_info {
+    unsigned int width;
+    unsigned int height;
+    unsigned int stride;
+}
+dc_frame_info;
+
+typedef struct _dc_overlay_rect {
+    unsigned int tlx;
+    unsigned int tly;
+    unsigned int brx;
+    unsigned int bry;
+}
+dc_overlay_rect;
+
+typedef enum _dc_alpha_blending_mode {
+    DC_BLEND_MODE_CLEAR = 0x0,
+    DC_BLEND_MODE_SRC,
+    DC_BLEND_MODE_DST,
+    DC_BLEND_MODE_SRC_OVER,
+    DC_BLEND_MODE_DST_OVER,
+    DC_BLEND_MODE_SRC_IN,
+    DC_BLEND_MODE_DST_IN,
+    DC_BLEND_MODE_SRC_OUT,
+}
+dc_alpha_blending_mode;
+
+typedef enum _dc_rot_angle {
+    DC_ROT_ANGLE_ROT0 = 0x0,
+    DC_ROT_ANGLE_FLIP_X,
+    DC_ROT_ANGLE_FLIP_Y,
+    DC_ROT_ANGLE_FLIP_XY,
+    DC_ROT_ANGLE_ROT90,
+    DC_ROT_ANGLE_ROT180,
+    DC_ROT_ANGLE_ROT270,
+}
+dc_rot_angle;
+
+typedef enum _dc_tile_mode {
+    DC_TILE_MODE_LINEAR = 0x0,
+    DC_TILE_MODE_TILED4X4,
+    DC_TILE_MODE_SUPER_TILED_XMAJOR,
+    DC_TILE_MODE_SUPER_TILED_YMAJOR,
+    DC_TILE_MODE_TILE_MODE8X8,
+    DC_TILE_MODE_TILE_MODE8X4,
+    DC_TILE_MODE_SUPER_TILED_XMAJOR8X4,
+    DC_TILE_MODE_SUPER_TILED_YMAJOR4X8,
+    DC_TILE_MODE_TILE_Y,
+}
+dc_tile_mode;
+
+typedef struct _dc_global_alpha {
+    unsigned int global_alpha_mode;
+    unsigned int global_alpha_value;
+}
+dc_global_alpha;
+
+typedef struct _dc_filter_tap {
+    unsigned int vertical_filter_tap;
+    unsigned int horizontal_filter_tap;
+}
+dc_filter_tap;
+
+typedef struct _dc_sync_table {
+    unsigned int horkernel[128];
+    unsigned int verkernel[128];
+}
+dc_sync_table;
+
+typedef struct _dc_gamma_table {
+    bool gamma_enable;
+    unsigned int gamma[GAMMA_INDEX_MAX][3];
+}
+dc_gamma_table;
+
+typedef struct _dc_color_key {
+    unsigned char enable;
+    unsigned int colorkey_low;
+    unsigned int colorkey_high;
+    /* background color only available for video, not available for overlay*/
+    unsigned int bg_color;
+}
+dc_color_key;
+
+#endif
diff --git a/fb.c b/fb.c
new file mode 100755
index 0000000..be1cf8b
--- /dev/null
+++ b/fb.c
@@ -0,0 +1,479 @@
+/*
+ * NUA3500 frame buffer device control
+
+ * Copyright (C) 2021, Nuvoton Technology Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include <linux/videodev2.h>
+#include "msm-v4l2-controls.h"
+#include <fcntl.h>
+#include <string.h>
+#include <sys/mman.h>
+#include <sys/ioctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <errno.h>
+
+#include "common.h"
+
+static char *dbg_type[2] = {"OUTPUT", "CAPTURE"};
+static char *dbg_status[2] = {"ON", "OFF"};
+
+
+int fb_open(struct instance *i, char *name)
+{
+	struct v4l2_capability cap;
+	int ret;
+
+	i->video.fd = open(name, O_RDWR, 0);
+	if (i->video.fd < 0) {
+		err("Failed to open video decoder: %s", name);
+		return -1;
+	}
+
+	memzero(cap);
+	ret = ioctl(i->video.fd, VIDIOC_QUERYCAP, &cap);
+	if (ret) {
+		err("Failed to verify capabilities");
+		return -1;
+	}
+
+	info("caps (%s): driver=\"%s\" bus_info=\"%s\" card=\"%s\" fd=0x%x",
+	     name, cap.driver, cap.bus_info, cap.card, i->video.fd);
+
+	if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE) ||
+	    !(cap.capabilities & V4L2_CAP_VIDEO_OUTPUT_MPLANE) ||
+	    !(cap.capabilities & V4L2_CAP_STREAMING)) {
+		err("Insufficient capabilities for video device (is %s correct?)",
+		    name);
+		// return -1;
+	}
+
+        return 0;
+}
+
+void video_close(struct instance *i)
+{
+	close(i->video.fd);
+}
+
+int video_set_control(struct instance *i)
+{
+	struct v4l2_control control = {0};
+	int ret;
+
+	control.id = V4L2_CID_MPEG_VIDC_VIDEO_CONTINUE_DATA_TRANSFER;
+	control.value = 1;
+
+	ret = ioctl(i->video.fd, VIDIOC_S_CTRL, &control);
+
+	return ret;
+}
+
+static int video_queue_buf(struct instance *i, int n, int l1, int l2, int type,
+			   int nplanes)
+{
+	struct video *vid = &i->video;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[2];
+	int ret;
+
+	memzero(buf);
+	memset(planes, 0, sizeof(planes));
+	buf.type = type;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.index = n;
+	buf.length = nplanes;
+	buf.m.planes = planes;
+
+	buf.m.planes[0].bytesused = l1;
+	buf.m.planes[1].bytesused = l2;
+
+	buf.m.planes[0].data_offset = 0;
+	buf.m.planes[1].data_offset = 0;
+
+	if (type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+		buf.m.planes[0].length = vid->cap_buf_size[0];
+	} else {
+		buf.m.planes[0].length = vid->out_buf_size;
+		if (l1 == 0)
+			buf.flags |= V4L2_QCOM_BUF_FLAG_EOS;
+	}
+
+	ret = ioctl(vid->fd, VIDIOC_QBUF, &buf);
+	if (ret) {
+		err("Failed to queue buffer (index=%d) on %s (ret:%d)",
+		    buf.index,
+		    dbg_type[type==V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE], ret);
+		return -1;
+	}
+
+//	dbg("  Queued buffer on %s queue with index %d",
+//	    dbg_type[type==V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE], buf.index);
+
+	return 0;
+}
+
+int video_queue_buf_out(struct instance *i, int n, int length)
+{
+	struct video *vid = &i->video;
+
+	if (n >= vid->out_buf_cnt) {
+		err("Tried to queue a non exisiting buffer");
+		return -1;
+	}
+
+	return video_queue_buf(i, n, length, 0,
+			       V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, OUT_PLANES);
+}
+
+int video_queue_buf_cap(struct instance *i, int n)
+{
+	struct video *vid = &i->video;
+
+	if (n >= vid->cap_buf_cnt) {
+		err("Tried to queue a non exisiting buffer");
+		return -1;
+	}
+
+	return video_queue_buf(i, n, vid->cap_buf_size[0], vid->cap_buf_size[1],
+			       V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, CAP_PLANES);
+}
+
+static int video_dequeue_buf(struct instance *i, struct v4l2_buffer *buf)
+{
+	struct video *vid = &i->video;
+	int ret;
+
+	ret = ioctl(vid->fd, VIDIOC_DQBUF, buf);
+	if (ret < 0) {
+		err("Failed to dequeue buffer (%d)", -errno);
+		return -errno;
+	}
+
+//	dbg("Dequeued buffer on %s queue with index %d (flags:%x, bytesused:%d)",
+//	    dbg_type[buf->type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE],
+//	    buf->index, buf->flags, buf->m.planes[0].bytesused);
+
+	return 0;
+}
+
+int video_dequeue_output(struct instance *i, int *n)
+{
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[OUT_PLANES];
+	int ret;
+
+	memzero(buf);
+	buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.m.planes = planes;
+	buf.length = OUT_PLANES;
+
+	ret = video_dequeue_buf(i, &buf);
+	if (ret < 0)
+		return ret;
+
+	*n = buf.index;
+
+	return 0;
+}
+
+int video_dequeue_capture(struct instance *i, int *n, int *finished,
+			  unsigned int *bytesused)
+{
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[CAP_PLANES];
+
+	memzero(buf);
+	buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.m.planes = planes;
+	buf.length = CAP_PLANES;
+
+	if (video_dequeue_buf(i, &buf))
+		return -1;
+
+	*finished = 0;
+
+	if (buf.flags & V4L2_QCOM_BUF_FLAG_EOS ||
+	    buf.m.planes[0].bytesused == 0)
+		*finished = 1;
+
+	*bytesused = buf.m.planes[0].bytesused;
+	*n = buf.index;
+
+	return 0;
+}
+
+int video_stream(struct instance *i, enum v4l2_buf_type type, int status)
+{
+	struct video *vid = &i->video;
+	int ret;
+
+	ret = ioctl(vid->fd, status, &type);
+	if (ret) {
+		err("Failed to change streaming (type=%s, status=%s)",
+		    dbg_type[type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE],
+		    dbg_status[status == VIDIOC_STREAMOFF]);
+		return -1;
+	}
+
+	dbg("Stream %s on %s queue", dbg_status[status==VIDIOC_STREAMOFF],
+	    dbg_type[type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE]);
+
+	return 0;
+}
+
+int video_stop(struct instance *i)
+{
+	struct video *vid = &i->video;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_decoder_cmd dec;
+	int ret;
+
+	memzero(dec);
+	dec.cmd = V4L2_DEC_CMD_STOP;
+	ret = ioctl(vid->fd, VIDIOC_DECODER_CMD, &dec);
+	if (ret < 0) {
+		err("DECODER_CMD failed (%s)", strerror(errno));
+		return -1;
+	}
+
+	/* HACK: streamoff failing, so bail out of here */
+	return 0;
+
+	memzero(reqbuf);
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret < 0) {
+		err("REQBUFS with count=0 on CAPTURE queue failed (%s)",
+		    strerror(errno));
+		return -1;
+	}
+
+	memzero(reqbuf);
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret < 0) {
+		err("REQBUFS with count=0 on OUTPUT queue failed (%s)",
+		    strerror(errno));
+		return -1;
+	}
+
+	ret = video_stream(i, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
+			   VIDIOC_STREAMOFF);
+	if (ret < 0)
+		err("STREAMOFF CAPTURE queue failed (%s)", strerror(errno));
+
+	ret = video_stream(i, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE,
+			   VIDIOC_STREAMOFF);
+	if (ret < 0)
+		err("STREAMOFF OUTPUT queue failed (%s)", strerror(errno));
+
+	return 0;
+}
+
+int video_setup_capture(struct instance *i, int extra_buf, int w, int h)
+{
+	struct video *vid = &i->video;
+	struct v4l2_format fmt;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[CAP_PLANES];
+	int ret;
+	int n;
+
+	fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	fmt.fmt.pix_mp.height = h;
+	fmt.fmt.pix_mp.width = w;
+
+printf("video_setup_capture: %dx%d\n", w, h);
+	if (i->out_format == NULL) {
+		printf("Output format not specified, use defalt NV12.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_NV12;
+	}
+	else if (strcmp(i->out_format, "argb888") == 0) {
+		printf("Specified output format ARGB888.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_ARGB32;
+	}
+	else if (strcmp(i->out_format, "rgb565") == 0) {
+		printf("Specified output format RGB565.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_RGB565;
+	}
+	else {
+		printf("Unrecognized output format, use defalt NV12.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_NV12;
+	}
+
+	ret = ioctl(vid->fd, VIDIOC_S_FMT, &fmt);
+	if (ret) {
+		err("Failed to set format (%dx%d)", w, h);
+		return -1;
+	}
+
+	vid->cap_w = fmt.fmt.pix_mp.width;
+	vid->cap_h = fmt.fmt.pix_mp.height;
+
+	vid->cap_buf_size[0] = fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
+	vid->cap_buf_size[1] = fmt.fmt.pix_mp.plane_fmt[1].sizeimage;
+
+	vid->cap_buf_cnt = 4 + extra_buf;
+	vid->cap_buf_cnt_min = 4;
+	vid->cap_buf_queued = 0;
+
+	dbg("video decoder buffer parameters: %dx%d plane[0]=%d plane[1]=%d",
+	    fmt.fmt.pix_mp.width, fmt.fmt.pix_mp.height,
+	    vid->cap_buf_size[0], vid->cap_buf_size[1]);
+
+	memzero(reqbuf);
+	reqbuf.count = vid->cap_buf_cnt;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret != 0) {
+		err("REQBUFS failed on CAPTURE queue (%s)", strerror(errno));
+		return -1;
+	}
+
+	dbg("Number of CAPTURE buffers is %d (requested %d, extra %d)",
+	    reqbuf.count, vid->cap_buf_cnt, extra_buf);
+
+	vid->cap_buf_cnt = reqbuf.count;
+
+	for (n = 0; n < vid->cap_buf_cnt; n++) {
+		memzero(buf);
+		memset(planes, 0, sizeof(planes));
+		buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		buf.memory = V4L2_MEMORY_MMAP;
+		buf.index = n;
+		buf.m.planes = planes;
+		buf.length = CAP_PLANES;
+
+		ret = ioctl(vid->fd, VIDIOC_QUERYBUF, &buf);
+		if (ret != 0) {
+			err("QUERYBUF failed on CAPTURE queue (%s)",
+			    strerror(errno));
+			return -1;
+		}
+
+		vid->cap_buf_off[n][0] = buf.m.planes[0].m.mem_offset;
+
+		vid->cap_buf_addr[n][0] = mmap(NULL, buf.m.planes[0].length,
+					       PROT_READ | PROT_WRITE,
+					       MAP_SHARED,
+					       vid->fd,
+					       buf.m.planes[0].m.mem_offset);
+
+		if (vid->cap_buf_addr[n][0] == MAP_FAILED) {
+			err("Failed to MMAP CAPTURE buffer on plane0");
+			return -1;
+		}
+
+		vid->cap_buf_size[0] = buf.m.planes[0].length;
+	}
+
+	dbg("Succesfully mmapped %d CAPTURE buffers", n);
+
+	return 0;
+}
+
+int video_setup_output(struct instance *i, unsigned long codec,
+		       unsigned int size, int count)
+{
+	struct video *vid = &i->video;
+	struct v4l2_format fmt;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[OUT_PLANES];
+	int ret;
+	int n;
+
+	memzero(fmt);
+	fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	fmt.fmt.pix_mp.width = MAX_H264_WIDTH; // i->width;
+	fmt.fmt.pix_mp.height = MAX_H264_HEIGHT; //i->height;
+	fmt.fmt.pix_mp.pixelformat = codec;
+
+	ret = ioctl(vid->fd, VIDIOC_S_FMT, &fmt);
+	if (ret) {
+		err("Failed to set format on OUTPUT (%s)", strerror(errno));
+		return -1;
+	}
+
+	dbg("Setup decoding OUTPUT buffer size=%u (requested=%u)",
+	    fmt.fmt.pix_mp.plane_fmt[0].sizeimage, size);
+
+	vid->out_buf_size = fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
+
+	memzero(reqbuf);
+	reqbuf.count = count;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret) {
+		err("REQBUFS failed on OUTPUT queue");
+		return -1;
+	}
+
+	vid->out_buf_cnt = reqbuf.count;
+
+	dbg("Number of video decoder OUTPUT buffers is %d (requested %d)",
+	    vid->out_buf_cnt, count);
+
+	for (n = 0; n < vid->out_buf_cnt; n++) {
+		memzero(buf);
+		memset(planes, 0, sizeof(planes));
+		buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+		buf.memory = V4L2_MEMORY_MMAP;
+		buf.index = n;
+		buf.m.planes = planes;
+		buf.length = OUT_PLANES;
+
+		ret = ioctl(vid->fd, VIDIOC_QUERYBUF, &buf);
+		if (ret != 0) {
+			err("QUERYBUF failed on OUTPUT buffer");
+			return -1;
+		}
+
+		vid->out_buf_off[n] = buf.m.planes[0].m.mem_offset;
+		vid->out_buf_size = buf.m.planes[0].length;
+
+		vid->out_buf_addr[n] = mmap(NULL, buf.m.planes[0].length,
+					    PROT_READ | PROT_WRITE, MAP_SHARED,
+					    vid->fd,
+					    buf.m.planes[0].m.mem_offset);
+
+		if (vid->out_buf_addr[n] == MAP_FAILED) {
+			err("Failed to MMAP OUTPUT buffer");
+			return -1;
+		}
+
+		vid->out_buf_flag[n] = 0;
+	}
+
+	dbg("Succesfully mmapped %d OUTPUT buffers", n);
+
+	return 0;
+}
+
diff --git a/fileops.c b/fileops.c
new file mode 100644
index 0000000..c254567
--- /dev/null
+++ b/fileops.c
@@ -0,0 +1,60 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * File operations
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include "common.h"
+#include "fileops.h"
+
+int input_open(struct instance *i, char *name)
+{
+	struct stat in_stat;
+
+	i->in.fd = open(name, O_RDONLY);
+	if (!i->in.fd) {
+		err("Failed to open file: %s", i->in.name);
+		return -1;
+	}
+
+	fstat(i->in.fd, &in_stat);
+
+	i->in.size = in_stat.st_size;
+	i->in.offs = 0;
+	i->in.p = mmap(0, i->in.size, PROT_READ, MAP_SHARED, i->in.fd, 0);
+	if (i->in.p == MAP_FAILED) {
+		err("Failed to map input file");
+		return -1;
+	}
+
+	return 0;
+}
+
+void input_close(struct instance *i)
+{
+	munmap(i->in.p, i->in.size);
+	close(i->in.fd);
+}
+
diff --git a/fileops.h b/fileops.h
new file mode 100644
index 0000000..bdebe3e
--- /dev/null
+++ b/fileops.h
@@ -0,0 +1,34 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * File operations header file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#ifndef INCLUDE_FILEOPS_H
+#define INCLUDE_FILEOPS_H
+
+#include "common.h"
+
+/* Open and mmap the input file */
+int	input_open(struct instance *i, char *name);
+/* Unmap and close the input file */
+void	input_close(struct instance *i);
+
+#endif /* INCLUDE_FILEOPS_H */
+
diff --git a/main.c b/main.c
index 880afad..20d5bb3 100644
--- a/main.c
+++ b/main.c
@@ -1,1404 +1,503 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- * Main file of the application
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- * Copyright (c) 2015 Linaro Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <linux/input.h>
-#include <linux/videodev2.h>
-#include <media/msm_vidc.h>
-#include <sys/ioctl.h>
-#include <sys/signalfd.h>
-#include <signal.h>
-#include <poll.h>
-#include <pthread.h>
-#include <errno.h>
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Main file of the application
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ * Copyright (c) 2015 Linaro Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <linux/videodev2.h>
+#include "msm-v4l2-controls.h"
+#include <sys/ioctl.h>
+#include <sys/mman.h>
 #include <fcntl.h>
-#include <unistd.h>
-
-#include "args.h"
-#include "common.h"
-#include "video.h"
-#include "display.h"
-
-#define DBG_TAG "  main"
-
-#define av_err(errnum, fmt, ...) \
-	err(fmt ": %s", ##__VA_ARGS__, av_err2str(errnum))
-
-/* This is the size of the buffer for the compressed stream.
- * It limits the maximum compressed frame size. */
-#define STREAM_BUUFER_SIZE	(1024 * 1024)
-
-static void stream_close(struct instance *i);
-
-static const int event_type[] = {
-	V4L2_EVENT_MSM_VIDC_FLUSH_DONE,
-	V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_SUFFICIENT,
-	V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_INSUFFICIENT,
-	V4L2_EVENT_MSM_VIDC_SYS_ERROR,
-	V4L2_EVENT_MSM_VIDC_HW_OVERLOAD,
-	V4L2_EVENT_MSM_VIDC_HW_UNSUPPORTED,
-	V4L2_EVENT_MSM_VIDC_RELEASE_BUFFER_REFERENCE,
-	V4L2_EVENT_MSM_VIDC_RELEASE_UNQUEUED_BUFFER,
+#include <poll.h>
+#include <pthread.h>
+#include <semaphore.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <linux/fb.h>
+
+#include "args.h"
+#include "common.h"
+#include "fileops.h"
+#include "video.h"
+#include "parser.h"
+#include "dcfb.h"
+
+/* This is the size of the buffer for the compressed stream.
+ * It limits the maximum compressed frame size. */
+#define STREAM_BUUFER_SIZE	(1024 * 1024)
+
+/* The number of compress4ed stream buffers */
+#define STREAM_BUFFER_CNT	2
+
+/* The number of extra buffers for the decoded output.
+ * This is the number of buffers that the application can keep
+ * used and still enable video device to decode with the hardware. */
+#define RESULT_EXTRA_BUFFER_CNT 2
+
+static const int event_type[] = {
+	V4L2_EVENT_MSM_VIDC_FLUSH_DONE,
+	V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_SUFFICIENT,
+	V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_INSUFFICIENT,
+	V4L2_EVENT_MSM_VIDC_CLOSE_DONE,
+	V4L2_EVENT_MSM_VIDC_SYS_ERROR
+};
+
+dc_frame_info UserFrameBufferSize = {
+    .width = 1024,
+    .height = 600,
+    .stride = 4096,
 };
-
-static int
-subscribe_events(struct instance *i)
-{
-	const int n_events = sizeof(event_type) / sizeof(event_type[0]);
-	int idx;
-
-	for (idx = 0; idx < n_events; idx++) {
-		if (video_subscribe_event(i, event_type[idx]))
-			return -1;
-	}
-
-	return 0;
-}
-
-static struct fb *
-find_fb(struct instance *i, int group, int index)
-{
-	struct fb *fb;
-
-	list_for_each_entry(fb, &i->fb_list, link) {
-		if (fb->group == group && fb->index == index && fb->buffer)
-			return fb;
-	}
-
-	return NULL;
-}
-
-static int
-restart_capture(struct instance *i)
-{
-	struct video *vid = &i->video;
-	struct fb *fb, *next;
-	int n;
-
-	/*
-	 * Destroy window buffers that are not in use by the
-	 * wayland compositor; buffers in use will be destroyed
-	 * when the release callback is called
-	 */
-	list_for_each_entry_safe(fb, next, &i->fb_list, link) {
-		if (!fb->busy)
-			fb_destroy(fb);
-	}
-
-	/* Stop capture and release buffers */
-	if (vid->cap_buf_cnt > 0 && video_stop_capture(i))
-		return -1;
-
-	/* Setup capture queue with new parameters */
-	if (video_setup_capture(i, 4, i->width, i->height))
-		return -1;
-
-	/* Start streaming */
-	if (video_stream(i, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
-			 VIDIOC_STREAMON))
-		return -1;
-
-	/* Queue all capture buffers */
-	for (n = 0; n < vid->cap_buf_cnt; n++) {
-		if (video_queue_buf_cap(i, n))
-			return -1;
-	}
-
-	/*
-	 * Recreate the window frame buffers
-	 */
-	i->group++;
-
-	return 0;
-}
-
-static const char *
-colorspace_to_string(int cspace)
-{
-	switch (cspace) {
-	case MSM_VIDC_BT709_5:
-		return "bt709";
-	case MSM_VIDC_UNSPECIFIED:
-		return "unspecified";
-	case MSM_VIDC_BT470_6_M:
-		return "bt470m";
-	case MSM_VIDC_BT601_6_625:
-		return "bt601/625";
-	case MSM_VIDC_BT601_6_525:
-		return "bt601/525";
-	case MSM_VIDC_SMPTE_240M:
-		return "smpte240m";
-	case MSM_VIDC_GENERIC_FILM:
-		return "generic";
-	case MSM_VIDC_BT2020:
-		return "bt2020";
-	case MSM_VIDC_RESERVED_1:
-		return "reserved1";
-	case MSM_VIDC_RESERVED_2:
-		return "reserved2";
-	}
-	return "unknown";
-}
-
-static const char *
-depth_to_string(int depth)
-{
-	switch (depth) {
-	case MSM_VIDC_BIT_DEPTH_8:
-		return "8bits";
-	case MSM_VIDC_BIT_DEPTH_10:
-		return "10bits";
-	case MSM_VIDC_BIT_DEPTH_UNSUPPORTED:
-		return "unsupported";
-	}
-	return "unknown";
-}
-
-static const char *
-pic_struct_to_string(int pic)
-{
-	switch (pic) {
-	case MSM_VIDC_PIC_STRUCT_PROGRESSIVE:
-		return "progressive";
-	case MSM_VIDC_PIC_STRUCT_MAYBE_INTERLACED:
-		return "interlaced";
-	}
-	return "unknown";
-}
-
-static int
-handle_video_event(struct instance *i)
-{
-	struct v4l2_event event;
-
-	if (video_dequeue_event(i, &event))
-		return -1;
-
-	switch (event.type) {
-	case V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_INSUFFICIENT: {
-		unsigned int *ptr = (unsigned int *)event.u.data;
-		unsigned int height = ptr[0];
-		unsigned int width = ptr[1];
-
-		info("Port Reconfig received insufficient, new size %ux%u",
-		     width, height);
-
-		if (ptr[2] & V4L2_EVENT_BITDEPTH_FLAG) {
-			enum msm_vidc_pixel_depth depth = ptr[3];
-			info("  bit depth changed to %s",
-			     depth_to_string(depth));
-
-			switch (depth) {
-			case MSM_VIDC_BIT_DEPTH_10:
-				i->depth = 10;
-				break;
-			case MSM_VIDC_BIT_DEPTH_8:
-				i->depth = 8;
-				break;
-			default:
-				i->depth = 0;
-				break;
-			}
-		}
-
-		if (ptr[2] & V4L2_EVENT_PICSTRUCT_FLAG) {
-			unsigned int pic_struct = ptr[4];
-			info("  interlacing changed to %s",
-			     pic_struct_to_string(pic_struct));
-
-			if (pic_struct == MSM_VIDC_PIC_STRUCT_MAYBE_INTERLACED)
-				i->interlaced = 1;
-			else
-				i->interlaced = 0;
-		}
-
-		if (ptr[2] & V4L2_EVENT_COLOUR_SPACE_FLAG) {
-			unsigned int cspace = ptr[5];
-			info("  colorspace changed to %s",
-			     colorspace_to_string(cspace));
-		}
-
-		i->width = width;
-		i->height = height;
-		i->reconfigure_pending = 1;
-
-		/* flush capture queue, we will reconfigure it when flush
-		 * done event is received */
-		video_flush(i, V4L2_QCOM_CMD_FLUSH_CAPTURE);
-		break;
-	}
-	case V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_SUFFICIENT:
-		dbg("Setting changed sufficient");
-		break;
-	case V4L2_EVENT_MSM_VIDC_FLUSH_DONE: {
-		unsigned int *ptr = (unsigned int *)event.u.data;
-		unsigned int flags = ptr[0];
-
-		if (flags & V4L2_QCOM_CMD_FLUSH_CAPTURE)
-			dbg("Flush Done received on CAPTURE queue");
-		if (flags & V4L2_QCOM_CMD_FLUSH_OUTPUT)
-			dbg("Flush Done received on OUTPUT queue");
-
-		if (i->reconfigure_pending) {
-			dbg("Reconfiguring output");
-			restart_capture(i);
-			i->reconfigure_pending = 0;
-		}
-		break;
-	}
-	case V4L2_EVENT_MSM_VIDC_SYS_ERROR:
-		dbg("SYS Error received");
-		break;
-	case V4L2_EVENT_MSM_VIDC_HW_OVERLOAD:
-		dbg("HW Overload received");
-		break;
-	case V4L2_EVENT_MSM_VIDC_HW_UNSUPPORTED:
-		dbg("HW Unsupported received");
-		break;
-	case V4L2_EVENT_MSM_VIDC_RELEASE_BUFFER_REFERENCE:
-		dbg("Release buffer reference");
-		break;
-	case V4L2_EVENT_MSM_VIDC_RELEASE_UNQUEUED_BUFFER:
-		dbg("Release unqueued buffer");
-		break;
-	default:
-		dbg("unknown event type occurred %x", event.type);
-		break;
-	}
-
-	return 0;
-}
-
-static void
-cleanup(struct instance *i)
-{
-	stream_close(i);
-	if (i->window)
-		window_destroy(i->window);
-	if (i->display)
-		display_destroy(i->display);
-	if (i->sigfd != 1)
-		close(i->sigfd);
-	if (i->video.fd)
-		video_close(i);
-}
-
-struct ts_entry {
-	uint64_t pts;
-	uint64_t dts;
-	uint64_t duration;
-	uint64_t base;
-	struct list_head link;
-};
-
-#define TIMESTAMP_NONE	((uint64_t)-1)
-
-static struct ts_entry *
-ts_insert(struct video *vid, uint64_t pts, uint64_t dts, uint64_t duration,
-	  uint64_t base)
-{
-	struct ts_entry *l;
-
-	l = malloc(sizeof (*l));
-	if (!l)
-		return NULL;
-
-	l->pts = pts;
-	l->dts = dts;
-	l->duration = duration;
-	l->base = base;
-
-	list_add_tail(&l->link, &vid->pending_ts_list);
-
-	return l;
-}
-
-static void
-ts_remove(struct ts_entry *l)
-{
-	list_del(&l->link);
-	free(l);
-}
-
-static int
-parse_frame(struct instance *i, AVPacket *pkt)
-{
-	int ret;
-
-	if (!i->bsf_data_pending) {
-		ret = av_read_frame(i->avctx, pkt);
-		if (ret < 0)
-			return ret;
-
-		if (pkt->stream_index != i->stream->index) {
-			av_packet_unref(pkt);
-			return AVERROR(EAGAIN);
-		}
-
-		if (i->bsf) {
-			ret = av_bsf_send_packet(i->bsf, pkt);
-			if (ret < 0)
-				return ret;
-
-			i->bsf_data_pending = 1;
-		}
-	}
-
-	if (i->bsf) {
-		ret = av_bsf_receive_packet(i->bsf, pkt);
-		if (ret == AVERROR(EAGAIN))
-			i->bsf_data_pending = 0;
-
-		if (ret < 0)
-			return ret;
-	}
-
-	return 0;
-}
-
-static void
-finish(struct instance *i)
-{
-	pthread_mutex_lock(&i->lock);
-	i->finish = 1;
-	pthread_cond_signal(&i->cond);
-	pthread_mutex_unlock(&i->lock);
-}
-
-static int
-send_eos(struct instance *i, int buf_index)
-{
-	struct video *vid = &i->video;
-	struct timeval tv;
-
-	tv.tv_sec = 0;
-	tv.tv_usec = 0;
-
-	if (video_queue_buf_out(i, buf_index, 0,
-				V4L2_QCOM_BUF_FLAG_EOS |
-				V4L2_QCOM_BUF_TIMESTAMP_INVALID, tv) < 0)
-		return -1;
-
-	vid->out_buf_flag[buf_index] = 1;
-
-	return 0;
-}
-
-static char *
-dump_pkt(const uint8_t *data, size_t size)
-{
-	static char *buf;
-	static size_t buf_size;
-	size_t s = size * 3 + 1;
-
-	if (!buf || buf_size < s) {
-		char *old = buf;
-		s = (s + 4095) & ~4095;
-		buf = realloc(old, s);
-		if (!buf) {
-			free(old);
-			return NULL;
-		}
-		buf_size = s;
-	}
-
-	for (size_t i = 0; i < size; i++) {
-		sprintf(buf + i * 3, "%c%02x",
-			i % 32 == 0 ? '\n' : ' ', data[i]);
-	}
-
-	buf[s - 1] = 0;
-
-	return buf;
-}
-
-
-/*
- * Escape start codes in BDU
- */
-static int
-rbdu_escape(uint8_t *dst, int dst_size, const uint8_t *src, int src_size)
-{
-	uint8_t *dstp = dst;
-	const uint8_t *srcp = src;
-	const uint8_t *end = src + src_size;
-	int count = 0;
-
-	while (srcp < end) {
-		if (count == 2 && *srcp <= 0x03) {
-			*dstp++ = 0x03;
-			count = 0;
-		}
-
-		if (*srcp == 0)
-			count++;
-		else
-			count = 0;
-
-		*dstp++ = *srcp++;
-	}
-
-	return dstp - dst;
-}
-
-/*
- * Transform RBDU (raw bitstream decodable units)
- *  into an EBDU (encapsulated bitstream decodable units)
- */
-static int
-vc1_write_bdu(uint8_t *dst, int dst_size,
-	      uint8_t *bdu, int bdu_size,
-	      uint8_t type)
-{
-	int len;
-
-	/* add start code */
-	dst[0] = 0x00;
-	dst[1] = 0x00;
-	dst[2] = 0x01;
-	dst[3] = type;
-	len = 4;
-
-	/* escape start codes */
-	len += rbdu_escape(dst + len, dst_size - len, bdu, bdu_size);
-
-	/* add flushing byte at the end of the BDU */
-	dst[len++] = 0x80;
-
-	return len;
-}
-
-static int
-vc1_find_sc(const uint8_t *data, int size)
-{
-	for (int i = 0; i < size - 4; i++) {
-		if (data[i + 0] == 0x00 &&
-		    data[i + 1] == 0x00 &&
-		    data[i + 2] == 0x01)
-			return i;
-	}
-
-	return -1;
-}
-
-static int
-write_sequence_header_vc1(struct instance *i, uint8_t *data, int size)
-{
-	AVCodecParameters *codecpar = i->stream->codecpar;
-	int n;
-
-	if (codecpar->extradata_size == 0) {
-		dbg("no codec data, skip sequence header generation");
-		return 0;
-	}
-
-	if (codecpar->extradata_size == 4 || codecpar->extradata_size == 5) {
-		/* Simple/Main Profile ASF header */
-		return vc1_write_bdu(data, size,
-				     codecpar->extradata,
-				     codecpar->extradata_size,
-				     0x0f);
-	}
-
-	if (codecpar->extradata_size == 36 && codecpar->extradata[3] == 0xc5) {
-		/* Annex L Sequence Layer */
-		if (size < codecpar->extradata_size)
-			return -1;
-
-		memcpy(data, codecpar->extradata, codecpar->extradata_size);
-		return codecpar->extradata_size;
-	}
-
-	n = vc1_find_sc(codecpar->extradata, codecpar->extradata_size);
-	if (n >= 0) {
-		/* BDU in header */
-		if (size < codecpar->extradata_size - n)
-			return -1;
-
-		memcpy(data, codecpar->extradata + n,
-		       codecpar->extradata_size - n);
-		return codecpar->extradata_size - n;
-	}
-
-	err("cannot parse VC1 codec data");
-
-	return -1;
-}
-
-static int
-write_sequence_header(struct instance *i, uint8_t *data, int size)
-{
-	AVCodecParameters *codecpar = i->stream->codecpar;
-
-	switch (codecpar->codec_id) {
-	case AV_CODEC_ID_WMV3:
-	case AV_CODEC_ID_VC1:
-		return write_sequence_header_vc1(i, data, size);
-	default:
-		return 0;
-	}
-}
-
-static int
-send_pkt(struct instance *i, int buf_index, AVPacket *pkt)
-{
-	struct video *vid = &i->video;
-	struct timeval tv;
-	uint64_t pts, dts, duration, start_time;
-	int flags;
-	int size;
-	uint8_t *data;
-	const char *hex;
-	AVRational vid_timebase;
-	AVRational v4l_timebase = { 1, 1000000 };
-	AVCodecParameters *codecpar = i->stream->codecpar;
-
-	data = (uint8_t *)vid->out_buf_addr[buf_index];
-	size = 0;
-
-	if (i->need_header) {
-		int n = write_sequence_header(i, data, vid->out_buf_size);
-		if (n > 0)
-			size += n;
-
-		switch (codecpar->codec_id) {
-		case AV_CODEC_ID_WMV3:
-		case AV_CODEC_ID_VC1:
-			if (vc1_find_sc(pkt->data, MIN(10, pkt->size)) < 0)
-				i->insert_sc = 1;
-			break;
-		default:
-			break;
-		}
-
-		i->need_header = 0;
-	}
-
-	if ((codecpar->codec_id == AV_CODEC_ID_WMV3 ||
-	     codecpar->codec_id == AV_CODEC_ID_VC1) &&
-	    i->insert_sc) {
-		size += vc1_write_bdu(data + size, vid->out_buf_size - size,
-				      pkt->data, pkt->size, 0x0d);
-	} else {
-		memcpy(data + size, pkt->data, pkt->size);
-		size += pkt->size;
-	}
-
-	flags = 0;
-
-	vid_timebase = i->stream->time_base;
-
-	start_time = 0;
-	if (i->stream->start_time != AV_NOPTS_VALUE)
-		start_time = av_rescale_q(i->stream->start_time,
-					  vid_timebase, v4l_timebase);
-
-	pts = TIMESTAMP_NONE;
-	if (pkt->pts != AV_NOPTS_VALUE)
-		pts = av_rescale_q(pkt->pts, vid_timebase, v4l_timebase);
-
-	dts = TIMESTAMP_NONE;
-	if (pkt->dts != AV_NOPTS_VALUE)
-		dts = av_rescale_q(pkt->dts, vid_timebase, v4l_timebase);
-
-	duration = TIMESTAMP_NONE;
-	if (pkt->duration) {
-		duration = av_rescale_q(pkt->duration,
-					vid_timebase, v4l_timebase);
-	}
-
-	if (debug_level > 3)
-		hex = dump_pkt(data, size);
-	else
-		hex = "";
-
-	dbg("input size=%d pts=%" PRIi64 " dts=%" PRIi64 " duration=%" PRIu64
-	     " start_time=%" PRIi64 "%s", size, pts, dts, duration,
-	     start_time, hex);
-
-	if (pts != TIMESTAMP_NONE) {
-		tv.tv_sec = pts / 1000000;
-		tv.tv_usec = pts % 1000000;
-	} else {
-		flags |= V4L2_QCOM_BUF_TIMESTAMP_INVALID;
-		tv.tv_sec = 0;
-		tv.tv_usec = 0;
-	}
-
-	if ((pkt->flags & AV_PKT_FLAG_KEY) &&
-	    pts != TIMESTAMP_NONE && dts != TIMESTAMP_NONE)
-		vid->pts_dts_delta = pts - dts;
-
-	if (video_queue_buf_out(i, buf_index, size, flags, tv) < 0)
-		return -1;
-
-	pthread_mutex_lock(&i->lock);
-	ts_insert(vid, pts, dts, duration, start_time);
-	pthread_mutex_unlock(&i->lock);
-
-	vid->out_buf_flag[buf_index] = 1;
-
-	return 0;
-}
-
-static int
-get_buffer_unlocked(struct instance *i)
-{
-	struct video *vid = &i->video;
-
-	for (int n = 0; n < vid->out_buf_cnt; n++) {
-		if (!vid->out_buf_flag[n])
-			return n;
-	}
-
-	return -1;
-}
-
-/* This threads is responsible for parsing the stream and
- * feeding video decoder with consecutive frames to decode */
-static void *
-parser_thread_func(void *args)
-{
-	struct instance *i = (struct instance *)args;
-	AVPacket pkt;
-	int buf, parse_ret;
-
-	dbg("Parser thread started");
-
-	av_init_packet(&pkt);
-
-	while (1) {
-		parse_ret = parse_frame(i, &pkt);
-		if (parse_ret == AVERROR(EAGAIN))
-			continue;
-
-
-		buf = -1;
-
-		pthread_mutex_lock(&i->lock);
-		while (!i->finish && (buf = get_buffer_unlocked(i)) < 0)
-			pthread_cond_wait(&i->cond, &i->lock);
-		pthread_mutex_unlock(&i->lock);
-
-		if (buf < 0) {
-			/* decoding stopped before parsing ended, abort */
-			break;
-		}
-
-		if (parse_ret < 0) {
-			if (parse_ret == AVERROR_EOF)
-				dbg("Queue end of stream");
-			else
-				av_err(parse_ret, "Parsing failed");
-
-			send_eos(i, buf);
-			break;
-		}
-
-		if (send_pkt(i, buf, &pkt) < 0)
-			break;
-
-		av_packet_unref(&pkt);
-	}
-
-	av_packet_unref(&pkt);
-
-	dbg("Parser thread finished");
-
-	return NULL;
-}
-
-static void
-buffer_released(struct fb *fb, void *data)
-{
-	struct instance *i = data;
-	int n = fb->index;
-
-	if (fb->group != i->group) {
-		fb_destroy(fb);
-		return;
-	}
-
-	if (!i->reconfigure_pending)
-		video_queue_buf_cap(i, n);
-}
-
-static struct fb *
-get_fb(struct instance *i, int n)
-{
-	struct video *vid = &i->video;
-	struct fb *fb;
-
-	fb = find_fb(i, i->group, n);
-	if (!fb) {
-		fb = window_create_buffer(i->window, i->group, n,
-					  vid->cap_buf_fd[n],
-					  vid->cap_buf_format,
-					  vid->cap_w, vid->cap_h,
-					  vid->cap_planes_count,
-					  vid->cap_plane_off,
-					  vid->cap_plane_stride);
-		if (fb)
-			list_add_tail(&fb->link, &i->fb_list);
-	}
-
-	return fb;
-}
-
-static int
-handle_video_capture(struct instance *i)
-{
-	struct video *vid = &i->video;
-	struct timeval tv;
-	uint32_t flags;
-	uint64_t pts;
-	unsigned int bytesused;
-	struct msm_vidc_extradata_header *extradata;
-	bool busy;
-	int ret, n;
-
-	/* capture buffer is ready */
-
-	ret = video_dequeue_capture(i, &n, &bytesused, &flags, &tv, &extradata);
+
+char *UserMemFb = NULL;
+
+static int subscribe_for_events(int fd)
+{
+	int size_event = sizeof(event_type) / sizeof(event_type[0]);
+	struct v4l2_event_subscription sub;
+	int i, ret;
+
+	for (i = 0; i < size_event; i++) {
+		memset(&sub, 0, sizeof(sub));
+		sub.type = event_type[i];
+		ret = ioctl(fd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+		if (ret < 0)
+			err("cannot subscribe for event type %d (%s)",
+				sub.type, strerror(errno));
+	}
+
+	return 0;
+}
+
+static int handle_v4l_events(struct video *vid)
+{
+	struct v4l2_event event;
+	int ret;
+
+	memset(&event, 0, sizeof(event));
+	ret = ioctl(vid->fd, VIDIOC_DQEVENT, &event);
+	if (ret < 0) {
+		err("vidioc_dqevent failed (%s) %d", strerror(errno), -errno);
+		return -errno;
+	}
+
+	switch (event.type) {
+	case V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_INSUFFICIENT:
+		dbg("Port Reconfig recieved insufficient\n");
+		break;
+	case V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_SUFFICIENT:
+		dbg("Setting changed sufficient\n");
+		break;
+	case V4L2_EVENT_MSM_VIDC_FLUSH_DONE:
+		dbg("Flush Done Recieved \n");
+		break;
+	case V4L2_EVENT_MSM_VIDC_CLOSE_DONE:
+		dbg("Close Done Recieved \n");
+		break;
+	case V4L2_EVENT_MSM_VIDC_SYS_ERROR:
+		dbg("SYS Error Recieved \n");
+		break;
+	default:
+		dbg("unknown event type occurred %x\n", event.type);
+		break;
+	}
+
+	return 0;
+}
+
+void cleanup(struct instance *i)
+{
+	if (i->video.fd)
+		video_close(i);
+	if (i->in.fd)
+		input_close(i);
+}
+
+int extract_and_process_header(struct instance *i)
+{
+	int used = 0, fs;
+	int ret;
+
+	ret = i->parser.func(&i->parser.ctx,
+			     i->in.p + i->in.offs,
+			     i->in.size - i->in.offs,
+			     i->video.out_buf_addr[0],
+			     i->video.out_buf_size,
+			     &used, &fs, 1);
+	if (ret != 0) {
+		err("Failed to extract header from stream");
+		return -1;
+	}
+
+	i->in.offs += used;
+
+	ret = video_queue_buf_out(i, 0, fs);
+	if (ret)
+		return -1;
+
+	dbg("queued output buffer %d", 0);
+
+	i->video.out_buf_flag[0] = 1;
+
+	ret = video_stream(i, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE,
+			   VIDIOC_STREAMON);
+	if (ret)
+		return -1;
+
+	return 0;
+}
+
+int save_frame(struct instance *i, const void *buf, unsigned int size)
+{
+	mode_t mode = S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH;
+	char filename[64];
+	int fd;
+	int ret;
+	static unsigned int frame_num = 0;
+
+	if (!i->save_frames)
+		return 0;
+
+	if (!i->save_path)
+		ret = sprintf(filename, "/mnt/frame%04d.nv12", frame_num);
+	else
+		ret = sprintf(filename, "%s/frame%04d.nv12", i->save_path,
+			      frame_num);
+	if (ret < 0) {
+		err("sprintf fail (%s)", strerror(errno));
+		return -1;
+	}
+
+	dbg("create file %s", filename);
+
+	fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC | O_SYNC, mode);
+	if (fd < 0) {
+		err("cannot open file (%s)", strerror(errno));
+		return -1;
+	}
+
+	ret = write(fd, buf, size);
+	if (ret < 0) {
+		err("cannot write to file (%s)", strerror(errno));
+		return -1;
+	}
+
+	close(fd);
+
+	frame_num++;
+
+	return 0;
+}
+
+/* This threads is responsible for parsing the stream and
+ * feeding video decoder with consecutive frames to decode */
+void *parser_thread_func(void *args)
+{
+	struct instance *i = (struct instance *)args;
+	struct video *vid = &i->video;
+	int used, fs, n;
+	int ret;
+
+	dbg("Parser thread started");
+
+	while (!i->error && !i->finish && !i->parser.finished) {
+		n = 0;
+		pthread_mutex_lock(&i->lock);
+		while (n < vid->out_buf_cnt && vid->out_buf_flag[n])
+			n++;
+		pthread_mutex_unlock(&i->lock);
+
+		if (n < vid->out_buf_cnt && !i->parser.finished) {
+
+			//printf("%s %d, n = %d, %d, %d, offset=0x%x, left=%d\n", 
+			//	__func__, __LINE__, n, vid->out_buf_cnt, i->parser.finished, 
+			//	i->in.offs, i->in.size - i->in.offs);		
+
+			ret = i->parser.func(&i->parser.ctx,
+					     i->in.p + i->in.offs,
+					     i->in.size - i->in.offs,
+					     vid->out_buf_addr[n],
+					     vid->out_buf_size,
+					     &used, &fs, 0);
+
+			if ((ret != 0) || (i->in.offs + 4 >= i->in.size) || (fs == 0)) {
+				if (ret != 0)
+					dbg("Parser has error, abort!\n");
+				else
+					dbg("Parser has extracted all frames");
+				i->parser.finished = 1;
+				fs = 0;
+				break;
+			}
+
+			// dbg("Extracted frame of size %d", fs);
+
+			pthread_mutex_lock(&i->lock);
+			vid->out_buf_flag[n] = 1;
+			pthread_mutex_unlock(&i->lock);
+
+			// dbg("queued output buffer %d", n);
+
+			ret = video_queue_buf_out(i, n, fs);
+			i->in.offs += used;
+		}
+	}
+
+	dbg("Parser thread finished");
+
+	return NULL;
+}
+
+void *main_thread_func(void *args)
+{
+	struct instance *i = (struct instance *)args;
+	struct video *vid = &i->video;
+	struct pollfd pfd;
+	short revents;
+	int ret, n, finished;
+
+	dbg("main thread started");
+
+	pfd.fd = vid->fd;
+	pfd.events = POLLIN | POLLRDNORM | POLLOUT | POLLWRNORM |
+		     POLLRDBAND | POLLPRI;
+
+	while (1) {
+		ret = poll(&pfd, 1, 2000);
+		if (!ret) {
+			err("poll timeout");
+			break;
+		} else if (ret < 0) {
+			err("poll error");
+			break;
+		}
+
+		revents = pfd.revents;
+
+		if (revents & (POLLIN | POLLRDNORM)) {
+			unsigned int bytesused;
+
+			/* capture buffer is ready */
+
+			ret = video_dequeue_capture(i, &n, &finished,
+						    &bytesused);
+			if (ret < 0)
+				goto next_event;
+
+			vid->cap_buf_flag[n] = 0;
+
+			// info("decoded frame %ld", vid->total_captured);
+
+			if (finished)
+				break;
+
+			vid->total_captured++;
+
+			//save_frame(i, (void *)vid->cap_buf_addr[n][0],
+			//	   bytesused);
+
+			ret = video_queue_buf_cap(i, n);
+			if (!ret)
+				vid->cap_buf_flag[n] = 1;
+		}
+
+next_event:
+		if (revents & (POLLOUT | POLLWRNORM)) {
+
+			ret = video_dequeue_output(i, &n);
+			if (ret < 0) {
+				err("dequeue output buffer fail");
+			} else {
+				pthread_mutex_lock(&i->lock);
+				vid->out_buf_flag[n] = 0;
+				pthread_mutex_unlock(&i->lock);
+			}
+
+			// dbg("dequeued output buffer %d", n);
+		}
+
+		if (revents & POLLPRI) {
+			dbg("v4l2 event");
+			handle_v4l_events(vid);
+		}
+	}
+
+	dbg("main thread finished");
+
+	return NULL;
+}
+
+int fb_open(struct instance *i, char *name)
+{
+	struct fb_var_screeninfo FBVar;
+	struct fb_fix_screeninfo FBFix;
+	unsigned int ScreenSizeFb;
+	unsigned int OneframeSizeFb;
+	int ret;
+
+	i->fb.fd = open(name, O_RDWR, 0);
+	if (i->fb.fd < 0) {
+		err("Failed to open fb device: %s", name);
+		return -1;
+	}
+
+	ret = ioctl(i->fb.fd, FBIOGET_VSCREENINFO, &FBVar);
 	if (ret < 0) {
-		err("dequeue capture buffer fail");
-		return ret;
-	}
-
-	if (flags & V4L2_QCOM_BUF_TIMESTAMP_INVALID)
-		pts = TIMESTAMP_NONE;
-	else
-		pts = ((uint64_t)tv.tv_sec) * 1000000 + tv.tv_usec;
-
-	busy = false;
-
-	if (bytesused > 0) {
-		struct ts_entry *l, *min = NULL;
-		int pending = 0;
-
-		vid->total_captured++;
-
-		pthread_mutex_lock(&i->lock);
-
-		/* PTS are expected to be monotonically increasing,
-		 * so when unknown use the lowest pending DTS */
-		list_for_each_entry(l, &vid->pending_ts_list, link) {
-			if (l->dts == TIMESTAMP_NONE)
-				continue;
-			if (min == NULL || min->dts > l->dts)
-				min = l;
-			pending++;
-		}
-
-		if (min) {
-			dbg("pending %d min pts %" PRIi64
-			    " dts %" PRIi64
-			    " duration %" PRIi64, pending,
-			    min->pts, min->dts, min->duration);
-		}
-
-		if (pts == TIMESTAMP_NONE) {
-			dbg("no pts on frame");
-			if (min && vid->pts_dts_delta != TIMESTAMP_NONE) {
-				dbg("reuse dts %" PRIu64
-				    " delta %" PRIu64,
-				    min->dts, vid->pts_dts_delta);
-				pts = min->dts + vid->pts_dts_delta;
-			}
-		}
-
-		if (pts == TIMESTAMP_NONE) {
-			if (min && vid->cap_last_pts != TIMESTAMP_NONE)
-				pts = vid->cap_last_pts + min->duration;
-			else
-				pts = 0;
-
-			dbg("guessing pts %" PRIu64, pts);
-		}
-
-		vid->cap_last_pts = pts;
-
-		if (min != NULL) {
-			pts -= min->base;
-			ts_remove(min);
-		}
-
-		pthread_mutex_unlock(&i->lock);
-
-		if (i->window) {
-			struct fb *fb = get_fb(i, n);
-			if (!fb) {
-				err("could not get framebuffer for "
-				    "video buffer %d", n);
-				return -1;
-			}
-
-			info("show buffer pts=%" PRIu64, pts);
-
-			fb_apply_extradata(fb, extradata);
-			window_show_buffer(i->window, fb,
-					   buffer_released, i);
-			busy = true;
-		}
-
-		i->prerolled = 1;
-
+	    printf("FBIOGET_VSCREENINFO failed!\n");
+	    return -1;
 	}
-
-	if (!busy && !i->reconfigure_pending)
-		video_queue_buf_cap(i, n);
-
-	if (flags & V4L2_QCOM_BUF_FLAG_EOS) {
-		info("End of stream");
-		finish(i);
-	}
-
-	return 0;
-}
-
-static int
-handle_video_output(struct instance *i)
-{
-	struct video *vid = &i->video;
-	int ret, n;
-
-	ret = video_dequeue_output(i, &n);
+
+#if 0
+	ret = ioctl(i->fb.fd, FBIOGET_FSCREENINFO, &FBFix);
 	if (ret < 0) {
-		err("dequeue output buffer fail");
-		return ret;
-	}
-
-	pthread_mutex_lock(&i->lock);
-	vid->out_buf_flag[n] = 0;
-	pthread_cond_signal(&i->cond);
-	pthread_mutex_unlock(&i->lock);
-
-	return 0;
-}
-
-static int
-handle_signal(struct instance *i)
-{
-	struct signalfd_siginfo siginfo;
-	sigset_t sigmask;
-
-	if (read(i->sigfd, &siginfo, sizeof (siginfo)) < 0) {
-		perror("signalfd/read");
+	    printf("FBIOGET_FSCREENINFO failed!\n");
+	    return -1;
+	}
+
+	/* framebuffer info */
+	OneframeSizeFb = FBVar.xres * FBVar.yres * FBVar.bits_per_pixel / 8;
+	ScreenSizeFb = FBVar.xres * FBVar.yres * (FBVar.yres_virtual / FBVar.yres) * FBVar.bits_per_pixel / 8;
+	UserMemFb = (char *)mmap(NULL, ScreenSizeFb, PROT_READ | PROT_WRITE, MAP_SHARED, i->fb.fd, 0);
+	if (UserMemFb == NULL) {
+		printf("fb can't mmap!\n");
 		return -1;
 	}
-
-	sigemptyset(&sigmask);
-	sigaddset(&sigmask, siginfo.ssi_signo);
-	sigprocmask(SIG_UNBLOCK, &sigmask, NULL);
-
-	finish(i);
-
-	return 0;
-}
-
-static int
-setup_signal(struct instance *i)
-{
-	sigset_t sigmask;
-	int fd;
-
-	sigemptyset(&sigmask);
-	sigaddset(&sigmask, SIGINT);
-	sigaddset(&sigmask, SIGTERM);
-
-	fd = signalfd(-1, &sigmask, SFD_CLOEXEC);
-	if (fd < 0) {
-		perror("signalfd");
-		return -1;
-	}
-
-	sigprocmask(SIG_BLOCK, &sigmask, NULL);
-	i->sigfd = fd;
-
-	return 0;
-}
-
-enum {
-	EV_VIDEO,
-	EV_DISPLAY,
-	EV_STDIN,
-	EV_SIGNAL,
-	EV_COUNT
-};
-
-static int
-kbd_init(struct instance *i)
-{
-	struct termios newt;
-
-	if (tcgetattr(STDIN_FILENO, &i->stdin_termios) < 0)
-		return -1;
-
-	newt = i->stdin_termios;
-	newt.c_lflag &= ~ICANON;
-	newt.c_lflag &= ~ECHO;
-
-	if (tcsetattr(STDIN_FILENO, TCSANOW, &newt) < 0)
-		return -1;
-
-	i->stdin_valid = 1;
-
-	return STDIN_FILENO;
-}
-
-static int
-kbd_handle_key(struct instance *i)
-{
-	uint8_t key[3];
-	int ret;
-
-	ret = read(STDIN_FILENO, key, 3);
-	if (ret < 0)
-		return -1;
-
-	if (key[0] == 's') {
-		info("Frame Step");
-		i->prerolled = 0;
-	}
-
-	return 0;
-}
-
-static void
-kbd_shutdown(struct instance *i)
-{
-	if (i->stdin_valid)
-		tcsetattr(STDIN_FILENO, TCSANOW, &i->stdin_termios);
-}
-
-void main_loop(struct instance *i)
-{
-	struct video *vid = &i->video;
-	struct wl_display *wl_display = NULL;
-	struct pollfd pfd[EV_COUNT];
-	int ev[EV_COUNT];
-	short revents;
-	int nfds = 0;
-	int ret;
-
-	dbg("main thread started");
-
-	for (int i = 0; i < EV_COUNT; i++)
-		ev[i] = -1;
-
-	memset(pfd, 0, sizeof (pfd));
-
-	pfd[nfds].fd = vid->fd;
-	pfd[nfds].events = POLLOUT | POLLWRNORM | POLLPRI;
-	ev[EV_VIDEO] = nfds++;
-
-	if (i->display) {
-		wl_display = display_get_wl_display(i->display);
-		pfd[nfds].fd = wl_display_get_fd(wl_display);
-		pfd[nfds].events = POLLIN;
-		ev[EV_DISPLAY] = nfds++;
-	}
-
-	ret = kbd_init(i);
-	if (ret >= 0) {
-		pfd[nfds].fd = ret;
-		pfd[nfds].events = POLLIN;
-		ev[EV_STDIN] = nfds++;
-	}
-
-	if (i->sigfd != -1) {
-		pfd[nfds].fd = i->sigfd;
-		pfd[nfds].events = POLLIN;
-		ev[EV_SIGNAL] = nfds++;
-	}
-
-	while (!i->finish) {
-		if (i->display) {
-			if (!display_is_running(i->display))
-				break;
-
-			while (wl_display_prepare_read(wl_display) != 0)
-				wl_display_dispatch_pending(wl_display);
-
-			ret = wl_display_flush(wl_display);
-			if (ret < 0) {
-				if (errno == EAGAIN)
-					pfd[ev[EV_DISPLAY]].events |= POLLOUT;
-				else if (errno != EPIPE) {
-					err("wl_display_flush: %m");
-					wl_display_cancel_read(wl_display);
-					break;
-				}
-			}
-		}
-
-		if (i->paused && i->prerolled)
-			pfd[ev[EV_VIDEO]].events &= ~(POLLIN | POLLRDNORM);
-		else
-			pfd[ev[EV_VIDEO]].events |= POLLIN | POLLRDNORM;
-
-		ret = poll(pfd, nfds, -1);
-		if (ret <= 0) {
-			err("poll error");
-			break;
-		}
-
-		if (i->display) {
-			ret = wl_display_read_events(wl_display);
-			if (ret < 0) {
-				err("wl_display_read_events: %m");
-				break;
-			}
-
-			ret = wl_display_dispatch_pending(wl_display);
-			if (ret < 0) {
-				err("wl_display_dispatch_pending: %m");
-				break;
-			}
-		}
-
-		for (int idx = 0; idx < nfds; idx++) {
-			revents = pfd[idx].revents;
-			if (!revents)
-				continue;
-
-			if (idx == ev[EV_VIDEO]) {
-				if (revents & (POLLIN | POLLRDNORM))
-					handle_video_capture(i);
-				if (revents & (POLLOUT | POLLWRNORM))
-					handle_video_output(i);
-				if (revents & POLLPRI)
-					handle_video_event(i);
-
-			} else if (idx == ev[EV_DISPLAY]) {
-				if (revents & POLLOUT)
-					pfd[ev[EV_DISPLAY]].events &= ~POLLOUT;
-
-			} else if (idx == ev[EV_STDIN]) {
-				kbd_handle_key(i);
-				break;
-
-			} else if (idx == ev[EV_SIGNAL]) {
-				handle_signal(i);
-				break;
-			}
-		}
-	}
-
-	kbd_shutdown(i);
-
-	dbg("main thread finished");
-}
-
-static void
-handle_window_key(struct window *window, uint32_t time, uint32_t key,
-		  enum wl_keyboard_key_state state)
-{
-	struct instance *i = window_get_user_data(window);
-
-	if (state != WL_KEYBOARD_KEY_STATE_PRESSED)
-		return;
-
-	switch (key) {
-	case KEY_ESC:
-		finish(i);
-		break;
-
-	case KEY_SPACE:
-		info("%s", i->paused ? "Resume" : "Pause");
-		i->paused = !i->paused;
-		if (i->paused)
-			av_read_pause(i->avctx);
-		else
-			av_read_play(i->avctx);
-		break;
-
-	case KEY_S:
-		info("Frame Step");
-		i->prerolled = 0;
-		break;
-
-	case KEY_F:
-		if (i->window)
-			window_toggle_fullscreen(i->window);
-		break;
-	}
-}
-
-static int
-setup_display(struct instance *i)
-{
-	AVRational ar;
-
-	i->display = display_create();
-	if (!i->display)
-		return -1;
-
-	i->window = display_create_window(i->display);
-	if (!i->window)
-		return -1;
-
-	window_set_user_data(i->window, i);
-	window_set_key_callback(i->window, handle_window_key);
-
-	ar = av_guess_sample_aspect_ratio(i->avctx, i->stream, NULL);
-	window_set_aspect_ratio(i->window, ar.num, ar.den);
-
-	if (i->fullscreen)
-		window_toggle_fullscreen(i->window);
-
-	return 0;
-}
-
-static void
-stream_close(struct instance *i)
-{
-	i->stream = NULL;
-	if (i->bsf)
-		av_bsf_free(&i->bsf);
-	if (i->avctx)
-		avformat_close_input(&i->avctx);
-}
-
-static int
-get_av_log_level(void)
-{
-	if (debug_level >= 5)
-		return AV_LOG_TRACE;
-	if (debug_level >= 4)
-		return AV_LOG_DEBUG;
-	if (debug_level >= 3)
-		return AV_LOG_VERBOSE;
-	if (debug_level >= 2)
-		return AV_LOG_INFO;
-	if (debug_level >= 1)
-		return AV_LOG_ERROR;
-	return AV_LOG_QUIET;
-}
-
-static int
-stream_open(struct instance *i)
-{
-	const AVBitStreamFilter *filter;
-	AVCodecParameters *codecpar;
-	AVRational framerate;
-	int codec;
-	int ret;
-
-	av_log_set_level(get_av_log_level());
-
-	av_register_all();
-	avformat_network_init();
-
-	ret = avformat_open_input(&i->avctx, i->url, NULL, NULL);
-	if (ret < 0) {
-		av_err(ret, "failed to open %s", i->url);
-		goto fail;
-	}
-
-	ret = avformat_find_stream_info(i->avctx, NULL);
+#endif
+
+	ret = ioctl(i->fb.fd, ULTRAFBIO_BUFFER_SIZE, &UserFrameBufferSize);
 	if (ret < 0) {
-		av_err(ret, "failed to get streams info");
-		goto fail;
-	}
-
-	av_dump_format(i->avctx, -1, i->url, 0);
-
-	ret = av_find_best_stream(i->avctx, AVMEDIA_TYPE_VIDEO, -1, -1,
-				  NULL, 0);
-	if (ret < 0) {
-		av_err(ret, "stream does not seem to contain video");
-		goto fail;
-	}
-
-	i->stream = i->avctx->streams[ret];
-	codecpar = i->stream->codecpar;
-
-	i->width = codecpar->width ?: 320;
-	i->height = codecpar->height ?: 240;
-	i->need_header = 1;
-
-	framerate = av_stream_get_r_frame_rate(i->stream);
-	i->fps_n = framerate.num;
-	i->fps_d = framerate.den;
-
-	filter = NULL;
-
-	switch (codecpar->codec_id) {
-	case AV_CODEC_ID_H263:
-		codec = V4L2_PIX_FMT_H263;
-		break;
-	case AV_CODEC_ID_H264:
-		codec = V4L2_PIX_FMT_H264;
-		filter = av_bsf_get_by_name("h264_mp4toannexb");
-		break;
-	case AV_CODEC_ID_HEVC:
-		codec = V4L2_PIX_FMT_HEVC;
-		filter = av_bsf_get_by_name("hevc_mp4toannexb");
-		break;
-	case AV_CODEC_ID_MPEG2VIDEO:
-		codec = V4L2_PIX_FMT_MPEG2;
-		break;
-	case AV_CODEC_ID_MPEG4:
-		codec = V4L2_PIX_FMT_MPEG4;
-		break;
-	case AV_CODEC_ID_MSMPEG4V3:
-		codec = V4L2_PIX_FMT_DIVX_311;
-		break;
-	case AV_CODEC_ID_WMV3:
-		codec = V4L2_PIX_FMT_VC1_ANNEX_G;
-		break;
-	case AV_CODEC_ID_VC1:
-		codec = V4L2_PIX_FMT_VC1_ANNEX_G;
-		break;
-	case AV_CODEC_ID_VP8:
-		codec = V4L2_PIX_FMT_VP8;
-		break;
-	case AV_CODEC_ID_VP9:
-		codec = V4L2_PIX_FMT_VP9;
-		break;
-	default:
-		err("cannot decode %s", avcodec_get_name(codecpar->codec_id));
-		goto fail;
-	}
-
-	i->fourcc = codec;
-
-	if (filter) {
-		ret = av_bsf_alloc(filter, &i->bsf);
-		if (ret < 0) {
-			av_err(ret, "cannot allocate bistream filter");
-			goto fail;
-		}
-
-		avcodec_parameters_copy(i->bsf->par_in, codecpar);
-		i->bsf->time_base_in = i->stream->time_base;
-
-		ret = av_bsf_init(i->bsf);
-		if (ret < 0) {
-			av_err(ret, "failed to initialize bitstream filter");
-			goto fail;
-		}
-	}
-
-	return 0;
-
-fail:
-	stream_close(i);
-	return -1;
-}
-
-int main(int argc, char **argv)
-{
-	struct instance inst;
-	pthread_t parser_thread;
-	int ret;
-
-	ret = parse_args(&inst, argc, argv);
-	if (ret) {
-		print_usage(argv[0]);
-		return 1;
-	}
-
-	inst.sigfd = -1;
-	pthread_mutex_init(&inst.lock, 0);
-	pthread_cond_init(&inst.cond, 0);
-
-	INIT_LIST_HEAD(&inst.video.pending_ts_list);
-	INIT_LIST_HEAD(&inst.fb_list);
-	inst.video.pts_dts_delta = TIMESTAMP_NONE;
-	inst.video.cap_last_pts = TIMESTAMP_NONE;
-	inst.video.extradata_index = -1;
-	inst.video.extradata_size = 0;
-	inst.video.extradata_ion_fd = -1;
-
-	ret = stream_open(&inst);
-	if (ret)
-		goto err;
-
-	ret = video_open(&inst, inst.video.name);
-	if (ret)
-		goto err;
-
-	ret = subscribe_events(&inst);
-	if (ret)
-		goto err;
-
-	if (inst.secure) {
-		ret = video_set_secure(&inst);
-		if (ret)
-			goto err;
-	}
-
-	ret = video_setup_output(&inst, inst.fourcc,
-				 STREAM_BUUFER_SIZE, 6);
-	if (ret)
-		goto err;
-
-	ret = setup_display(&inst);
-	if (ret)
-		err("display server not available, continuing anyway...");
-
-	ret = video_set_control(&inst);
-	if (ret)
-		goto err;
-
-	ret = video_stream(&inst, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE,
-			   VIDIOC_STREAMON);
-	if (ret)
-		goto err;
-
-	ret = restart_capture(&inst);
-	if (ret)
-		goto err;
-
-	dbg("Launching threads");
-
-	setup_signal(&inst);
-
-	if (pthread_create(&parser_thread, NULL, parser_thread_func, &inst))
-		goto err;
-
-	main_loop(&inst);
-
-	pthread_join(parser_thread, 0);
-
-	dbg("Threads have finished");
-
-	video_stop_output(&inst);
-	video_stop_capture(&inst);
-
-	cleanup(&inst);
-
-	pthread_cond_destroy(&inst.cond);
-	pthread_mutex_destroy(&inst.lock);
-
-	info("Total frames captured %ld", inst.video.total_captured);
-
-	return 0;
-err:
-	cleanup(&inst);
-	return 1;
-}
-
+	    printf("ULTRAFBIO_BUFFER_SIZE set buffer size error\n");
+	    return -1;
+	}
+
+	ret = ioctl(i->fb.fd, FBIOPUT_VSCREENINFO, &FBVar);
+	if (ret != 0) {
+	    printf("FBIOPUT_VSCREENINFO failed!\n");
+	    return -1;
+	}
+
+	return 0;
+}	
+
+int main(int argc, char **argv)
+{
+	struct instance inst;
+	struct video *vid = &inst.video;
+	pthread_t parser_thread;
+	pthread_t main_thread;
+	int ret, n;
+
+	ret = parse_args(&inst, argc, argv);
+	if (ret) {
+		print_usage(argv[0]);
+		return 1;
+	}
+
+	info("decoding resolution is %dx%d", inst.width, inst.height);
+
+	pthread_mutex_init(&inst.lock, 0);
+
+	vid->total_captured = 0;
+
+	ret = input_open(&inst, inst.in.name);
+	if (ret)
+		goto err;
+
+	ret = fb_open(&inst, inst.fb.name);
+	if (ret)
+		goto err;
+
+	ret = video_open(&inst, inst.video.name);
+	if (ret)
+		goto err;
+#if 0
+	/* TODO: */
+	ret = subscribe_for_events(vid->fd);
+	if (ret)
+		goto err;
+#endif
+
+	ret = video_setup_output(&inst, inst.parser.codec,
+				 STREAM_BUUFER_SIZE, 6);
+	if (ret)
+		goto err;
+
+	ret = parse_stream_init(&inst.parser.ctx);
+	if (ret)
+		goto err;
+
+	ret = video_setup_capture(&inst, 2, inst.width, inst.height);
+	if (ret)
+		goto err;
+
+#if 0  // ychuang - skip
+	ret = video_set_control(&inst);
+	if (ret)
+		goto err;
+#endif		
+
+	ret = extract_and_process_header(&inst);
+	if (ret)
+		goto err;
+
+	/* queue all capture buffers */
+	for (n = 0; n < vid->cap_buf_cnt; n++) {
+		ret = video_queue_buf_cap(&inst, n);
+		if (ret)
+			goto err;
+		vid->cap_buf_flag[n] = 1;
+	}
+
+	ret = video_stream(&inst, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
+			   VIDIOC_STREAMON);
+	if (ret)
+		goto err;
+
+	dbg("Launching threads");
+
+	if (pthread_create(&parser_thread, NULL, parser_thread_func, &inst))
+		goto err;
+
+	if (pthread_create(&main_thread, NULL, main_thread_func, &inst))
+		goto err;
+
+	pthread_join(parser_thread, 0);
+	pthread_join(main_thread, 0);
+
+	dbg("Threads have finished");
+
+	video_stop(&inst);
+
+	cleanup(&inst);
+
+	pthread_mutex_destroy(&inst.lock);
+
+	info("Total frames captured %ld", vid->total_captured);
+
+	return 0;
+err:
+	printf("ERR OUT!\n");
+	cleanup(&inst);
+	return 1;
+}
+
diff --git a/msm-v4l2-controls.h b/msm-v4l2-controls.h
new file mode 100644
index 0000000..3ce6c70
--- /dev/null
+++ b/msm-v4l2-controls.h
@@ -0,0 +1,461 @@
+#ifndef __MSM_V4L2_CONTROLS_H__
+#define __MSM_V4L2_CONTROLS_H__
+
+#include <linux/v4l2-controls.h>
+
+/*  MPEG-class control IDs specific to the msm_vidc driver */
+#define V4L2_CID_MPEG_MSM_VIDC_BASE		(V4L2_CTRL_CLASS_MPEG | 0x2000)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_ENABLE_PICTURE_TYPE \
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+0)
+#define V4L2_CID_MPEG_VIDC_VIDEO_KEEP_ASPECT_RATIO \
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+1)
+#define V4L2_CID_MPEG_VIDC_VIDEO_POST_LOOP_DEBLOCKER_MODE \
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+2)
+#define V4L2_CID_MPEG_VIDC_VIDEO_DIVX_FORMAT \
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+3)
+enum v4l2_mpeg_vidc_video_divx_format_type {
+	V4L2_MPEG_VIDC_VIDEO_DIVX_FORMAT_4		= 0,
+	V4L2_MPEG_VIDC_VIDEO_DIVX_FORMAT_5		= 1,
+	V4L2_MPEG_VIDC_VIDEO_DIVX_FORMAT_6	    = 2,
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_MB_ERROR_MAP_REPORTING	\
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+4)
+#define V4L2_CID_MPEG_VIDC_VIDEO_CONTINUE_DATA_TRANSFER \
+			(V4L2_CID_MPEG_MSM_VIDC_BASE+5)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_STREAM_FORMAT   (V4L2_CID_MPEG_MSM_VIDC_BASE+6)
+enum v4l2_mpeg_vidc_video_stream_format {
+	V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_STARTCODES         = 0,
+	V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_ONE_NAL_PER_BUFFER = 1,
+	V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_ONE_BYTE_LENGTH    = 2,
+	V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_TWO_BYTE_LENGTH    = 3,
+	V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_FOUR_BYTE_LENGTH   = 4,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_OUTPUT_ORDER   (V4L2_CID_MPEG_MSM_VIDC_BASE+7)
+enum v4l2_mpeg_vidc_video_output_order {
+	V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DISPLAY         = 0,
+	V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DECODE          = 1,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_FRAME_RATE   (V4L2_CID_MPEG_MSM_VIDC_BASE+8)
+#define V4L2_CID_MPEG_VIDC_VIDEO_IDR_PERIOD   (V4L2_CID_MPEG_MSM_VIDC_BASE+9)
+#define V4L2_CID_MPEG_VIDC_VIDEO_NUM_P_FRAMES (V4L2_CID_MPEG_MSM_VIDC_BASE+10)
+#define V4L2_CID_MPEG_VIDC_VIDEO_NUM_B_FRAMES (V4L2_CID_MPEG_MSM_VIDC_BASE+11)
+#define V4L2_CID_MPEG_VIDC_VIDEO_REQUEST_IFRAME (V4L2_CID_MPEG_MSM_VIDC_BASE+12)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL (V4L2_CID_MPEG_MSM_VIDC_BASE+13)
+enum v4l2_mpeg_vidc_video_rate_control {
+	V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_OFF = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_VBR_VFR = 1,
+	V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_VBR_CFR = 2,
+	V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_CBR_VFR = 3,
+	V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_CBR_CFR = 4,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_ROTATION (V4L2_CID_MPEG_MSM_VIDC_BASE+14)
+enum v4l2_mpeg_vidc_video_rotation {
+	V4L2_CID_MPEG_VIDC_VIDEO_ROTATION_NONE = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_ROTATION_90 = 1,
+	V4L2_CID_MPEG_VIDC_VIDEO_ROTATION_180 = 2,
+	V4L2_CID_MPEG_VIDC_VIDEO_ROTATION_270 = 3,
+};
+#define MSM_VIDC_BASE V4L2_CID_MPEG_MSM_VIDC_BASE
+#define V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL (MSM_VIDC_BASE+15)
+enum v4l2_mpeg_vidc_h264_cabac_model {
+	V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_0 = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_1 = 1,
+	V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_2 = 2,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_MODE (MSM_VIDC_BASE+16)
+enum v4l2_mpeg_vidc_video_intra_refresh_mode {
+	V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_NONE = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_CYCLIC = 1,
+	V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_ADAPTIVE = 2,
+	V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_CYCLIC_ADAPTIVE = 3,
+	V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_RANDOM = 4,
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_AIR_MBS (V4L2_CID_MPEG_MSM_VIDC_BASE+17)
+#define V4L2_CID_MPEG_VIDC_VIDEO_AIR_REF (V4L2_CID_MPEG_MSM_VIDC_BASE+18)
+#define V4L2_CID_MPEG_VIDC_VIDEO_CIR_MBS (V4L2_CID_MPEG_MSM_VIDC_BASE+19)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H263_PROFILE (V4L2_CID_MPEG_MSM_VIDC_BASE+20)
+enum v4l2_mpeg_vidc_video_h263_profile {
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_BASELINE = 0,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_H320CODING	= 1,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_BACKWARDCOMPATIBLE = 2,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_ISWV2 = 3,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_ISWV3 = 4,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_HIGHCOMPRESSION = 5,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_INTERNET = 6,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_INTERLACE = 7,
+	V4L2_MPEG_VIDC_VIDEO_H263_PROFILE_HIGHLATENCY = 8,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H263_LEVEL (V4L2_CID_MPEG_MSM_VIDC_BASE+21)
+enum v4l2_mpeg_vidc_video_h263_level {
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_1_0 = 0,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_2_0 = 1,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_3_0 = 2,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_4_0 = 3,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_4_5 = 4,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_5_0 = 5,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_6_0 = 6,
+	V4L2_MPEG_VIDC_VIDEO_H263_LEVEL_7_0 = 7,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H264_AU_DELIMITER \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 22)
+enum v4l2_mpeg_vidc_video_h264_au_delimiter {
+	V4L2_MPEG_VIDC_VIDEO_H264_AU_DELIMITER_DISABLED = 0,
+	V4L2_MPEG_VIDC_VIDEO_H264_AU_DELIMITER_ENABLED = 1
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_SYNC_FRAME_DECODE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 23)
+enum v4l2_mpeg_vidc_video_sync_frame_decode {
+	V4L2_MPEG_VIDC_VIDEO_SYNC_FRAME_DECODE_DISABLE = 0,
+	V4L2_MPEG_VIDC_VIDEO_SYNC_FRAME_DECODE_ENABLE = 1
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_SECURE (V4L2_CID_MPEG_MSM_VIDC_BASE+24)
+#define V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 25)
+enum v4l2_mpeg_vidc_extradata {
+	V4L2_MPEG_VIDC_EXTRADATA_NONE = 0,
+	V4L2_MPEG_VIDC_EXTRADATA_MB_QUANTIZATION = 1,
+	V4L2_MPEG_VIDC_EXTRADATA_INTERLACE_VIDEO = 2,
+	V4L2_MPEG_VIDC_EXTRADATA_VC1_FRAMEDISP = 3,
+	V4L2_MPEG_VIDC_EXTRADATA_VC1_SEQDISP = 4,
+	V4L2_MPEG_VIDC_EXTRADATA_TIMESTAMP = 5,
+	V4L2_MPEG_VIDC_EXTRADATA_S3D_FRAME_PACKING = 6,
+	V4L2_MPEG_VIDC_EXTRADATA_FRAME_RATE = 7,
+	V4L2_MPEG_VIDC_EXTRADATA_PANSCAN_WINDOW = 8,
+	V4L2_MPEG_VIDC_EXTRADATA_RECOVERY_POINT_SEI = 9,
+	V4L2_MPEG_VIDC_EXTRADATA_MULTISLICE_INFO = 10,
+	V4L2_MPEG_VIDC_EXTRADATA_NUM_CONCEALED_MB = 11,
+	V4L2_MPEG_VIDC_EXTRADATA_METADATA_FILLER = 12,
+	V4L2_MPEG_VIDC_EXTRADATA_INPUT_CROP = 13,
+	V4L2_MPEG_VIDC_EXTRADATA_DIGITAL_ZOOM = 14,
+	V4L2_MPEG_VIDC_EXTRADATA_ASPECT_RATIO = 15,
+	V4L2_MPEG_VIDC_EXTRADATA_MPEG2_SEQDISP = 16,
+	V4L2_MPEG_VIDC_EXTRADATA_STREAM_USERDATA = 17,
+	V4L2_MPEG_VIDC_EXTRADATA_FRAME_QP = 18,
+	V4L2_MPEG_VIDC_EXTRADATA_FRAME_BITS_INFO = 19,
+	V4L2_MPEG_VIDC_EXTRADATA_LTR = 20,
+	V4L2_MPEG_VIDC_EXTRADATA_METADATA_MBI = 21,
+};
+
+#define V4L2_CID_MPEG_VIDC_SET_PERF_LEVEL (V4L2_CID_MPEG_MSM_VIDC_BASE + 26)
+enum v4l2_mpeg_vidc_perf_level {
+	V4L2_CID_MPEG_VIDC_PERF_LEVEL_NOMINAL			= 0,
+	V4L2_CID_MPEG_VIDC_PERF_LEVEL_PERFORMANCE		= 1,
+	V4L2_CID_MPEG_VIDC_PERF_LEVEL_TURBO			= 2,
+};
+#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_GOB		\
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 27)
+
+#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_DELIVERY_MODE	\
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 28)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H264_VUI_TIMING_INFO \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 29)
+enum v4l2_mpeg_vidc_video_h264_vui_timing_info {
+	V4L2_MPEG_VIDC_VIDEO_H264_VUI_TIMING_INFO_DISABLED = 0,
+	V4L2_MPEG_VIDC_VIDEO_H264_VUI_TIMING_INFO_ENABLED = 1
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_ALLOC_MODE_INPUT	\
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 30)
+#define V4L2_CID_MPEG_VIDC_VIDEO_ALLOC_MODE_OUTPUT       \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 31)
+enum v4l2_mpeg_vidc_video_alloc_mode_type {
+	V4L2_MPEG_VIDC_VIDEO_STATIC	= 0,
+	V4L2_MPEG_VIDC_VIDEO_RING	= 1,
+	V4L2_MPEG_VIDC_VIDEO_DYNAMIC	= 2,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_FRAME_ASSEMBLY	\
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 32)
+enum v4l2_mpeg_vidc_video_assembly {
+	V4L2_MPEG_VIDC_FRAME_ASSEMBLY_DISABLE	= 0,
+	V4L2_MPEG_VIDC_FRAME_ASSEMBLY_ENABLE	= 1,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_VP8_PROFILE_LEVEL \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 33)
+enum v4l2_mpeg_vidc_video_vp8_profile_level {
+	V4L2_MPEG_VIDC_VIDEO_VP8_UNUSED,
+	V4L2_MPEG_VIDC_VIDEO_VP8_VERSION_0,
+	V4L2_MPEG_VIDC_VIDEO_VP8_VERSION_1,
+	V4L2_MPEG_VIDC_VIDEO_VP8_VERSION_2,
+	V4L2_MPEG_VIDC_VIDEO_VP8_VERSION_3,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H264_VUI_BITSTREAM_RESTRICT \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 34)
+enum v4l2_mpeg_vidc_video_h264_vui_bitstream_restrict {
+	V4L2_MPEG_VIDC_VIDEO_H264_VUI_BITSTREAM_RESTRICT_DISABLED = 0,
+	V4L2_MPEG_VIDC_VIDEO_H264_VUI_BITSTREAM_RESTRICT_ENABLED = 1
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_PRESERVE_TEXT_QUALITY \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 35)
+enum v4l2_mpeg_vidc_video_preserve_text_quality {
+	V4L2_MPEG_VIDC_VIDEO_PRESERVE_TEXT_QUALITY_DISABLED = 0,
+	V4L2_MPEG_VIDC_VIDEO_PRESERVE_TEXT_QUALITY_ENABLED = 1
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 36)
+enum v4l2_mpeg_vidc_video_deinterlace {
+	V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE_DISABLED = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE_ENABLED = 1
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_MPEG4_TIME_RESOLUTION \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 37)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_MODE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 38)
+enum v4l2_mpeg_vidc_video_decoder_multi_stream {
+	V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_PRIMARY = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_SECONDARY = 1,
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_SCS_THRESHOLD \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 39)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_MPEG2_LEVEL	(V4L2_CID_MPEG_MSM_VIDC_BASE+40)
+enum v4l2_mpeg_vidc_video_mpeg2_level {
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_LEVEL_0	= 0,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_LEVEL_1	= 1,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_LEVEL_2	= 2,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_LEVEL_3	= 3,
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_MPEG2_PROFILE	(V4L2_CID_MPEG_MSM_VIDC_BASE+41)
+enum v4l2_mpeg_vidc_video_mpeg2_profile {
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_SIMPLE		= 0,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_MAIN			= 1,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_422			= 2,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_SNR_SCALABLE		= 3,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_SPATIAL_SCALABLE	= 4,
+	V4L2_MPEG_VIDC_VIDEO_MPEG2_PROFILE_HIGH			= 5,
+};
+#define V4L2_CID_MPEG_VIDC_VIDEO_REQUEST_SEQ_HEADER \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 42)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_MVC_BUFFER_LAYOUT \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 43)
+enum v4l2_mpeg_vidc_video_mvc_layout {
+	V4L2_MPEG_VIDC_VIDEO_MVC_SEQUENTIAL = 0,
+	V4L2_MPEG_VIDC_VIDEO_MVC_TOP_BOTTOM = 1
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_VP8_MIN_QP (V4L2_CID_MPEG_MSM_VIDC_BASE + 44)
+#define V4L2_CID_MPEG_VIDC_VIDEO_VP8_MAX_QP (V4L2_CID_MPEG_MSM_VIDC_BASE + 45)
+#define V4L2_CID_MPEG_VIDC_VIDEO_CONCEAL_COLOR \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 46)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_LTRMODE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 47)
+
+enum v4l2_mpeg_vidc_video_ltrmode {
+	V4L2_MPEG_VIDC_VIDEO_LTR_MODE_DISABLE = 0,
+	V4L2_MPEG_VIDC_VIDEO_LTR_MODE_MANUAL = 1,
+	V4L2_MPEG_VIDC_VIDEO_LTR_MODE_PERIODIC = 2
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_LTRCOUNT \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 48)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_USELTRFRAME \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 49)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_MARKLTRFRAME \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 50)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_HIER_P_NUM_LAYERS \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 51)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_RATE_CONTROL_TIMESTAMP_MODE \
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 52)
+enum v4l2_mpeg_vidc_video_rate_control_timestamp_mode {
+	V4L2_MPEG_VIDC_VIDEO_RATE_CONTROL_TIMESTAMP_MODE_HONOR = 0,
+	V4L2_MPEG_VIDC_VIDEO_RATE_CONTROL_TIMESTAMP_MODE_IGNORE = 1,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_ENABLE_INITIAL_QP \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 53)
+enum vl42_mpeg_vidc_video_enable_initial_qp {
+	V4L2_CID_MPEG_VIDC_VIDEO_ENABLE_INITIAL_QP_IFRAME = 0x1,
+	V4L2_CID_MPEG_VIDC_VIDEO_ENABLE_INITIAL_QP_PFRAME = 0x2,
+	V4L2_CID_MPEG_VIDC_VIDEO_ENABLE_INITIAL_QP_BFRAME = 0x4,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_I_FRAME_QP \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 54)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_P_FRAME_QP \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 55)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_B_FRAME_QP \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 56)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_X_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 57)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_X_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 58)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_X_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 59)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_Y_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 60)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_Y_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 61)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_Y_RANGE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 62)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_VPX_ERROR_RESILIENCE \
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 63)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_BUFFER_SIZE_LIMIT \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 64)
+
+enum vl42_mpeg_vidc_video_vpx_error_resilience {
+	V4L2_MPEG_VIDC_VIDEO_VPX_ERROR_RESILIENCE_DISABLED = 0,
+	V4L2_MPEG_VIDC_VIDEO_VPX_ERROR_RESILIENCE_ENABLED = 1,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_HEVC_PROFILE \
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 65)
+
+#if 0
+enum v4l2_mpeg_video_hevc_profile {
+	V4L2_MPEG_VIDC_VIDEO_HEVC_PROFILE_MAIN			= 0,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_PROFILE_MAIN10		= 1,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_PROFILE_MAIN_STILL_PIC	= 2,
+};
+#endif
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_HEVC_TIER_LEVEL \
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 66)
+
+#if 0
+enum v4l2_mpeg_video_hevc_level {
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_1	= 0,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_1	= 1,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_2	= 2,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_2	= 3,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_2_1	= 4,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_2_1	= 5,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_3	= 6,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_3	= 7,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_3_1	= 8,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_3_1	= 9,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_4	= 10,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_4	= 11,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_4_1	= 12,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_4_1	= 13,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_5	= 14,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_5	= 15,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_5_1	= 16,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_5_1	= 17,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_5_2	= 18,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_5_2	= 19,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_6	= 20,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_6	= 21,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_6_1	= 22,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_6_1	= 23,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_MAIN_TIER_LEVEL_6_2	= 24,
+	V4L2_MPEG_VIDC_VIDEO_HEVC_LEVEL_HIGH_TIER_LEVEL_6_2	= 25,
+};
+#endif
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_H264_NAL_SVC \
+	(V4L2_CID_MPEG_MSM_VIDC_BASE + 67)
+
+enum vl42_mpeg_vidc_video_h264_svc_nal {
+	V4L2_CID_MPEG_VIDC_VIDEO_H264_NAL_SVC_DISABLED = 0,
+	V4L2_CID_MPEG_VIDC_VIDEO_H264_NAL_SVC_ENABLED = 1,
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE	 \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 68)
+
+enum v4l2_mpeg_vidc_video_perf_mode {
+	V4L2_MPEG_VIDC_VIDEO_PERF_MAX_QUALITY = 1,
+	V4L2_MPEG_VIDC_VIDEO_PERF_POWER_SAVE = 2
+};
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_HIER_B_NUM_LAYERS \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 69)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_SECURE_SCALING_THRESHOLD \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 70)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_NON_SECURE_OUTPUT2 \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 71)
+
+#define V4L2_CID_MPEG_VIDC_VIDEO_HYBRID_HIERP_MODE \
+		(V4L2_CID_MPEG_MSM_VIDC_BASE + 72)
+
+/* Vendor extensions */
+#define V4L2_QCOM_BUF_FLAG_CODECCONFIG		0x10000
+#define V4L2_QCOM_BUF_FLAG_EOSEQ		0x20000
+#define V4L2_QCOM_BUF_TIMESTAMP_INVALID		0x40000
+#define V4L2_QCOM_BUF_FLAG_IDRFRAME		0x80000	/*Image is a IDR-frame*/
+#define V4L2_QCOM_BUF_FLAG_DECODEONLY		0x100000
+#define V4L2_QCOM_BUF_DATA_CORRUPT		0x200000
+#define V4L2_QCOM_BUF_DROP_FRAME		0x400000
+#define V4L2_QCOM_BUF_INPUT_UNSUPPORTED		0x800000
+#define V4L2_QCOM_BUF_FLAG_EOS			0x1000000
+#define V4L2_QCOM_BUF_TS_DISCONTINUITY		0x2000000
+#define V4L2_QCOM_BUF_TS_ERROR			0x4000000
+#define V4L2_QCOM_BUF_FLAG_READONLY		0x8000000
+#define V4L2_MSM_VIDC_BUF_START_CODE_NOT_FOUND	0x10000000
+#define V4L2_MSM_BUF_FLAG_YUV_601_709_CLAMP	0x20000000
+#define V4L2_MSM_BUF_FLAG_MBAFF			0x40000000
+
+/* Capabilities */
+#define V4L2_CAP_QCOM_FRAMESKIP	0x2000	/*  frame skipping is supported */
+
+struct v4l2_qcom_frameskip {
+	__u64		   maxframeinterval;
+	__u8		   fpsvariance;
+};
+
+/* Encoder commands */
+#define V4L2_ENC_QCOM_CMD_FLUSH  (4)
+
+/* Decoder commands */
+#define V4L2_DEC_QCOM_CMD_FLUSH  (4)
+
+/* Flags for V4L2_DEC_QCOM_CMD_FLUSH */
+#define V4L2_DEC_QCOM_CMD_FLUSH_OUTPUT  (1 << 0)
+#define V4L2_DEC_QCOM_CMD_FLUSH_CAPTURE (1 << 1)
+
+#define V4L2_QCOM_CMD_FLUSH_OUTPUT  (1 << 0)
+#define V4L2_QCOM_CMD_FLUSH_CAPTURE (1 << 1)
+
+/* Events */
+#define V4L2_EVENT_MSM_VIDC_START	(V4L2_EVENT_PRIVATE_START + 0x00001000)
+#define V4L2_EVENT_MSM_VIDC_FLUSH_DONE	(V4L2_EVENT_MSM_VIDC_START + 1)
+#define V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_SUFFICIENT	\
+		(V4L2_EVENT_MSM_VIDC_START + 2)
+#define V4L2_EVENT_MSM_VIDC_PORT_SETTINGS_CHANGED_INSUFFICIENT	\
+		(V4L2_EVENT_MSM_VIDC_START + 3)
+#define V4L2_EVENT_MSM_VIDC_CLOSE_DONE	(V4L2_EVENT_MSM_VIDC_START + 4)
+#define V4L2_EVENT_MSM_VIDC_SYS_ERROR	(V4L2_EVENT_MSM_VIDC_START + 5)
+#define V4L2_EVENT_MSM_VIDC_RELEASE_BUFFER_REFERENCE \
+		(V4L2_EVENT_MSM_VIDC_START + 6)
+#define V4L2_EVENT_MSM_VIDC_RELEASE_UNQUEUED_BUFFER \
+		(V4L2_EVENT_MSM_VIDC_START + 7)
+#define V4L2_EVENT_MSM_VIDC_HW_OVERLOAD (V4L2_EVENT_MSM_VIDC_START + 8)
+#define V4L2_EVENT_MSM_VIDC_MAX_CLIENTS (V4L2_EVENT_MSM_VIDC_START + 9)
+#define V4L2_EVENT_MSM_VIDC_HW_UNSUPPORTED (V4L2_EVENT_MSM_VIDC_START + 10)
+
+#endif/* __MSM_V4L2_CONTROLS_H__ */
diff --git a/parser.c b/parser.c
new file mode 100644
index 0000000..7879c43
--- /dev/null
+++ b/parser.c
@@ -0,0 +1,626 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Really simple stream parser file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include "common.h"
+#include "parser.h"
+#include <string.h>
+
+int parse_stream_init(struct mfc_parser_context *ctx)
+{
+	if (!ctx) {
+		err("ctx is NULL");
+		return -1;
+	}
+
+	memzero(*ctx);
+
+	return 0;
+}
+
+int parse_mpeg4_stream(struct mfc_parser_context *ctx,
+		       char *in, int in_size,
+		       char *out, int out_size,
+		       int *consumed, int *frame_size, char get_head)
+{
+	char *in_orig;
+	char tmp;
+	char frame_finished;
+	int frame_length;
+
+	in_orig = in;
+
+	*consumed = 0;
+
+	frame_finished = 0;
+
+	while (in_size-- > 0) {
+		switch (ctx->state) {
+		case MPEG4_PARSER_NO_CODE:
+			if (*in == 0x0) {
+				ctx->state = MPEG4_PARSER_CODE_0x1;
+				ctx->tmp_code_start = *consumed;
+			}
+			break;
+		case MPEG4_PARSER_CODE_0x1:
+			if (*in == 0x0)
+				ctx->state = MPEG4_PARSER_CODE_0x2;
+			else
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			break;
+		case MPEG4_PARSER_CODE_0x2:
+			if (*in == 0x1) {
+				ctx->state = MPEG4_PARSER_CODE_1x1;
+			} else if ((*in & 0xFC) == 0x80) {
+				/* Short header */
+				ctx->state = MPEG4_PARSER_NO_CODE;
+				/* Ignore the short header if the current hasn't
+				 * been started with a short header. */
+
+				if (get_head && !ctx->short_header) {
+					ctx->last_tag = MPEG4_TAG_HEAD;
+					ctx->headers_count++;
+					ctx->short_header = 1;
+				} else if (!ctx->seek_end ||
+					(ctx->seek_end && ctx->short_header)) {
+					ctx->last_tag = MPEG4_TAG_VOP;
+					ctx->main_count++;
+					ctx->short_header = 1;
+				}
+			} else if (*in == 0x0) {
+				ctx->tmp_code_start++;
+			} else {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			}
+			break;
+		case MPEG4_PARSER_CODE_1x1:
+			tmp = *in & 0xF0;
+			if (tmp == 0x00 || tmp == 0x01 || tmp == 0x20 ||
+				*in == 0xb0 || *in == 0xb2 || *in == 0xb3 ||
+				*in == 0xb5) {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+				ctx->last_tag = MPEG4_TAG_HEAD;
+				ctx->headers_count++;
+			} else if (*in == 0xb6) {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+				ctx->last_tag = MPEG4_TAG_VOP;
+				ctx->main_count++;
+			} else
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			break;
+		}
+
+		if (get_head == 1 && ctx->headers_count >= 1 && ctx->main_count == 1) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			break;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 1 && ctx->main_count == 0) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 0 && ctx->main_count == 1) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 0 && ctx->headers_count > 0 && ctx->main_count == 1) {
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 1 && (ctx->headers_count > 0 || ctx->main_count > 0)) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			if (ctx->headers_count == 0)
+				ctx->seek_end = 1;
+			else
+				ctx->seek_end = 0;
+			break;
+		}
+
+		in++;
+		(*consumed)++;
+	}
+
+
+	*frame_size = 0;
+
+	if (ctx->got_end == 1) {
+		frame_length = ctx->code_end;
+	} else
+		frame_length = *consumed;
+
+
+	if (ctx->code_start >= 0) {
+		frame_length -= ctx->code_start;
+		in = in_orig + ctx->code_start;
+	} else {
+		memcpy(out, ctx->bytes, -ctx->code_start);
+		*frame_size += -ctx->code_start;
+		out += -ctx->code_start;
+		in_size -= -ctx->code_start;
+		in = in_orig;
+	}
+
+	if (ctx->got_start) {
+		if (out_size < frame_length) {
+			err("Output buffer too small for current frame");
+			return 0;
+		}
+
+		memcpy(out, in, frame_length);
+		*frame_size += frame_length;
+
+		if (ctx->got_end) {
+			ctx->code_start = ctx->code_end - *consumed;
+			ctx->got_start = 1;
+			ctx->got_end = 0;
+			frame_finished = 1;
+			if (ctx->last_tag == MPEG4_TAG_VOP) {
+				ctx->seek_end = 1;
+				ctx->main_count = 0;
+				ctx->headers_count = 0;
+			} else {
+				ctx->seek_end = 0;
+				ctx->main_count = 0;
+				ctx->headers_count = 1;
+				ctx->short_header = 0;
+				/* If the last frame used the short then
+				 * we shall save this information, otherwise
+				 * it is necessary to clear it */
+			}
+			memcpy(ctx->bytes, in_orig + ctx->code_end, *consumed - ctx->code_end);
+		} else {
+			ctx->code_start = 0;
+			frame_finished = 0;
+		}
+	}
+
+	ctx->tmp_code_start -= *consumed;
+
+	return frame_finished;
+}
+
+#if 1   // support byte stream format only
+int parse_h264_stream(struct mfc_parser_context *ctx,
+		      char *in, int in_size,
+		      char *out, int out_size,
+		      int *consumed, int *frame_size, char get_head)
+{
+	char  *in_orig = in;
+	int   tmp_zstart;
+	int   slice_found = 0;
+	int   done = 0; 
+	char  tmp;
+
+	//printf("%s called, in_size %d ==>\n", __func__, in_size);
+	
+	*consumed = 0;
+	*frame_size = 0;
+	tmp_zstart = 0;
+	ctx->state = H264_PARSER_NO_CODE;
+	
+	while (in_size-- > 0) {
+		switch (ctx->state) {
+		case H264_PARSER_NO_CODE:
+			if (*in == 0x0) {
+				ctx->state = H264_PARSER_CODE_0x1;
+				tmp_zstart = *consumed;
+			}
+			break;
+		case H264_PARSER_CODE_0x1:
+			if (*in == 0x0)
+				ctx->state = H264_PARSER_CODE_0x2;
+			else
+				ctx->state = H264_PARSER_NO_CODE;
+			break;
+		case H264_PARSER_CODE_0x2:
+			if (*in == 0x1) {
+				ctx->state = H264_PARSER_CODE_1x1;
+			} else if (*in == 0x0) {
+				ctx->state = H264_PARSER_CODE_0x3;
+			} else {
+				ctx->state = H264_PARSER_NO_CODE;
+			}
+			break;
+		case H264_PARSER_CODE_0x3:
+			if (*in == 0x1)
+				ctx->state = H264_PARSER_CODE_1x1;
+			else
+				ctx->state = H264_PARSER_NO_CODE;
+			break;
+		case H264_PARSER_CODE_1x1:
+			tmp = *in & 0x1F;
+
+			if (tmp == 1 || tmp == 5) {
+				ctx->state = H264_PARSER_CODE_SLICE;
+			} else if (tmp == 6 || tmp == 7 || tmp == 8) {
+				ctx->state = H264_PARSER_NO_CODE;
+				ctx->last_tag = H264_TAG_HEAD;
+				ctx->headers_count++;
+				if (slice_found)
+					done = 1;
+			}
+			else {
+				if (slice_found)
+					done = 1;
+				ctx->state = H264_PARSER_NO_CODE;
+			}
+			break;
+		case H264_PARSER_CODE_SLICE:
+			if ((*in & 0x80) == 0x80) {
+				if (slice_found) {
+					done = 1;
+				}
+				else {
+					ctx->main_count++;
+					ctx->last_tag = H264_TAG_SLICE;
+					slice_found = 1;
+				}
+			}
+			ctx->state = H264_PARSER_NO_CODE;
+			break;
+		}
+		
+		if (done)
+			break;
+
+		in++;
+		(*consumed)++;
+	}
+
+	*consumed = tmp_zstart;	
+
+	if (*consumed > out_size) {
+		printf("%s - frame size too big! %d > %d\n", __func__, *consumed, out_size);
+		return -1;
+	}
+
+	if (in_size < 4)
+		*consumed += in_size;
+
+//printf("\n[PARSER] %dn\n", *consumed);
+
+	*frame_size = *consumed;
+	memcpy(out, in_orig, *consumed);
+	return 0;
+}
+#else
+
+int parse_h264_stream(struct mfc_parser_context *ctx,
+		      char *in, int in_size,
+		      char *out, int out_size,
+		      int *consumed, int *frame_size, char get_head)
+{
+	char *in_orig;
+	char tmp;
+	char frame_finished;
+	int frame_length;
+
+printf("parse_h264_stream\n");
+	in_orig = in;
+
+	*consumed = 0;
+
+	frame_finished = 0;
+
+	while (in_size-- > 0) {
+		switch (ctx->state) {
+		case H264_PARSER_NO_CODE:
+			if (*in == 0x0) {
+				ctx->state = H264_PARSER_CODE_0x1;
+				ctx->tmp_code_start = *consumed;
+			}
+			break;
+		case H264_PARSER_CODE_0x1:
+			if (*in == 0x0)
+				ctx->state = H264_PARSER_CODE_0x2;
+			else
+				ctx->state = H264_PARSER_NO_CODE;
+			break;
+		case H264_PARSER_CODE_0x2:
+			if (*in == 0x1) {
+				ctx->state = H264_PARSER_CODE_1x1;
+			} else if (*in == 0x0) {
+				ctx->state = H264_PARSER_CODE_0x3;
+			} else {
+				ctx->state = H264_PARSER_NO_CODE;
+			}
+			break;
+		case H264_PARSER_CODE_0x3:
+			if (*in == 0x1)
+				ctx->state = H264_PARSER_CODE_1x1;
+			else if (*in == 0x0)
+				ctx->tmp_code_start++;
+			else
+				ctx->state = H264_PARSER_NO_CODE;
+			break;
+		case H264_PARSER_CODE_1x1:
+			tmp = *in & 0x1F;
+
+			if (tmp == 1 || tmp == 5) {
+				ctx->state = H264_PARSER_CODE_SLICE;
+			} else if (tmp == 6 || tmp == 7 || tmp == 8) {
+				ctx->state = H264_PARSER_NO_CODE;
+				ctx->last_tag = H264_TAG_HEAD;
+				ctx->headers_count++;
+			}
+			else
+				ctx->state = H264_PARSER_NO_CODE;
+			break;
+		case H264_PARSER_CODE_SLICE:
+			if ((*in & 0x80) == 0x80) {
+				ctx->main_count++;
+				ctx->last_tag = H264_TAG_SLICE;
+			}
+			ctx->state = H264_PARSER_NO_CODE;
+			break;
+		}
+
+		if (get_head == 1 && ctx->headers_count >= 1 && ctx->main_count == 1) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			break;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 1 && ctx->main_count == 0) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 0 && ctx->main_count == 1) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 0 && ctx->headers_count > 0 && ctx->main_count == 1) {
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 1 && (ctx->headers_count > 0 || ctx->main_count > 0)) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			if (ctx->headers_count == 0)
+				ctx->seek_end = 1;
+			else
+				ctx->seek_end = 0;
+			break;
+		}
+
+		in++;
+		(*consumed)++;
+	}
+
+
+	*frame_size = 0;
+
+	if (ctx->got_end == 1) {
+		frame_length = ctx->code_end;
+	} else
+		frame_length = *consumed;
+
+
+	if (ctx->code_start >= 0) {
+		frame_length -= ctx->code_start;
+		in = in_orig + ctx->code_start;
+	} else {
+		memcpy(out, ctx->bytes, -ctx->code_start);
+		*frame_size += -ctx->code_start;
+		out += -ctx->code_start;
+		in_size -= -ctx->code_start;
+		in = in_orig;
+	}
+
+	if (ctx->got_start) {
+		if (out_size < frame_length) {
+			err("Output buffer too small for current frame");
+			return 0;
+		}
+		memcpy(out, in, frame_length);
+		*frame_size += frame_length;
+
+		if (ctx->got_end) {
+			ctx->code_start = ctx->code_end - *consumed;
+			ctx->got_start = 1;
+			ctx->got_end = 0;
+			frame_finished = 1;
+			if (ctx->last_tag == H264_TAG_SLICE) {
+				ctx->seek_end = 1;
+				ctx->main_count = 0;
+				ctx->headers_count = 0;
+			} else {
+				ctx->seek_end = 0;
+				ctx->main_count = 0;
+				ctx->headers_count = 1;
+			}
+			memcpy(ctx->bytes, in_orig + ctx->code_end, *consumed - ctx->code_end);
+		} else {
+			ctx->code_start = 0;
+			frame_finished = 0;
+		}
+	}
+
+	ctx->tmp_code_start -= *consumed;
+
+	return frame_finished;
+}
+#endif
+
+int parse_mpeg2_stream(struct mfc_parser_context *ctx,
+		       char* in, int in_size, char* out, int out_size,
+		       int *consumed, int *frame_size, char get_head)
+{
+	char  *in_orig;
+	char frame_finished;
+	int frame_length;
+
+	in_orig = in;
+
+	*consumed = 0;
+
+	frame_finished = 0;
+
+	while (in_size-- > 0) {
+		switch (ctx->state) {
+		case MPEG4_PARSER_NO_CODE:
+			if (*in == 0x0) {
+				ctx->state = MPEG4_PARSER_CODE_0x1;
+				ctx->tmp_code_start = *consumed;
+			}
+			break;
+		case MPEG4_PARSER_CODE_0x1:
+			if (*in == 0x0)
+				ctx->state = MPEG4_PARSER_CODE_0x2;
+			else
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			break;
+		case MPEG4_PARSER_CODE_0x2:
+			if (*in == 0x1) {
+				ctx->state = MPEG4_PARSER_CODE_1x1;
+			} else if (*in == 0x0) {
+				/* We still have two zeroes */
+				ctx->tmp_code_start++;
+				// TODO XXX check in h264 and mpeg4
+			} else {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			}
+			break;
+		case MPEG4_PARSER_CODE_1x1:
+			if (*in == 0xb3 || *in == 0xb8) {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+				ctx->last_tag = MPEG4_TAG_HEAD;
+				ctx->headers_count++;
+				dbg("Found header at %d (%x)", *consumed, *consumed);
+			} else if (*in == 0x00) {
+				ctx->state = MPEG4_PARSER_NO_CODE;
+				ctx->last_tag = MPEG4_TAG_VOP;
+				ctx->main_count++;
+				dbg("Found picture at %d (%x)", *consumed, *consumed);
+			} else
+				ctx->state = MPEG4_PARSER_NO_CODE;
+			break;
+		}
+
+		if (get_head == 1 && ctx->headers_count >= 1 && ctx->main_count == 1) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			break;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 1 && ctx->main_count == 0) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+		}
+
+		if (ctx->got_start == 0 && ctx->headers_count == 0 && ctx->main_count == 1) {
+			ctx->code_start = ctx->tmp_code_start;
+			ctx->got_start = 1;
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 0 && ctx->headers_count > 0 && ctx->main_count == 1) {
+			ctx->seek_end = 1;
+			ctx->headers_count = 0;
+			ctx->main_count = 0;
+		}
+
+		if (ctx->seek_end == 1 && (ctx->headers_count > 0 || ctx->main_count > 0)) {
+			ctx->code_end = ctx->tmp_code_start;
+			ctx->got_end = 1;
+			if (ctx->headers_count == 0)
+				ctx->seek_end = 1;
+			else
+				ctx->seek_end = 0;
+			break;
+		}
+
+		in++;
+		(*consumed)++;
+	}
+
+	*frame_size = 0;
+
+	if (ctx->got_end == 1) {
+		frame_length = ctx->code_end;
+	} else
+		frame_length = *consumed;
+
+
+	if (ctx->code_start >= 0) {
+		frame_length -= ctx->code_start;
+		in = in_orig + ctx->code_start;
+	} else {
+		memcpy(out, ctx->bytes, -ctx->code_start);
+		*frame_size += -ctx->code_start;
+		out += -ctx->code_start;
+		in_size -= -ctx->code_start;
+		in = in_orig;
+	}
+
+	if (ctx->got_start) {
+		if (out_size < frame_length) {
+			err("Output buffer too small for current frame");
+			return 0;
+		}
+
+		memcpy(out, in, frame_length);
+		*frame_size += frame_length;
+
+		if (ctx->got_end) {
+			ctx->code_start = ctx->code_end - *consumed;
+			ctx->got_start = 1;
+			ctx->got_end = 0;
+			frame_finished = 1;
+			if (ctx->last_tag == MPEG4_TAG_VOP) {
+				ctx->seek_end = 1;
+				ctx->main_count = 0;
+				ctx->headers_count = 0;
+			} else {
+				ctx->seek_end = 0;
+				ctx->main_count = 0;
+				ctx->headers_count = 1;
+			}
+			memcpy(ctx->bytes, in_orig + ctx->code_end, *consumed - ctx->code_end);
+		} else {
+			ctx->code_start = 0;
+			frame_finished = 0;
+		}
+	}
+
+	ctx->tmp_code_start -= *consumed;
+
+	return frame_finished;
+}
+
diff --git a/parser.h b/parser.h
new file mode 100644
index 0000000..492d12a
--- /dev/null
+++ b/parser.h
@@ -0,0 +1,96 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Really simple stream parser header file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#ifndef INCLUDE_PARSER_H
+#define INCLUDE_PARSER_H
+
+/* H264 parser states */
+enum mfc_h264_parser_state {
+	H264_PARSER_NO_CODE,
+	H264_PARSER_CODE_0x1,
+	H264_PARSER_CODE_0x2,
+	H264_PARSER_CODE_0x3,
+	H264_PARSER_CODE_1x1,
+	H264_PARSER_CODE_SLICE,
+	H264_PARSER_CODE_TAG_SLICE,
+};
+
+/* H264 recent tag type */
+enum mfc_h264_tag_type {
+	H264_TAG_HEAD,
+	H264_TAG_SLICE,
+};
+
+/* MPEG4 parser states */
+enum mfc_mpeg4_parser_state {
+	MPEG4_PARSER_NO_CODE,
+	MPEG4_PARSER_CODE_0x1,
+	MPEG4_PARSER_CODE_0x2,
+	MPEG4_PARSER_CODE_1x1,
+};
+
+/* MPEG4 recent tag type */
+enum mfc_mpeg4_tag_type {
+	MPEG4_TAG_HEAD,
+	MPEG4_TAG_VOP,
+};
+
+/* Parser context */
+struct mfc_parser_context {
+	int state;
+	int last_tag;
+	char bytes[6];
+	int main_count;
+	int headers_count;
+	int tmp_code_start;
+	int code_start;
+	int code_end;
+	char got_start;
+	char got_end;
+	char seek_end;
+	int short_header;
+};
+
+/* Initialize the stream parser */
+int parse_stream_init(struct mfc_parser_context *ctx);
+
+/* Parser the stream:
+ * - consumed is used to return the number of bytes consumed from the output
+ * - frame_size is used to return the size of the frame that has been extracted
+ * - get_head - when equal to 1 it is used to extract the stream header wehn
+ *   setting up MFC
+ * Return value: 1 - if a complete frame has been extracted, 0 otherwise
+ */
+int parse_mpeg4_stream(struct mfc_parser_context *ctx,
+        char* in, int in_size, char* out, int out_size,
+        int *consumed, int *frame_size, char get_head);
+
+int parse_h264_stream(struct mfc_parser_context *ctx,
+        char* in, int in_size, char* out, int out_size,
+        int *consumed, int *frame_size, char get_head);
+
+int parse_mpeg2_stream(struct mfc_parser_context *ctx,
+        char* in, int in_size, char* out, int out_size,
+        int *consumed, int *frame_size, char get_head);
+
+#endif /* PARSER_H_ */
+
diff --git a/queue.c b/queue.c
new file mode 100644
index 0000000..5649fc2
--- /dev/null
+++ b/queue.c
@@ -0,0 +1,89 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Queue handling
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include "common.h"
+#include "queue.h"
+
+#include <pthread.h>
+#include <stdlib.h>
+
+int queue_init(struct queue *q, int size)
+{
+	q->q = (int*)malloc(size * sizeof(int));
+	if (!q->q) {
+		err("Failed to init queue (malloc failed)");
+		return -1;
+	}
+	q->size = size;
+	q->head = 0;
+	q->tail = 0;
+	q->n = 0;
+	pthread_mutex_init(&q->mutex, NULL);
+	return 0;
+}
+
+int queue_add(struct queue *q, int e)
+{
+	pthread_mutex_lock(&q->mutex);
+	if (q->n >= q->size) {
+		pthread_mutex_unlock(&q->mutex);
+		return -1;
+	}
+	q->q[q->head] = e;
+	q->head++;
+	q->head %= q->size;
+	q->n++;
+	pthread_mutex_unlock(&q->mutex);
+	return 0;
+}
+
+int queue_remove(struct queue *q)
+{
+	int x;
+	pthread_mutex_lock(&q->mutex);
+	if (q->n == 0) {
+		pthread_mutex_unlock(&q->mutex);
+		return -1;
+	}
+	x = q->q[q->tail];
+	q->tail++;
+	q->tail %= q->size;
+	q->n--;
+	pthread_mutex_unlock(&q->mutex);
+	return x;
+}
+
+int queue_empty(struct queue *q)
+{
+	int x;
+	pthread_mutex_lock(&q->mutex);
+	x = (q->n == 0);
+	pthread_mutex_unlock(&q->mutex);
+	return x;
+}
+
+void queue_free(struct queue *q)
+{
+	free(q->q);
+	pthread_mutex_destroy(&q->mutex);
+}
+
diff --git a/queue.h b/queue.h
new file mode 100644
index 0000000..531020f
--- /dev/null
+++ b/queue.h
@@ -0,0 +1,49 @@
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ * Queue handling header file
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#ifndef INCLUDE_QUEUE_H
+#define INCLUDE_QUEUE_H
+
+#include <pthread.h>
+
+struct queue {
+	int size;
+	int head;
+	int tail;
+	int n;
+	int *q;
+	pthread_mutex_t mutex;
+};
+
+/* Initialize queue and allocate memory */
+int queue_init(struct queue *q, int size);
+/* Add an element to the queue */
+int queue_add(struct queue *q, int e);
+/* Remove the element form queue */
+int queue_remove(struct queue *q);
+/* Free the internal queue memory */
+void queue_free(struct queue *q);
+/* Check if the queue is empty */
+int queue_empty(struct queue *q);
+
+#endif /* INCLUDE_QUEUE_H */
+
diff --git a/video.c b/video.c
index bb8ae8e..a8f240a 100644
--- a/video.c
+++ b/video.c
@@ -1,1351 +1,481 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- * Copyright (c) 2015 Linaro Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-#include <assert.h>
-#include <fcntl.h>
-#include <string.h>
-#include <endian.h>
-#include <sys/mman.h>
-#include <sys/ioctl.h>
-#include <sys/stat.h>
-#include <sys/types.h>
-#include <unistd.h>
-#include <errno.h>
-
-#include <linux/videodev2.h>
-#include <linux/ion.h>
-#include <linux/msm_ion.h>
-#include <media/msm_vidc.h>
-
-#include "common.h"
-
-#define DBG_TAG "   vid"
-
-#define CASE(ENUM) case ENUM: return #ENUM;
-
-#define EXTRADATA_IDX(__num_planes) ((__num_planes) ? (__num_planes) - 1 : 0)
-
-static const struct {
-	uint32_t mask;
-	const char *str;
-} v4l2_buf_flags[] = {
-	{ V4L2_BUF_FLAG_MAPPED, "MAPPED" },
-	{ V4L2_BUF_FLAG_QUEUED, "QUEUED" },
-	{ V4L2_BUF_FLAG_DONE, "DONE" },
-	{ V4L2_BUF_FLAG_KEYFRAME, "KEYFRAME" },
-	{ V4L2_BUF_FLAG_PFRAME, "PFRAME" },
-	{ V4L2_BUF_FLAG_BFRAME, "BFRAME" },
-	{ V4L2_BUF_FLAG_ERROR, "ERROR" },
-	{ V4L2_BUF_FLAG_TIMECODE, "TIMECODE" },
-	{ V4L2_BUF_FLAG_PREPARED, "PREPARED" },
-	{ V4L2_BUF_FLAG_NO_CACHE_INVALIDATE, "NO_CACHE_INVALIDATE" },
-	{ V4L2_BUF_FLAG_NO_CACHE_CLEAN, "NO_CACHE_CLEAN" },
-	{ V4L2_BUF_FLAG_TIMESTAMP_UNKNOWN, "TIMESTAMP_UNKNOWN" },
-	{ V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC, "TIMESTAMP_MONOTONIC" },
-	{ V4L2_BUF_FLAG_TIMESTAMP_COPY, "TIMESTAMP_COPY" },
-	{ V4L2_BUF_FLAG_TSTAMP_SRC_EOF, "TSTAMP_SRC_EOF" },
-	{ V4L2_BUF_FLAG_TSTAMP_SRC_SOE, "TSTAMP_SRC_SOE" },
-	{ V4L2_QCOM_BUF_FLAG_CODECCONFIG, "QCOM_CODECCONFIG" },
-	{ V4L2_QCOM_BUF_FLAG_EOSEQ, "QCOM_EOSEQ" },
-	{ V4L2_QCOM_BUF_TIMESTAMP_INVALID, "QCOM_TIMESTAMP_INVALID" },
-	{ V4L2_QCOM_BUF_FLAG_IDRFRAME, "QCOM_IDRFRAME" },
-	{ V4L2_QCOM_BUF_FLAG_DECODEONLY, "QCOM_DECODEONLY" },
-	{ V4L2_QCOM_BUF_DATA_CORRUPT, "QCOM_DATA_CORRUPT" },
-	{ V4L2_QCOM_BUF_DROP_FRAME, "QCOM_DROP_FRAME" },
-	{ V4L2_QCOM_BUF_INPUT_UNSUPPORTED, "QCOM_INPUT_UNSUPPORTED" },
-	{ V4L2_QCOM_BUF_FLAG_EOS, "QCOM_EOS" },
-	{ V4L2_QCOM_BUF_FLAG_READONLY, "QCOM_READONLY" },
-	{ V4L2_MSM_VIDC_BUF_START_CODE_NOT_FOUND, "MSM_START_CODE_NOT_FOUND" },
-	{ V4L2_MSM_BUF_FLAG_YUV_601_709_CLAMP, "MSM_YUV_601_709_CLAMP" },
-	{ V4L2_MSM_BUF_FLAG_MBAFF, "MSM_MBAFF" },
-	{ V4L2_MSM_BUF_FLAG_DEFER, "MSM_DEFER" },
-};
-
-static const char *buf_flags_to_string(uint32_t flags)
-{
-	static __thread char s[256];
-	size_t n = 0;
-
-	for (size_t i = 0; i < ARRAY_LENGTH(v4l2_buf_flags); i++) {
-		if (flags & v4l2_buf_flags[i].mask) {
-			n += snprintf(s + n, sizeof (s) - n, "%s%s",
-				      n > 0 ? "|" : "",
-				      v4l2_buf_flags[i].str);
-			if (n >= sizeof (s))
-				break;
-		}
-	}
-
-	s[MIN(n, sizeof (s) - 1)] = '\0';
-
-	return s;
-}
-
-static const char *fourcc_to_string(uint32_t fourcc)
-{
-	static __thread char s[4];
-	uint32_t fmt = htole32(fourcc);
-
-	memcpy(s, &fmt, 4);
-
-	return s;
-}
-
-static const char *buf_type_to_string(enum v4l2_buf_type type)
-{
-	switch (type) {
-	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
-	case V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:
-		return "OUTPUT";
-	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
-	case V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:
-		return "CAPTURE";
-	default:
-		return "??";
-	}
-}
-
-static const char *v4l2_field_to_string(enum v4l2_field field)
-{
-	switch (field) {
-	CASE(V4L2_FIELD_ANY)
-	CASE(V4L2_FIELD_NONE)
-	CASE(V4L2_FIELD_TOP)
-	CASE(V4L2_FIELD_BOTTOM)
-	CASE(V4L2_FIELD_INTERLACED)
-	CASE(V4L2_FIELD_SEQ_TB)
-	CASE(V4L2_FIELD_SEQ_BT)
-	CASE(V4L2_FIELD_ALTERNATE)
-	CASE(V4L2_FIELD_INTERLACED_TB)
-	CASE(V4L2_FIELD_INTERLACED_BT)
-	default: return "unknown";
-	}
-}
-
-static const char *v4l2_colorspace_to_string(enum v4l2_colorspace cspace)
-{
-	switch (cspace) {
-	CASE(V4L2_COLORSPACE_SMPTE170M)
-	CASE(V4L2_COLORSPACE_SMPTE240M)
-	CASE(V4L2_COLORSPACE_REC709)
-	CASE(V4L2_COLORSPACE_BT878)
-	CASE(V4L2_COLORSPACE_470_SYSTEM_M)
-	CASE(V4L2_COLORSPACE_470_SYSTEM_BG)
-	CASE(V4L2_COLORSPACE_JPEG)
-	CASE(V4L2_COLORSPACE_SRGB)
-	default: return "unknown";
-	}
-}
-
-static const char *extradata_type_to_string(int type)
-{
-	switch (type) {
-	CASE(MSM_VIDC_EXTRADATA_NONE)
-	CASE(MSM_VIDC_EXTRADATA_MB_QUANTIZATION)
-	CASE(MSM_VIDC_EXTRADATA_INTERLACE_VIDEO)
-	CASE(MSM_VIDC_EXTRADATA_VC1_FRAMEDISP)
-	CASE(MSM_VIDC_EXTRADATA_VC1_SEQDISP)
-	CASE(MSM_VIDC_EXTRADATA_TIMESTAMP)
-	CASE(MSM_VIDC_EXTRADATA_S3D_FRAME_PACKING)
-	CASE(MSM_VIDC_EXTRADATA_FRAME_RATE)
-	CASE(MSM_VIDC_EXTRADATA_PANSCAN_WINDOW)
-	CASE(MSM_VIDC_EXTRADATA_RECOVERY_POINT_SEI)
-	CASE(MSM_VIDC_EXTRADATA_MPEG2_SEQDISP)
-	CASE(MSM_VIDC_EXTRADATA_STREAM_USERDATA)
-	CASE(MSM_VIDC_EXTRADATA_FRAME_QP)
-	CASE(MSM_VIDC_EXTRADATA_FRAME_BITS_INFO)
-	CASE(MSM_VIDC_EXTRADATA_VQZIP_SEI)
-	CASE(MSM_VIDC_EXTRADATA_ROI_QP)
-	CASE(MSM_VIDC_EXTRADATA_MASTERING_DISPLAY_COLOUR_SEI)
-	CASE(MSM_VIDC_EXTRADATA_CONTENT_LIGHT_LEVEL_SEI)
-	CASE(MSM_VIDC_EXTRADATA_PQ_INFO)
-	CASE(MSM_VIDC_EXTRADATA_INPUT_CROP)
-	CASE(MSM_VIDC_EXTRADATA_OUTPUT_CROP)
-	CASE(MSM_VIDC_EXTRADATA_DIGITAL_ZOOM)
-	CASE(MSM_VIDC_EXTRADATA_VPX_COLORSPACE_INFO)
-	CASE(MSM_VIDC_EXTRADATA_MULTISLICE_INFO)
-	CASE(MSM_VIDC_EXTRADATA_NUM_CONCEALED_MB)
-	CASE(MSM_VIDC_EXTRADATA_INDEX)
-	CASE(MSM_VIDC_EXTRADATA_ASPECT_RATIO)
-	CASE(MSM_VIDC_EXTRADATA_METADATA_LTR)
-	CASE(MSM_VIDC_EXTRADATA_METADATA_FILLER)
-	CASE(MSM_VIDC_EXTRADATA_METADATA_MBI)
-	CASE(MSM_VIDC_EXTRADATA_VUI_DISPLAY_INFO)
-	CASE(MSM_VIDC_EXTRADATA_YUVSTATS_INFO)
-	default: return "Unknown";
-	}
-}
-
-static const char *extradata_interlace_format_to_string(enum msm_vidc_interlace_type format)
-{
-	switch (format) {
-	CASE(MSM_VIDC_INTERLACE_FRAME_PROGRESSIVE)
-	CASE(MSM_VIDC_INTERLACE_INTERLEAVE_FRAME_TOPFIELDFIRST)
-	CASE(MSM_VIDC_INTERLACE_INTERLEAVE_FRAME_BOTTOMFIELDFIRST)
-	CASE(MSM_VIDC_INTERLACE_FRAME_TOPFIELDFIRST)
-	CASE(MSM_VIDC_INTERLACE_FRAME_BOTTOMFIELDFIRST)
-	default : return "Unknown";
-	}
-}
-
-static const char *extradata_interlace_color_format_to_string(unsigned int format)
-{
-	switch (format) {
-	CASE(MSM_VIDC_HAL_INTERLACE_COLOR_FORMAT_NV12)
-	CASE(MSM_VIDC_HAL_INTERLACE_COLOR_FORMAT_NV12_UBWC)
-	default: return "Unknown";
-	}
-}
-
-#undef CASE
-
-static void list_formats(struct instance *i, enum v4l2_buf_type type)
-{
-	struct v4l2_fmtdesc fdesc;
-	struct v4l2_frmsizeenum frmsize;
-
-	dbg("%s formats:", buf_type_to_string(type));
-
-	memzero(fdesc);
-	fdesc.type = type;
-
-	while (!ioctl(i->video.fd, VIDIOC_ENUM_FMT, &fdesc)) {
-		dbg("  %s", fdesc.description);
-
-		memzero(frmsize);
-		frmsize.pixel_format = fdesc.pixelformat;
-
-		while (!ioctl(i->video.fd, VIDIOC_ENUM_FRAMESIZES, &frmsize)) {
-			switch (frmsize.type) {
-			case V4L2_FRMSIZE_TYPE_DISCRETE:
-				dbg("    %dx%d",
-				    frmsize.discrete.width,
-				    frmsize.discrete.height);
-				break;
-			case V4L2_FRMSIZE_TYPE_STEPWISE:
-			case V4L2_FRMSIZE_TYPE_CONTINUOUS:
-				dbg("    %dx%d to %dx%d, step %+d%+d",
-				    frmsize.stepwise.min_width,
-				    frmsize.stepwise.min_height,
-				    frmsize.stepwise.max_width,
-				    frmsize.stepwise.max_height,
-				    frmsize.stepwise.step_width,
-				    frmsize.stepwise.step_height);
-				break;
-			}
-
-			if (frmsize.type != V4L2_FRMSIZE_TYPE_DISCRETE)
-				break;
-
-			frmsize.index++;
-		}
-
-		fdesc.index++;
-	}
-}
-
-int video_open(struct instance *i, char *name)
-{
-	struct v4l2_capability cap;
-
-	i->video.fd = open(name, O_RDWR, 0);
-	if (i->video.fd < 0) {
-		err("Failed to open video decoder: %s", name);
-		return -1;
-	}
-
-	memzero(cap);
-	if (ioctl(i->video.fd, VIDIOC_QUERYCAP, &cap) < 0) {
-		err("Failed to verify capabilities: %m");
-		return -1;
-	}
-
-	dbg("caps (%s): driver=\"%s\" bus_info=\"%s\" card=\"%s\" "
-	    "version=%u.%u.%u", name, cap.driver, cap.bus_info, cap.card,
-	    (cap.version >> 16) & 0xff,
-	    (cap.version >> 8) & 0xff,
-	    cap.version & 0xff);
-
-	dbg("  [%c] V4L2_CAP_VIDEO_CAPTURE",
-	    cap.capabilities & V4L2_CAP_VIDEO_CAPTURE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_CAPTURE_MPLANE",
-	    cap.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_OUTPUT",
-	    cap.capabilities & V4L2_CAP_VIDEO_OUTPUT ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_OUTPUT_MPLANE",
-	    cap.capabilities & V4L2_CAP_VIDEO_OUTPUT_MPLANE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_M2M",
-	    cap.capabilities & V4L2_CAP_VIDEO_M2M ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_M2M_MPLANE",
-	    cap.capabilities & V4L2_CAP_VIDEO_M2M_MPLANE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_OVERLAY",
-	    cap.capabilities & V4L2_CAP_VIDEO_OVERLAY ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VBI_CAPTURE",
-	    cap.capabilities & V4L2_CAP_VBI_CAPTURE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VBI_OUTPUT",
-	    cap.capabilities & V4L2_CAP_VBI_OUTPUT ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_SLICED_VBI_CAPTURE",
-	    cap.capabilities & V4L2_CAP_SLICED_VBI_CAPTURE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_SLICED_VBI_OUTPUT",
-	    cap.capabilities & V4L2_CAP_SLICED_VBI_OUTPUT ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_RDS_CAPTURE",
-	    cap.capabilities & V4L2_CAP_RDS_CAPTURE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_VIDEO_OUTPUT_OVERLAY",
-	    cap.capabilities & V4L2_CAP_VIDEO_OUTPUT_OVERLAY ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_HW_FREQ_SEEK",
-	    cap.capabilities & V4L2_CAP_HW_FREQ_SEEK ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_RDS_OUTPUT",
-	    cap.capabilities & V4L2_CAP_RDS_OUTPUT ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_TUNER",
-	    cap.capabilities & V4L2_CAP_TUNER ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_AUDIO",
-	    cap.capabilities & V4L2_CAP_AUDIO ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_RADIO",
-	    cap.capabilities & V4L2_CAP_RADIO ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_MODULATOR",
-	    cap.capabilities & V4L2_CAP_MODULATOR ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_SDR_CAPTURE",
-	    cap.capabilities & V4L2_CAP_SDR_CAPTURE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_EXT_PIX_FORMAT",
-	    cap.capabilities & V4L2_CAP_EXT_PIX_FORMAT ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_READWRITE",
-	    cap.capabilities & V4L2_CAP_READWRITE ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_ASYNCIO",
-	    cap.capabilities & V4L2_CAP_ASYNCIO ? '*' : ' ');
-	dbg("  [%c] V4L2_CAP_STREAMING",
-	    cap.capabilities & V4L2_CAP_STREAMING ? '*' : ' ');
-
-	if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE) ||
-	    !(cap.capabilities & V4L2_CAP_VIDEO_OUTPUT_MPLANE) ||
-	    !(cap.capabilities & V4L2_CAP_STREAMING)) {
-		err("Insufficient capabilities for video device (is %s correct?)",
-		    name);
-		return -1;
-	}
-
-	list_formats(i, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
-	list_formats(i, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
-
-        return 0;
-}
-
-void video_close(struct instance *i)
-{
-	close(i->video.fd);
-}
-
-int video_set_secure(struct instance *i)
-{
-	struct v4l2_control control = {0};
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_SECURE;
-	control.value = 1;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to set secure mode: %m");
-		return -1;
-	}
-
-	return 0;
-}
-
-int video_set_control(struct instance *i)
-{
-	struct v4l2_control control = {0};
-
-	if (i->decode_order) {
-		control.id = V4L2_CID_MPEG_VIDC_VIDEO_OUTPUT_ORDER;
-		control.value = V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DECODE;
-
-		if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-			err("failed to set output order: %m");
-			return -1;
-		}
-	}
-
-	if (i->skip_frames) {
-		control.id = V4L2_CID_MPEG_VIDC_VIDEO_PICTYPE_DEC_MODE;
-		control.value = V4L2_MPEG_VIDC_VIDEO_PICTYPE_DECODE_ON;
-
-		if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-			err("failed to set skip mode: %m");
-			return -1;
-		}
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_CONTINUE_DATA_TRANSFER;
-	control.value = i->continue_data_transfer;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to set data transfer mode: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_SET_PERF_LEVEL;
-	control.value = V4L2_CID_MPEG_VIDC_PERF_LEVEL_TURBO;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to set perf level: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_CONCEAL_COLOR;
-	control.value = 0x00ff;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to set conceal color: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
-	control.value = V4L2_MPEG_VIDC_EXTRADATA_INTERLACE_VIDEO;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to enable interlace extradata: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
-	control.value = V4L2_MPEG_VIDC_EXTRADATA_OUTPUT_CROP;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to enable output crop extradata: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
-	control.value = V4L2_MPEG_VIDC_EXTRADATA_ASPECT_RATIO;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to enable aspect ratio extradata: %m");
-		return -1;
-	}
-
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
-	control.value = V4L2_MPEG_VIDC_EXTRADATA_FRAME_RATE;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to enable framerate extradata: %m");
-		return -1;
-	}
-
-#if 0
-	/* FIXME : Use this when QCOM has fixed the bug */
-	control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
-	control.value = V4L2_MPEG_VIDC_EXTRADATA_DISPLAY_COLOUR_SEI;
-
-	if (ioctl(i->video.fd, VIDIOC_S_CTRL, &control) < 0) {
-		err("failed to enable display colour sei extradata: %m");
-		return -1;
-	}
-#endif
-
-	return 0;
-}
-
-int video_set_dpb(struct instance *i,
-		  enum v4l2_mpeg_vidc_video_dpb_color_format format)
-{
-	struct v4l2_ext_control control[2] = {0};
-	struct v4l2_ext_controls controls = {0};
-
-	control[0].id = V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_MODE;
-	control[0].value = V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_PRIMARY;
-
-	control[1].id = V4L2_CID_MPEG_VIDC_VIDEO_DPB_COLOR_FORMAT;
-	control[1].value = format;
-
-	controls.count = 2;
-	controls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
-	controls.controls = control;
-
-	if (ioctl(i->video.fd, VIDIOC_S_EXT_CTRLS, &controls) < 0) {
-		err("failed to set dpb format: %m");
-		return -1;
-	}
-
-	return 0;
-}
-
-int video_set_framerate(struct instance *i, int num, int den)
-{
-	struct v4l2_streamparm parm;
-
-	dbg("set framerate to %.3f", (float)num / (float)den);
-
-	memzero(parm);
-	parm.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-	parm.parm.output.timeperframe.numerator = den;
-	parm.parm.output.timeperframe.denominator = num;
-
-	if (ioctl(i->video.fd, VIDIOC_S_PARM, &parm) < 0) {
-		err("Failed to set framerate on OUTPUT: %m");
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-check_extradata_payload(enum msm_vidc_extradata_type type, void *data, int size)
-{
-	switch (type) {
-	case MSM_VIDC_EXTRADATA_OUTPUT_CROP: {
-		struct msm_vidc_output_crop_payload *payload = data;
-
-		if (size != sizeof (*payload)) {
-			dbg("extradata: Invalid data size for %s",
-			    extradata_type_to_string(type));
-			return -1;
-		}
-
-		dbg("extradata: %s top=%u left=%u "
-		    "display_width=%u display_height=%u width=%u height=%u",
-		    extradata_type_to_string(type),
-		    payload->top, payload->left,
-		    payload->display_width, payload->display_height,
-		    payload->width, payload->height);
-		break;
-	}
-
-	case MSM_VIDC_EXTRADATA_ASPECT_RATIO: {
-		struct msm_vidc_aspect_ratio_payload *payload = data;
-
-		if (size != sizeof (*payload)) {
-			dbg("extradata: Invalid data size for %s",
-			    extradata_type_to_string(type));
-			return -1;
-		}
-
-		dbg("extradata: %s aspect_width=%u aspect_height=%u",
-		    extradata_type_to_string(type),
-		    payload->aspect_width, payload->aspect_height);
-		break;
-	}
-
-	case MSM_VIDC_EXTRADATA_INTERLACE_VIDEO: {
-		struct msm_vidc_interlace_payload *payload = data;
-
-		if (size != sizeof (*payload)) {
-			dbg("extradata: Invalid data size for %s",
-			    extradata_type_to_string(type));
-			return -1;
-		}
-
-		dbg("extradata: %s format=%s color_format=%s",
-		    extradata_type_to_string(type),
-		    extradata_interlace_format_to_string(payload->format),
-		    extradata_interlace_color_format_to_string(payload->color_format));
-		break;
-	}
-
-	case MSM_VIDC_EXTRADATA_MASTERING_DISPLAY_COLOUR_SEI: {
-		struct msm_vidc_mastering_display_colour_sei_payload *payload = data;
-
-		if (size != sizeof (*payload)) {
-			dbg("extradata: Invalid data size for %s",
-			    extradata_type_to_string(type));
-			return -1;
-		}
-
-		dbg("extradata: %s nDisplayPrimariesX={%u, %u, %u} "
-		    "nDisplayPrimariesY={%u, %u, %u} nWhitePointX=%u "
-		    "nWhitePointY=%u nMaxDisplayMasteringLuminance=%u"
-		    "nMinDisplayMasteringLuminance=%u",
-		    extradata_type_to_string(type),
-		    payload->nDisplayPrimariesX[0],
-		    payload->nDisplayPrimariesX[1],
-		    payload->nDisplayPrimariesX[2],
-		    payload->nDisplayPrimariesY[0],
-		    payload->nDisplayPrimariesY[1],
-		    payload->nDisplayPrimariesY[2],
-		    payload->nWhitePointX,
-		    payload->nWhitePointY,
-		    payload->nMaxDisplayMasteringLuminance,
-		    payload->nMinDisplayMasteringLuminance);
-		break;
-	}
-
-	case MSM_VIDC_EXTRADATA_FRAME_RATE: {
-		struct msm_vidc_framerate_payload *payload = data;
-
-		if (size != sizeof (*payload)) {
-			dbg("extradata: Invalid data size for %s",
-			    extradata_type_to_string(type));
-			return -1;
-		}
-
-		int framerate_num = payload->frame_rate;
-		int framerate_den = 0x10000;
-
-		dbg("extradata: %s frame_rate=%.3f",
-		    extradata_type_to_string(type),
-		    (float)framerate_num / (float)framerate_den);
-		break;
-	}
-
-	default:
-		err("extradata: unhandled extradata header %s (%u)",
-		    extradata_type_to_string(type), type);
-		return -1;
-	}
-
-	return 0;
-}
-
-bool
-extradata_header_is_valid(const struct msm_vidc_extradata_header *hdr, int size)
-{
-	unsigned int left;
-	int ret;
-
-	if (!hdr || size < 0)
-		return false;
-
-	left = size;
-
-	while (left > sizeof (*hdr) && left >= hdr->size &&
-	       hdr->type != MSM_VIDC_EXTRADATA_NONE) {
-		if (hdr->type == MSM_VIDC_EXTRADATA_INDEX) {
-			struct msm_vidc_extradata_index *payload = (void *)hdr->data;
-			ret = check_extradata_payload(payload->type,
-						      (void *)hdr->data + sizeof (hdr->type),
-						      hdr->data_size - sizeof (hdr->type));
-		} else {
-			ret = check_extradata_payload(hdr->type,
-						      (void *)hdr->data,
-						      hdr->data_size);
-		}
-
-		if (ret)
-			return false;
-
-		left -= hdr->size;
-		hdr = (void *)hdr + hdr->size;
-	}
-
-	return true;
-}
-
-void *
-extradata_header_find(const struct msm_vidc_extradata_header *hdr, int type)
-{
-	while (hdr && hdr->type != MSM_VIDC_EXTRADATA_NONE) {
-		if (hdr->type == (unsigned)type)
-			return (void *)hdr->data;
-
-		if (hdr->type == MSM_VIDC_EXTRADATA_INDEX) {
-			struct msm_vidc_extradata_index *payload =
-				(void *)hdr->data;
-			if (type == (int)payload->type)
-				return (void *)hdr->data + sizeof (hdr->type);
-		}
-
-		hdr = (void *)hdr + hdr->size;
-	}
-
-	return NULL;
-}
-
-static int video_count_capture_queued_bufs(struct video *vid)
-{
-	int cap_queued = 0;
-
-	for (int idx = 0; idx < vid->cap_buf_cnt; idx++) {
-		if (vid->cap_buf_flag[idx])
-			cap_queued++;
-	}
-
-	return cap_queued;
-}
-
-static int video_count_output_queued_bufs(struct video *vid)
-{
-	int out_queued = 0;
-
-	for (int idx = 0; idx < vid->out_buf_cnt; idx++) {
-		if (vid->out_buf_flag[idx])
-			out_queued++;
-	}
-
-	return out_queued;
-}
-
-int video_queue_buf_out(struct instance *i, int n, int length,
-			uint32_t flags, struct timeval timestamp)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_buffer buf;
-	struct v4l2_plane planes[1];
-
-	type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-
-	if (n >= vid->out_buf_cnt) {
-		err("tried to queue a non existing %s buffer",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	memzero(buf);
-	memset(planes, 0, sizeof(planes));
-	buf.type = type;
-	buf.memory = V4L2_MEMORY_USERPTR;
-	buf.index = n;
-	buf.length = 1;
-	buf.m.planes = planes;
-
-	buf.m.planes[0].m.userptr = (unsigned long)vid->out_ion_addr;
-	buf.m.planes[0].reserved[0] = vid->out_ion_fd;
-	buf.m.planes[0].reserved[1] = vid->out_buf_off[n];
-	buf.m.planes[0].length = vid->out_buf_size;
-	buf.m.planes[0].bytesused = length;
-	buf.m.planes[0].data_offset = 0;
-
-	buf.flags = flags;
-	buf.timestamp = timestamp;
-
-	if (ioctl(vid->fd, VIDIOC_QBUF, &buf) < 0) {
-		err("failed to queue %s buffer (index=%d): %m",
-		    buf_type_to_string(buf.type), buf.index);
-		return -1;
-	}
-
-	dbg("%s: queued buffer %d (flags:%08x:%s, bytesused:%d, "
-	    "ts: %ld.%06lu), %d/%d queued", buf_type_to_string(buf.type),
-	    buf.index, buf.flags, buf_flags_to_string(buf.flags),
-	    buf.m.planes[0].bytesused,
-	    buf.timestamp.tv_sec, buf.timestamp.tv_usec,
-	    video_count_output_queued_bufs(vid), vid->out_buf_cnt);
-
-	return 0;
-}
-
-int video_queue_buf_cap(struct instance *i, int n)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_buffer buf;
-	struct v4l2_plane planes[2];
-
-	type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-
-	if (n >= vid->cap_buf_cnt) {
-		err("tried to queue a non existing %s buffer",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	memzero(buf);
-	memset(planes, 0, sizeof(planes));
-	buf.type = type;
-	buf.memory = V4L2_MEMORY_USERPTR;
-	buf.index = n;
-	buf.length = 2;
-	buf.m.planes = planes;
-
-	buf.m.planes[0].m.userptr = i->secure ?
-		(unsigned long)vid->cap_buf_fd[n] :
-		(unsigned long)vid->cap_buf_addr[n];
-	buf.m.planes[0].reserved[0] = vid->cap_buf_fd[n];
-	buf.m.planes[0].reserved[1] = 0;
-	buf.m.planes[0].length = vid->cap_buf_size;
-	buf.m.planes[0].bytesused = vid->cap_buf_size;
-	buf.m.planes[0].data_offset = 0;
-
-	if (vid->extradata_index) { // Should be 1
-		buf.m.planes[vid->extradata_index].m.userptr = (unsigned long)vid->extradata_ion_addr;
-		buf.m.planes[vid->extradata_index].reserved[0] = vid->extradata_ion_fd;
-		buf.m.planes[vid->extradata_index].reserved[1] = vid->extradata_off[n];
-		buf.m.planes[vid->extradata_index].length = vid->extradata_size;
-		buf.m.planes[vid->extradata_index].bytesused = 0;
-		buf.m.planes[vid->extradata_index].data_offset = 0;
-	}
-
-	if (ioctl(vid->fd, VIDIOC_QBUF, &buf) < 0) {
-		err("failed to queue %s buffer (index=%d): %m",
-		    buf_type_to_string(buf.type), buf.index);
-		return -1;
-	}
-
-	vid->cap_buf_flag[n] = 1;
-
-	dbg("%s: queued buffer %d, %d/%d queued", buf_type_to_string(buf.type),
-	    buf.index, video_count_capture_queued_bufs(vid), vid->cap_buf_cnt);
-
-	return 0;
-}
-
-static int video_dequeue_buf(struct instance *i, struct v4l2_buffer *buf)
-{
-	struct video *vid = &i->video;
-	int ret;
-
-	ret = ioctl(vid->fd, VIDIOC_DQBUF, buf);
-	if (ret < 0) {
-		err("failed to dequeue buffer on %s queue: %m",
-		    buf_type_to_string(buf->type));
-		return -errno;
-	}
-
-	switch (buf->type) {
-	case V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:
-		dbg("%s: dequeued buffer %d, %d/%d queued",
-		    buf_type_to_string(buf->type), buf->index,
-		    video_count_output_queued_bufs(vid), vid->out_buf_cnt);
-		break;
-	case V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:
-		vid->cap_buf_flag[buf->index] = 0;
-		dbg("%s: dequeued buffer %d (flags:%08x:%s, bytesused:%d, "
-		    "ts: %ld.%06lu), %d/%d queued",
-		    buf_type_to_string(buf->type),
-		    buf->index, buf->flags, buf_flags_to_string(buf->flags),
-		    buf->m.planes[0].bytesused,
-		    buf->timestamp.tv_sec, buf->timestamp.tv_usec,
-		    video_count_capture_queued_bufs(vid), vid->cap_buf_cnt);
-		break;
-	}
-
-	return 0;
-}
-
-int video_dequeue_output(struct instance *i, int *n)
-{
-	struct v4l2_buffer buf;
-	struct v4l2_plane planes[OUT_PLANES];
-	int ret;
-
-	memzero(buf);
-	buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-	buf.memory = V4L2_MEMORY_USERPTR;
-	buf.m.planes = planes;
-	buf.length = OUT_PLANES;
-
-	ret = video_dequeue_buf(i, &buf);
-	if (ret < 0)
-		return ret;
-
-	*n = buf.index;
-
-	return 0;
-}
-
-int video_dequeue_capture(struct instance *i, int *n, unsigned int *bytesused,
-			  uint32_t *flags, struct timeval *ts,
-			  struct msm_vidc_extradata_header **extradata)
-{
-	struct video *vid = &i->video;
-	struct v4l2_buffer buf;
-	struct v4l2_plane planes[CAP_PLANES];
-	void *extradata_addr;
-	bool extradata_valid;
-
-	memzero(buf);
-	buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-	buf.memory = V4L2_MEMORY_USERPTR;
-	buf.m.planes = planes;
-	buf.length = CAP_PLANES;
-
-	if (video_dequeue_buf(i, &buf))
-		return -1;
-
-	*bytesused = buf.m.planes[0].bytesused;
-	*n = buf.index;
-
-	if (flags)
-		*flags = buf.flags;
-	if (ts)
-		*ts = buf.timestamp;
-
-	extradata_addr = NULL;
-	if (vid->extradata_index >= 0)
-		extradata_addr = vid->extradata_addr[buf.index];
-
-	extradata_valid = false;
-	if (extradata_addr)
-		extradata_valid = extradata_header_is_valid(extradata_addr,
-							    vid->extradata_size);
-
-	if (extradata)
-		*extradata = extradata_valid ? extradata_addr : NULL;
-
-	return 0;
-}
-
-int video_stream(struct instance *i, enum v4l2_buf_type type, int status)
-{
-	struct video *vid = &i->video;
-	int ret;
-
-	ret = ioctl(vid->fd, status, &type);
-	if (ret) {
-		err("failed to stream on %s queue (status=%d)",
-		    buf_type_to_string(type), status);
-		return -1;
-	}
-
-	dbg("%s: stream %s", buf_type_to_string(type),
-	    status == VIDIOC_STREAMON ? "ON" :
-	    status == VIDIOC_STREAMOFF ? "OFF" : "??");
-
-	return 0;
-}
-
-int video_flush(struct instance *i, uint32_t flags)
-{
-	struct video *vid = &i->video;
-	struct v4l2_decoder_cmd dec;
-
-	if (flags & V4L2_QCOM_CMD_FLUSH_CAPTURE)
-		dbg("flushing CAPTURE queue");
-
-	if (flags & V4L2_QCOM_CMD_FLUSH_OUTPUT)
-		dbg("flushing OUTPUT queue");
-
-	memzero(dec);
-	dec.flags = flags;
-	dec.cmd = V4L2_DEC_QCOM_CMD_FLUSH;
-	if (ioctl(vid->fd, VIDIOC_DECODER_CMD, &dec) < 0) {
-		err("failed to flush: %m");
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-alloc_ion_buffer(struct instance *i, size_t size, uint32_t flags)
-{
-	struct ion_allocation_data ion_alloc = { 0 };
-	struct ion_fd_data ion_fd_data = { 0 };
-	struct ion_handle_data ion_handle_data = { 0 };
-	static int ion_fd = -1;
-	int ret;
-
-	if (ion_fd < 0) {
-		ion_fd = open("/dev/ion", O_RDONLY);
-		if (ion_fd < 0) {
-			err("Cannot open ion device: %m");
-			return -1;
-		}
-	}
-
-	ion_alloc.handle = -1;
-	ion_alloc.len = size;
-	ion_alloc.align = 4096;
-	ion_alloc.flags = flags;
-
-	if (flags & ION_SECURE)
-		ion_alloc.heap_id_mask = ION_HEAP(ION_SECURE_HEAP_ID);
-	else
-		ion_alloc.heap_id_mask = ION_HEAP(ION_IOMMU_HEAP_ID);
-
-	if (flags & ION_FLAG_CP_BITSTREAM)
-		ion_alloc.heap_id_mask |= ION_HEAP(ION_SECURE_DISPLAY_HEAP_ID);
-
-	if (ioctl(ion_fd, ION_IOC_ALLOC, &ion_alloc) < 0) {
-		err("Failed to allocate ion buffer: %m");
-		return -1;
-	}
-
-	dbg("Allocated %zd bytes ION buffer %d",
-	    ion_alloc.len, ion_alloc.handle);
-
-	ion_fd_data.handle = ion_alloc.handle;
-	ion_fd_data.fd = -1;
-
-	if (ioctl(ion_fd, ION_IOC_MAP, &ion_fd_data) < 0) {
-		err("Failed to map ion buffer: %m");
-		ret = -1;
-	} else {
-		ret = ion_fd_data.fd;
-	}
-
-	ion_handle_data.handle = ion_alloc.handle;
-	if (ioctl(ion_fd, ION_IOC_FREE, &ion_handle_data) < 0)
-		err("Failed to free ion buffer: %m");
-
-	return ret;
-}
-
-static int setup_extradata(struct instance *i, int index, int size)
-{
-	struct video *vid = &i->video;
-	int off = 0;
-
-	vid->extradata_index = index;
-	vid->extradata_size = size;
-
-	if (vid->extradata_ion_fd < 0) {
-		vid->extradata_ion_fd = alloc_ion_buffer(i, size * MAX_CAP_BUF, 0);
-		vid->extradata_ion_addr = mmap(NULL,
-					       size * MAX_CAP_BUF,
-					       PROT_READ|PROT_WRITE,
-					       MAP_SHARED,
-					       vid->extradata_ion_fd,
-					       0);
-
-		for (int i = 0; i < MAX_CAP_BUF; i++) {
-			vid->extradata_off[i] = off;
-			vid->extradata_addr[i] = vid->extradata_ion_addr + off;
-			off += size;
-		}
-	}
-
-	return 0;
-}
-
-int video_setup_capture(struct instance *i, int num_buffers, int w, int h)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_format fmt;
-	struct v4l2_pix_format_mplane *pix;
-	struct v4l2_requestbuffers reqbuf;
-	int ion_fd;
-	uint32_t ion_flags;
-	void *buf_addr;
-	int n, extra_idx;
-
-	type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-
-	video_set_dpb(i, i->depth == 10 ?
-		      V4L2_MPEG_VIDC_VIDEO_DPB_COLOR_FMT_TP10_UBWC :
-		      V4L2_MPEG_VIDC_VIDEO_DPB_COLOR_FMT_NONE);
-
-	memzero(fmt);
-	fmt.type = type;
-	pix = &fmt.fmt.pix_mp;
-	pix->height = h;
-	pix->width = w;
-
-	if (i->depth == 10)
-		pix->pixelformat = V4L2_PIX_FMT_NV12_TP10_UBWC;
-	else if (!i->interlaced)
-		pix->pixelformat = V4L2_PIX_FMT_NV12_UBWC;
-	else
-		pix->pixelformat = V4L2_PIX_FMT_NV12;
-
-	if (ioctl(vid->fd, VIDIOC_S_FMT, &fmt) < 0) {
-		err("failed to set %s format (%dx%d)",
-		    buf_type_to_string(fmt.type), w, h);
-		return -1;
-	}
-
-	memzero(reqbuf);
-	reqbuf.count = num_buffers;
-	reqbuf.type = type;
-	reqbuf.memory = V4L2_MEMORY_USERPTR;
-
-	if (ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf) < 0) {
-		err("failed to request %s buffers: %m",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	dbg("%s: requested %d buffers, got %d", buf_type_to_string(type),
-	    num_buffers, reqbuf.count);
-
-	vid->cap_buf_cnt = reqbuf.count;
-
-	if (ioctl(vid->fd, VIDIOC_G_FMT, &fmt) < 0) {
-		err("failed to get %s format", buf_type_to_string(type));
-		return -1;
-	}
-
-	dbg("  %dx%d fmt=%s (%d planes) field=%s cspace=%s flags=%08x",
-	    pix->width, pix->height, fourcc_to_string(pix->pixelformat),
-	    pix->num_planes, v4l2_field_to_string(pix->field),
-	    v4l2_colorspace_to_string(pix->colorspace), pix->flags);
-
-	for (n = 0; n < pix->num_planes; n++)
-		dbg("    plane %d: size=%d stride=%d scanlines=%d", n,
-		    pix->plane_fmt[n].sizeimage,
-		    pix->plane_fmt[n].bytesperline,
-		    pix->plane_fmt[n].reserved[0]);
-
-	vid->cap_buf_format = pix->pixelformat;
-	vid->cap_w = pix->width;
-	vid->cap_h = pix->height;
-
-	/* MSM V4L2 driver stores video data in the first plane and extra
-	 * metadata in the second plane. */
-	vid->cap_buf_size = pix->plane_fmt[0].sizeimage;
-
-	switch (vid->cap_buf_format) {
-	case V4L2_PIX_FMT_NV12:
-		vid->cap_planes_count = 2;
-		/* Y plane */
-		vid->cap_plane_off[0] = 0;
-		vid->cap_plane_stride[0] = pix->plane_fmt[0].bytesperline;
-		/* UV plane */
-		vid->cap_plane_off[1] = pix->plane_fmt[0].reserved[0] *
-			pix->plane_fmt[0].bytesperline;
-		vid->cap_plane_stride[1] = pix->plane_fmt[0].bytesperline;
-		break;
-	default:
-		/* the driver does not provide enough information to compute
-		 * the plane offsets for some formats like UBWC, so just use
-		 * a single plane. */
-		vid->cap_planes_count = 1;
-		vid->cap_plane_off[0] = 0;
-		vid->cap_plane_stride[0] = pix->plane_fmt[0].bytesperline;
-		break;
-	}
-
-	if (i->secure)
-		ion_flags = ION_FLAG_SECURE | ION_FLAG_CP_PIXEL;
-	else
-		ion_flags = 0;
-
-	for (n = 0; n < vid->cap_buf_cnt; n++) {
-		ion_fd = alloc_ion_buffer(i, vid->cap_buf_size, ion_flags);
-		if (ion_fd < 0)
-			return -1;
-
-		if (!i->secure) {
-			buf_addr = mmap(NULL, vid->cap_buf_size, PROT_READ,
-					MAP_SHARED, ion_fd, 0);
-			if (buf_addr == MAP_FAILED) {
-				err("failed to map %s buffer: %m",
-				    buf_type_to_string(type));
-				close(ion_fd);
-				return -1;
-			}
-		} else {
-			buf_addr = NULL;
-		}
-
-		vid->cap_buf_fd[n] = ion_fd;
-		vid->cap_buf_addr[n] = buf_addr;
-	}
-
-	dbg("%s: succesfully mmapped %d buffers", buf_type_to_string(type),
-	    vid->cap_buf_cnt);
-
-	extra_idx = EXTRADATA_IDX(pix->num_planes);
-	if (extra_idx && (extra_idx < VIDEO_MAX_PLANES)) {
-		dbg("%s: extradata plane is %d (size=%d)",
-		    buf_type_to_string(type), extra_idx,
-		    pix->plane_fmt[extra_idx].sizeimage);
-		setup_extradata(i, extra_idx,
-				pix->plane_fmt[extra_idx].sizeimage);
-	}
-
-	return 0;
-}
-
-int video_stop_capture(struct instance *i)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_requestbuffers reqbuf;
-
-	type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-
-	if (video_stream(i, type, VIDIOC_STREAMOFF))
-		return -1;
-
-	memzero(reqbuf);
-	reqbuf.memory = V4L2_MEMORY_USERPTR;
-	reqbuf.type = type;
-
-	if (ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf) < 0) {
-		err("REQBUFS with count=0 on %s queue failed: %m",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	for (int n = 0; n < vid->cap_buf_cnt; n++) {
-		if (munmap(vid->cap_buf_addr[n], vid->cap_buf_size))
-			err("failed to unmap %s buffer: %m",
-			    buf_type_to_string(type));
-
-		if (close(vid->cap_buf_fd[n]) < 0)
-			err("failed to close %s ion buffer: %m",
-			    buf_type_to_string(type));
-
-		vid->cap_buf_fd[n] = -1;
-		vid->cap_buf_addr[n] = NULL;
-		vid->cap_buf_flag[n] = 0;
-	}
-
-	vid->cap_planes_count = 0;
-	vid->cap_buf_size = 0;
-	vid->cap_buf_cnt = 0;
-
-	return 0;
-}
-
-int video_setup_output(struct instance *i, unsigned long codec,
-		       unsigned int size, int count)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_format fmt;
-	struct v4l2_pix_format_mplane *pix;
-	struct v4l2_requestbuffers reqbuf;
-	int ion_fd;
-	int ion_size;
-	void *buf_addr;
-	int n;
-
-	type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-
-	memzero(fmt);
-	fmt.type = type;
-	pix = &fmt.fmt.pix_mp;
-	pix->width = i->width;
-	pix->height = i->height;
-	pix->pixelformat = codec;
-
-	video_set_framerate(i, i->fps_n, i->fps_d);
-
-	if (ioctl(vid->fd, VIDIOC_S_FMT, &fmt) < 0) {
-		err("failed to set %s format: %m", buf_type_to_string(type));
-		return -1;
-	}
-
-	dbg("%s: setup buffer size=%u (requested=%u)", buf_type_to_string(type),
-	    pix->plane_fmt[0].sizeimage, size);
-
-	vid->out_buf_size = pix->plane_fmt[0].sizeimage;
-
-	memzero(reqbuf);
-	reqbuf.count = count;
-	reqbuf.type = type;
-	reqbuf.memory = V4L2_MEMORY_USERPTR;
-
-	if (ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf) < 0) {
-		err("failed to request %s buffers: %m",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	vid->out_buf_cnt = reqbuf.count;
-
-	dbg("%s: requested %d buffers, got %d", buf_type_to_string(type),
-	    count, reqbuf.count);
-
-	ion_size = vid->out_buf_cnt * vid->out_buf_size;
-	ion_fd = alloc_ion_buffer(i, ion_size, 0);
-	if (ion_fd < 0)
-		return -1;
-
-	buf_addr = mmap(NULL, ion_size, PROT_READ | PROT_WRITE, MAP_SHARED,
-			ion_fd, 0);
-	if (buf_addr == MAP_FAILED) {
-		err("failed to map %s buffer: %m", buf_type_to_string(type));
-		return -1;
-	}
-
-	vid->out_ion_fd = ion_fd;
-	vid->out_ion_size = ion_size;
-	vid->out_ion_addr = buf_addr;
-
-	for (n = 0; n < vid->out_buf_cnt; n++) {
-		vid->out_buf_off[n] = n * vid->out_buf_size;
-		vid->out_buf_addr[n] = buf_addr + vid->out_buf_off[n];
-		vid->out_buf_flag[n] = 0;
-	}
-
-	dbg("%s: succesfully mmapped %d buffers", buf_type_to_string(type),
-	    vid->out_buf_cnt);
-
-	return 0;
-}
-
-int video_stop_output(struct instance *i)
-{
-	struct video *vid = &i->video;
-	enum v4l2_buf_type type;
-	struct v4l2_requestbuffers reqbuf;
-
-	type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-
-	if (video_stream(i, type, VIDIOC_STREAMOFF))
-		return -1;
-
-	memzero(reqbuf);
-	reqbuf.memory = V4L2_MEMORY_USERPTR;
-	reqbuf.type = type;
-
-	if (ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf) < 0) {
-		err("REQBUFS with count=0 on %s queue failed: %m",
-		    buf_type_to_string(type));
-		return -1;
-	}
-
-	if (vid->out_ion_addr) {
-		if (munmap(vid->out_ion_addr, vid->out_ion_size))
-			err("failed to unmap %s buffer: %m",
-			    buf_type_to_string(type));
-	}
-
-	if (vid->out_ion_fd >= 0) {
-		if (close(vid->out_ion_fd) < 0)
-			err("failed to close %s ion buffer: %m",
-			    buf_type_to_string(type));
-	}
-
-	for (int n = 0; n < vid->out_buf_cnt; n++) {
-		vid->out_buf_flag[n] = 0;
-		vid->out_buf_off[n] = 0;
-		vid->out_buf_addr[n] = NULL;
-	}
-
-	vid->out_ion_fd = -1;
-	vid->out_ion_size = 0;
-	vid->out_ion_addr = NULL;
-	vid->out_buf_cnt = 0;
-
-	return 0;
-}
-
-int video_subscribe_event(struct instance *i, int event_type)
-{
-	struct v4l2_event_subscription sub;
-
-	memset(&sub, 0, sizeof(sub));
-	sub.type = event_type;
-
-	if (ioctl(i->video.fd, VIDIOC_SUBSCRIBE_EVENT, &sub) < 0) {
-		err("failed to subscribe to event type %u: %m", sub.type);
-		return -1;
-	}
-
-	return 0;
-}
-
-int video_dequeue_event(struct instance *i, struct v4l2_event *ev)
-{
-	struct video *vid = &i->video;
-
-	memset(ev, 0, sizeof (*ev));
-
-	if (ioctl(vid->fd, VIDIOC_DQEVENT, ev) < 0) {
-		err("failed to dequeue event: %m");
-		return -1;
-	}
-
-	return 0;
-}
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ * Copyright (c) 2015 Linaro Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#include <linux/videodev2.h>
+#include "msm-v4l2-controls.h"
+#include <fcntl.h>
+#include <string.h>
+#include <sys/mman.h>
+#include <sys/ioctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <errno.h>
+
+#include "common.h"
+
+static char *dbg_type[2] = {"OUTPUT", "CAPTURE"};
+static char *dbg_status[2] = {"ON", "OFF"};
+
+int video_open(struct instance *i, char *name)
+{
+	struct v4l2_capability cap;
+	int ret;
+
+	i->video.fd = open(name, O_RDWR, 0);
+	if (i->video.fd < 0) {
+		err("Failed to open video decoder: %s", name);
+		return -1;
+	}
+
+	memzero(cap);
+	ret = ioctl(i->video.fd, VIDIOC_QUERYCAP, &cap);
+	if (ret) {
+		err("Failed to verify capabilities");
+		return -1;
+	}
+
+	info("caps (%s): driver=\"%s\" bus_info=\"%s\" card=\"%s\" fd=0x%x",
+	     name, cap.driver, cap.bus_info, cap.card, i->video.fd);
+
+	if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE) ||
+	    !(cap.capabilities & V4L2_CAP_VIDEO_OUTPUT_MPLANE) ||
+	    !(cap.capabilities & V4L2_CAP_STREAMING)) {
+		err("Insufficient capabilities for video device (is %s correct?)",
+		    name);
+		return -1;
+	}
+
+        return 0;
+}
+
+void video_close(struct instance *i)
+{
+	close(i->video.fd);
+}
+
+int video_set_control(struct instance *i)
+{
+	struct v4l2_control control = {0};
+	int ret;
+
+	control.id = V4L2_CID_MPEG_VIDC_VIDEO_CONTINUE_DATA_TRANSFER;
+	control.value = 1;
+
+	ret = ioctl(i->video.fd, VIDIOC_S_CTRL, &control);
+
+	return ret;
+}
+
+static int video_queue_buf(struct instance *i, int n, int l1, int l2, int type,
+			   int nplanes)
+{
+	struct video *vid = &i->video;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[2];
+	int ret;
+
+	memzero(buf);
+	memset(planes, 0, sizeof(planes));
+	buf.type = type;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.index = n;
+	buf.length = nplanes;
+	buf.m.planes = planes;
+
+	buf.m.planes[0].bytesused = l1;
+	buf.m.planes[1].bytesused = l2;
+
+	buf.m.planes[0].data_offset = 0;
+	buf.m.planes[1].data_offset = 0;
+
+	if (type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+		buf.m.planes[0].length = vid->cap_buf_size[0];
+	} else {
+		buf.m.planes[0].length = vid->out_buf_size;
+		if (l1 == 0)
+			buf.flags |= V4L2_QCOM_BUF_FLAG_EOS;
+	}
+
+	ret = ioctl(vid->fd, VIDIOC_QBUF, &buf);
+	if (ret) {
+		err("Failed to queue buffer (index=%d) on %s (ret:%d)",
+		    buf.index,
+		    dbg_type[type==V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE], ret);
+		return -1;
+	}
+
+//	dbg("  Queued buffer on %s queue with index %d",
+//	    dbg_type[type==V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE], buf.index);
+
+	return 0;
+}
+
+int video_queue_buf_out(struct instance *i, int n, int length)
+{
+	struct video *vid = &i->video;
+
+	if (n >= vid->out_buf_cnt) {
+		err("Tried to queue a non exisiting buffer");
+		return -1;
+	}
+
+	return video_queue_buf(i, n, length, 0,
+			       V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, OUT_PLANES);
+}
+
+int video_queue_buf_cap(struct instance *i, int n)
+{
+	struct video *vid = &i->video;
+
+	if (n >= vid->cap_buf_cnt) {
+		err("Tried to queue a non exisiting buffer");
+		return -1;
+	}
+
+	return video_queue_buf(i, n, vid->cap_buf_size[0], vid->cap_buf_size[1],
+			       V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, CAP_PLANES);
+}
+
+static int video_dequeue_buf(struct instance *i, struct v4l2_buffer *buf)
+{
+	struct video *vid = &i->video;
+	int ret;
+
+	ret = ioctl(vid->fd, VIDIOC_DQBUF, buf);
+	if (ret < 0) {
+		err("Failed to dequeue buffer (%d)", -errno);
+		return -errno;
+	}
+
+//	dbg("Dequeued buffer on %s queue with index %d (flags:%x, bytesused:%d)",
+//	    dbg_type[buf->type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE],
+//	    buf->index, buf->flags, buf->m.planes[0].bytesused);
+
+	return 0;
+}
+
+int video_dequeue_output(struct instance *i, int *n)
+{
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[OUT_PLANES];
+	int ret;
+
+	memzero(buf);
+	buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.m.planes = planes;
+	buf.length = OUT_PLANES;
+
+	ret = video_dequeue_buf(i, &buf);
+	if (ret < 0)
+		return ret;
+
+	*n = buf.index;
+
+	return 0;
+}
+
+int video_dequeue_capture(struct instance *i, int *n, int *finished,
+			  unsigned int *bytesused)
+{
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[CAP_PLANES];
+
+	memzero(buf);
+	buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	buf.memory = V4L2_MEMORY_MMAP;
+	buf.m.planes = planes;
+	buf.length = CAP_PLANES;
+
+	if (video_dequeue_buf(i, &buf))
+		return -1;
+
+	*finished = 0;
+
+	if (buf.flags & V4L2_QCOM_BUF_FLAG_EOS ||
+	    buf.m.planes[0].bytesused == 0)
+		*finished = 1;
+
+	*bytesused = buf.m.planes[0].bytesused;
+	*n = buf.index;
+
+	return 0;
+}
+
+int video_stream(struct instance *i, enum v4l2_buf_type type, int status)
+{
+	struct video *vid = &i->video;
+	int ret;
+
+	ret = ioctl(vid->fd, status, &type);
+	if (ret) {
+		err("Failed to change streaming (type=%s, status=%s)",
+		    dbg_type[type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE],
+		    dbg_status[status == VIDIOC_STREAMOFF]);
+		return -1;
+	}
+
+	dbg("Stream %s on %s queue", dbg_status[status==VIDIOC_STREAMOFF],
+	    dbg_type[type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE]);
+
+	return 0;
+}
+
+int video_stop(struct instance *i)
+{
+	struct video *vid = &i->video;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_decoder_cmd dec;
+	int ret;
+
+	memzero(dec);
+	dec.cmd = V4L2_DEC_CMD_STOP;
+	ret = ioctl(vid->fd, VIDIOC_DECODER_CMD, &dec);
+	if (ret < 0) {
+		err("DECODER_CMD failed (%s)", strerror(errno));
+		return -1;
+	}
+
+	/* HACK: streamoff failing, so bail out of here */
+	return 0;
+
+	memzero(reqbuf);
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret < 0) {
+		err("REQBUFS with count=0 on CAPTURE queue failed (%s)",
+		    strerror(errno));
+		return -1;
+	}
+
+	memzero(reqbuf);
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret < 0) {
+		err("REQBUFS with count=0 on OUTPUT queue failed (%s)",
+		    strerror(errno));
+		return -1;
+	}
+
+	ret = video_stream(i, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
+			   VIDIOC_STREAMOFF);
+	if (ret < 0)
+		err("STREAMOFF CAPTURE queue failed (%s)", strerror(errno));
+
+	ret = video_stream(i, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE,
+			   VIDIOC_STREAMOFF);
+	if (ret < 0)
+		err("STREAMOFF OUTPUT queue failed (%s)", strerror(errno));
+
+	return 0;
+}
+
+int video_setup_capture(struct instance *i, int extra_buf, int w, int h)
+{
+	struct video *vid = &i->video;
+	struct v4l2_format fmt;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[CAP_PLANES];
+	int ret;
+	int n;
+
+	fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	fmt.fmt.pix_mp.height = h;
+	fmt.fmt.pix_mp.width = w;
+
+printf("video_setup_capture: %dx%d\n", w, h);
+	if (i->out_format == NULL) {
+		printf("Output format not specified, use defalt NV12.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_NV12;
+	}
+	else if (strcmp(i->out_format, "argb888") == 0) {
+		printf("Specified output format ARGB888.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_ARGB32;
+	}
+	else if (strcmp(i->out_format, "rgb565") == 0) {
+		printf("Specified output format RGB565.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_RGB565;
+	}
+	else {
+		printf("Unrecognized output format, use defalt NV12.\n");
+		fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_NV12;
+	}
+
+	ret = ioctl(vid->fd, VIDIOC_S_FMT, &fmt);
+	if (ret) {
+		err("Failed to set format (%dx%d)", w, h);
+		return -1;
+	}
+
+	vid->cap_w = fmt.fmt.pix_mp.width;
+	vid->cap_h = fmt.fmt.pix_mp.height;
+
+	vid->cap_buf_size[0] = fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
+	vid->cap_buf_size[1] = fmt.fmt.pix_mp.plane_fmt[1].sizeimage;
+
+	vid->cap_buf_cnt = 4 + extra_buf;
+	vid->cap_buf_cnt_min = 4;
+	vid->cap_buf_queued = 0;
+
+	dbg("video decoder buffer parameters: %dx%d plane[0]=%d plane[1]=%d",
+	    fmt.fmt.pix_mp.width, fmt.fmt.pix_mp.height,
+	    vid->cap_buf_size[0], vid->cap_buf_size[1]);
+
+	memzero(reqbuf);
+	reqbuf.count = vid->cap_buf_cnt;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret != 0) {
+		err("REQBUFS failed on CAPTURE queue (%s)", strerror(errno));
+		return -1;
+	}
+
+	dbg("Number of CAPTURE buffers is %d (requested %d, extra %d)",
+	    reqbuf.count, vid->cap_buf_cnt, extra_buf);
+
+	vid->cap_buf_cnt = reqbuf.count;
+
+	for (n = 0; n < vid->cap_buf_cnt; n++) {
+		memzero(buf);
+		memset(planes, 0, sizeof(planes));
+		buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		buf.memory = V4L2_MEMORY_MMAP;
+		buf.index = n;
+		buf.m.planes = planes;
+		buf.length = CAP_PLANES;
+
+		ret = ioctl(vid->fd, VIDIOC_QUERYBUF, &buf);
+		if (ret != 0) {
+			err("QUERYBUF failed on CAPTURE queue (%s)",
+			    strerror(errno));
+			return -1;
+		}
+
+		vid->cap_buf_off[n][0] = buf.m.planes[0].m.mem_offset;
+
+		vid->cap_buf_addr[n][0] = mmap(NULL, buf.m.planes[0].length,
+					       PROT_READ | PROT_WRITE,
+					       MAP_SHARED,
+					       vid->fd,
+					       buf.m.planes[0].m.mem_offset);
+
+		if (vid->cap_buf_addr[n][0] == MAP_FAILED) {
+			err("Failed to MMAP CAPTURE buffer on plane0");
+			return -1;
+		}
+
+		vid->cap_buf_size[0] = buf.m.planes[0].length;
+	}
+
+	dbg("Succesfully mmapped %d CAPTURE buffers", n);
+
+	return 0;
+}
+
+int video_setup_output(struct instance *i, unsigned long codec,
+		       unsigned int size, int count)
+{
+	struct video *vid = &i->video;
+	struct v4l2_format fmt;
+	struct v4l2_requestbuffers reqbuf;
+	struct v4l2_buffer buf;
+	struct v4l2_plane planes[OUT_PLANES];
+	int ret;
+	int n;
+
+	memzero(fmt);
+	fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	fmt.fmt.pix_mp.width = MAX_H264_WIDTH; // i->width;
+	fmt.fmt.pix_mp.height = MAX_H264_HEIGHT; //i->height;
+	fmt.fmt.pix_mp.pixelformat = codec;
+
+	ret = ioctl(vid->fd, VIDIOC_S_FMT, &fmt);
+	if (ret) {
+		err("Failed to set format on OUTPUT (%s)", strerror(errno));
+		return -1;
+	}
+
+	dbg("Setup decoding OUTPUT buffer size=%u (requested=%u)",
+	    fmt.fmt.pix_mp.plane_fmt[0].sizeimage, size);
+
+	vid->out_buf_size = fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
+
+	memzero(reqbuf);
+	reqbuf.count = count;
+	reqbuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	reqbuf.memory = V4L2_MEMORY_MMAP;
+
+	ret = ioctl(vid->fd, VIDIOC_REQBUFS, &reqbuf);
+	if (ret) {
+		err("REQBUFS failed on OUTPUT queue");
+		return -1;
+	}
+
+	vid->out_buf_cnt = reqbuf.count;
+
+	dbg("Number of video decoder OUTPUT buffers is %d (requested %d)",
+	    vid->out_buf_cnt, count);
+
+	for (n = 0; n < vid->out_buf_cnt; n++) {
+		memzero(buf);
+		memset(planes, 0, sizeof(planes));
+		buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+		buf.memory = V4L2_MEMORY_MMAP;
+		buf.index = n;
+		buf.m.planes = planes;
+		buf.length = OUT_PLANES;
+
+		ret = ioctl(vid->fd, VIDIOC_QUERYBUF, &buf);
+		if (ret != 0) {
+			err("QUERYBUF failed on OUTPUT buffer");
+			return -1;
+		}
+
+		vid->out_buf_off[n] = buf.m.planes[0].m.mem_offset;
+		vid->out_buf_size = buf.m.planes[0].length;
+
+		vid->out_buf_addr[n] = mmap(NULL, buf.m.planes[0].length,
+					    PROT_READ | PROT_WRITE, MAP_SHARED,
+					    vid->fd,
+					    buf.m.planes[0].m.mem_offset);
+
+		if (vid->out_buf_addr[n] == MAP_FAILED) {
+			err("Failed to MMAP OUTPUT buffer");
+			return -1;
+		}
+
+		vid->out_buf_flag[n] = 0;
+	}
+
+	dbg("Succesfully mmapped %d OUTPUT buffers", n);
+
+	return 0;
+}
+
diff --git a/video.h b/video.h
index 83b259c..7a0bf26 100644
--- a/video.h
+++ b/video.h
@@ -1,93 +1,66 @@
-/*
- * V4L2 Codec decoding example application
- * Kamil Debski <k.debski@samsung.com>
- *
- *
- * Copyright 2012 Samsung Electronics Co., Ltd.
- * Copyright (c) 2015 Linaro Ltd.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-#ifndef INCLUDE_VIDEO_H
-#define INCLUDE_VIDEO_H
-
-#include <stdint.h>
-#include <linux/videodev2.h>
-#include <media/msm_vidc.h>
-
-struct instance;
-struct fb;
-
-/* Open the video decoder device */
-int video_open(struct instance *i, char *name);
-
-/* Close the video decoder devices */
-void video_close(struct instance *i);
-
-/* Subscribe to an event on the video device */
-int video_subscribe_event(struct instance *i, int event_type);
-
-/* Setup the OUTPUT queue. The size determines the size for the stream
- * buffer. This is the maximum size a single compressed frame can have.
- * The count is the number of the stream buffers to allocate. */
-int video_setup_output(struct instance *i, unsigned long codec,
-		       unsigned int size, int count);
-
-/* Setup the CAPTURE queue. */
-int video_setup_capture(struct instance *i, int num_buffers, int w, int h);
-
-/* Stop OUTPUT queue and release buffers */
-int video_stop_output(struct instance *i);
-
-/* Stop CAPTURE queue and release buffers */
-int video_stop_capture(struct instance *i);
-
-/* Queue OUTPUT buffer */
-int video_queue_buf_out(struct instance *i, int n, int length,
-			uint32_t flags, struct timeval ts);
-
-/* Queue CAPTURE buffer */
-int video_queue_buf_cap(struct instance *i, int n);
-
-/* Control MFC streaming */
-int video_stream(struct instance *i, enum v4l2_buf_type type, int status);
-
-/* Flush a queue */
-int video_flush(struct instance *i, uint32_t flags);
-
-/* Dequeue a buffer, the structure *buf is used to return the parameters of the
- * dequeued buffer. */
-int video_dequeue_output(struct instance *i, int *n);
-int video_dequeue_capture(struct instance *i, int *n, unsigned int *bytesused,
-			  uint32_t *flags, struct timeval *ts,
-			  struct msm_vidc_extradata_header **extradata);
-
-/* Dequeue a pending event */
-int video_dequeue_event(struct instance *i, struct v4l2_event *ev);
-
-int video_set_framerate(struct instance *i, int num, int den);
-int video_set_control(struct instance *i);
-int video_set_secure(struct instance *i);
-int video_set_dpb(struct instance *i,
-		  enum v4l2_mpeg_vidc_video_dpb_color_format format);
-
-/* extradata parsing */
-bool extradata_header_is_valid(const struct msm_vidc_extradata_header *hdr,
-			       int size);
-void *extradata_header_find(const struct msm_vidc_extradata_header *hdr,
-			    int type);
-
-#endif /* INCLUDE_VIDEO_H */
-
+/*
+ * V4L2 Codec decoding example application
+ * Kamil Debski <k.debski@samsung.com>
+ *
+ *
+ * Copyright 2012 Samsung Electronics Co., Ltd.
+ * Copyright (c) 2015 Linaro Ltd.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+#ifndef INCLUDE_VIDEO_H
+#define INCLUDE_VIDEO_H
+
+#include "common.h"
+
+/* Open the video decoder device */
+int video_open(struct instance *i, char *name);
+
+/* Close the video decoder devices */
+void video_close(struct instance *i);
+
+/* Setup the OUTPUT queue. The size determines the size for the stream
+ * buffer. This is the maximum size a single compressed frame can have.
+ * The count is the number of the stream buffers to allocate. */
+int video_setup_output(struct instance *i, unsigned long codec,
+		       unsigned int size, int count);
+
+/* Setup the CAPTURE queue. The argument extra_buf means the number of extra
+ * buffers that should added to the minimum number of buffers required
+ * by MFC. The final number of buffers allocated is stored in the instance
+ * structure. */
+int video_setup_capture(struct instance *i, int extra_buf, int w, int h);
+
+/* Queue OUTPUT buffer */
+int video_queue_buf_out(struct instance *i, int n, int length);
+
+/* Queue CAPTURE buffer */
+int video_queue_buf_cap(struct instance *i, int n);
+
+/* Control MFC streaming */
+int video_stream(struct instance *i, enum v4l2_buf_type type, int status);
+
+/* Dequeue a buffer, the structure *buf is used to return the parameters of the
+ * dequeued buffer. */
+int video_dequeue_output(struct instance *i, int *n);
+int video_dequeue_capture(struct instance *i, int *n, int *finished,
+			  unsigned int *bytesused);
+
+int video_set_control(struct instance *i);
+
+int video_stop(struct instance *i);
+
+#endif /* INCLUDE_VIDEO_H */
+
-- 
2.25.1

